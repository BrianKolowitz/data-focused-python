{
  "0": {
    "id": "0",
    "title": "00 - Additional Links",
    "content": "Links Python for Data Analysis, 2nd Edition Python for Data Analysis, 2nd Edition Book Chapter 2: Python Language Basics, IPython, and Jupyter Notebooks Chapter 3: Built-in Data Structures, Functions, and Files Chapter 4: NumPy Basics: Arrays and Vectorized Computation Chapter 5: Getting Started with pandas Chapter 6: Data Loading, Storage, and File Formats Chapter 7: Data Cleaning and Preparation Chapter 8: Data Wrangling: Join, Combine, and Reshape Chapter 9: Plotting and Visualization Chapter 10: Data Aggregation and Group Operations Chapter 11: Time Series Chapter 12: Advanced pandas Chapter 13: Introduction to Modeling Libraries in Python Chapter 14: Data Analysis Examples Appendix A: Advanced NumPy",
    "url": "http://localhost:4000/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth/00%20-%20Additional%20Links.html",
    "relUrl": "/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth/00%20-%20Additional%20Links.html"
  },
  "1": {
    "id": "1",
    "title": "00 - Getting Started",
    "content": "Getting Started Welcome to Data Focused Python. In this guide we’ll walk through all the steps you need to get started with the course. Python has a robust community which is great, but it also means there’s going to be many options from python distribution to IDEs to libraries. There’s no right or wrong selection, only the one that works best for you. Requirements Python 3.7 Instructor Recommendations You can use any combination of technology that you’re most familiar with, but here’s a short list or recommended options. Python Distribution - Anaconda Python Python IDE - PyCharm Setup Depending on your configuration (Windows, MacOS, Linux, etc.) your setup will vary. There’s no shortage of guides on the internet that you can follow. Here’s one direct from Jetbrains the creators of PyCharm. Your First Python Program Now that you have everything setup, you’ll want to dive in and create your first program. Jetbrains has a great tutorial that describes how to Create and Running Your First Python Project. Once you’re comfortable creating programs you might want to learn how to Debug Your First Python Application, Test Your First Python Application, or even Creat and Running Your First Django Project. Django is a great way to build web applications in python, but debugging, testing, and creating web applications are not required components of this course. However, these are useful skills to pick up as you become more familiar with building solutions in python. Cloning the Course Materials After you’re comfortable working with your Python IDE to create basic python programs, you’ll want to clone the course materials from GitHub. Before you can clone the repository, you’ll have to install git on your local machine. Git is a distributed version control system that’s great for managing projects with distributed team members. There’s a lot of great resources on how to use git. Here’s 2 of my favorite interactive tutorials: Try Git Learn Git Branching We won’t be doing any branching in this course, but I think it’s important to know so I’ve included the link. Once you’ve installed git and are somewhat comfortable with the command line tool, you can read about how to Clone a Repository from GitHub. It’s as easy as: git clone https://github.com/BrianKolowitz/data-focused-python.git However, I personally like to Add SSH Keys to GitHub and clone using this command: git clone git@github.com:BrianKolowitz/data-focused-python.git Running the Notebooks Once the course git repository has been cloned locally you can run the course notebooks and follow along in class or try them at home. First, change the directory to the data-focused-python directory of your clonned repository,. cd data-focused-python Then start Jupyter jupyter notebook The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. If you’ve installed Anaconda, Jupyter is packaged as part of the distribution. Running the Python Interpreter Python itself is an interpreted programming language which means the source code you type gets executed by the interpreter at runtime. You can start the python interpreter from any command line by executing: python I encourage you to try it out. You can follow along the official python docs here Running the IPython Interpreter IPython builds on the Python interpreter adding advanced read-eval-print-loop (REPL) functionality among other features. Executing Python Files Using the Python interpreter is great for small problems, testing libraries, etc. but all of your code lives in memory inside the python interpreter. When the interpreter stops your code is gone forever. In order to get around this limitation you can create python script files and execute the files using the interpreter. Create a file on your harddrive called hello.py. Copy and paste this code into the file and save it. print(&#39;Hello class&#39;) print(&#39;Welcome to 95-888&#39;) You can then execute the file by typing this command into your terminal. python hello.py",
    "url": "http://localhost:4000/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/00%20-%20Getting%20Started.html",
    "relUrl": "/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/00%20-%20Getting%20Started.html"
  },
  "2": {
    "id": "2",
    "title": "01 - Descriptive Statistics",
    "content": "Descriptive Statistics Min Max Mean Median Standard Deviation Variance First we’re going to define a method to get the patient’s age from their birthdate and then use that function to create a list of patient ages. import csv from datetime import date, timedelta from dateutil import parser def get_age(birth_date): if isinstance(birth_date, str): birth_date = parser.parse(birth_date).date() age = (date.today() - birth_date) // timedelta(days=365) return age # calculate a list of patient ages patient_ages = [] with open(&#39;../data/csv/patients.csv&#39;) as f: reader = csv.DictReader(f) for i, row in enumerate(reader): date_of_birth = row[&#39;BIRTHDATE&#39;] age = get_age(date_of_birth) patient_ages.append(age) print(patient_ages) [5, 50, 50, 41, 63, 52, 28, 72, 23, 31] Min &amp; Max # find min and max with a for loop: min_age = 0 max_age = 0 for i, age in enumerate(patient_ages): if i == 0: min_age = age max_age = age if age &lt; min_age: min_age = age if age &gt; max_age: max_age = age print(f&#39;Min Age: {min_age}, Max Age: {max_age}&#39;) Min Age: 5, Max Age: 72 # find min and max with a for loop: min_age = patient_ages[0] max_age = patient_ages[0] for age in patient_ages: if age &lt; min_age: min_age = age if age &gt; max_age: max_age = age print(f&#39;Min Age: {min_age}, Max Age: {max_age}&#39;) Min Age: 5, Max Age: 72 # find min and max by sorting sorted_ages = sorted(patient_ages) min_age = sorted_ages[0] max_age = sorted_ages[-1] print(f&#39;Min Age: {min_age}, Max Age: {max_age}&#39;) Min Age: 5, Max Age: 72 # find min and max with reduce from functools import reduce min_age = reduce(lambda a, b : a if a &lt; b else b, patient_ages) max_age = reduce(lambda a, b : a if a &gt; b else b, patient_ages) print(f&#39;Min Age: {min_age}, Max Age: {max_age}&#39;) Min Age: 5, Max Age: 72 # find min and max with min and max min_age = min(patient_ages) max_age = max(patient_ages) print(f&#39;Min Age: {min_age}, Max Age: {max_age}&#39;) Min Age: 5, Max Age: 72 Mean # calculate mean with a for loop total_age = 0 age_count = 0 for age in patient_ages: total_age += age age_count += 1 mean_age = total_age / age_count print(f&#39;Mean Age: {mean_age}&#39;) Mean Age: 41.5 # calculate mean age with reduce import functools total_age = functools.reduce(lambda a, b : a + b, patient_ages) age_count = len(patient_ages) mean_age = total_age / age_count print(f&#39;Mean Age: {mean_age}&#39;) Mean Age: 41.5 # calculate mean age with sum and len mean_age = sum(patient_ages) / len(patient_ages) print(f&#39;Mean Age: {mean_age}&#39;) Mean Age: 41.5 # calculate mean with statistics package from statistics import mean mean_age = mean(patient_ages) print(f&#39;Mean Age: {mean_age}&#39;) Mean Age: 41.5 Median # calculate median with a for loop from math import floor sorted_ages = sorted(patient_ages) midpoint = len(sorted_ages) / 2 if midpoint.is_integer(): high_index = floor(midpoint) low_index = high_index - 1 median_age = (sorted_ages[high_index] + sorted_ages[low_index]) / 2 else: median_age = sorted_ages[floor(midpoint)] print(f&#39;Median Age: {median_age}&#39;) Median Age: 45.5 # calculate median with statistics package from statistics import median median_age = median(patient_ages) print(f&#39;Median Age: {median_age}&#39;) Median Age: 45.5 Variance # calculate variance with a for loop mean_age = mean(patient_ages) squares = [] for age in patient_ages: squares.append((age - mean_age)**2) age_variance = mean(squares) print(f&#39;Variance: {age_variance}&#39;) Variance: 361.45 # calculate variance with a list comprehension mean_age = mean(patient_ages) squares = [(age - mean_age)**2 for age in patient_ages] age_variance = mean(squares) print(f&#39;Variance: {age_variance}&#39;) Variance: 361.45 # calculate variance with map and reduce from functools import reduce mean_age = mean(patient_ages) squares = map(lambda x: (x - mean_age) ** 2, patient_ages) age_variance = reduce(lambda a, b: a + b, squares) / len(patient_ages) print(f&#39;Variance: {age_variance}&#39;) Variance: 361.45 # calculate variance with statistics package from statistics import pvariance age_variance = pvariance(patient_ages) print(f&#39;Populaiton Variance: {age_variance}&#39;) Populaiton Variance: 361.45 # calculate variance with statistics package from statistics import variance age_variance = variance(patient_ages) print(f&#39;Saple Variance: {age_variance}&#39;) Saple Variance: 401.6111111111111 Standard Deviation # calculate variance with statistics package import math from statistics import pvariance age_variance = pvariance(patient_ages) standard_devation = math.sqrt(age_variance) print(f&#39;Standard Deviation: {standard_devation}&#39;) Standard Deviation: 19.011838417154717 # calculate variance with statistics package from statistics import pstdev standard_devation = pstdev(patient_ages) print(f&#39;Standard Deviation: {standard_devation}&#39;) Standard Deviation: 19.011838417154717 # calculate standard deviation with statistics package from statistics import pstdev standard_deviation = pstdev(patient_ages) print(f&#39;Standard Deviation: {standard_deviation}&#39;) Standard Deviation: 19.011838417154717",
    "url": "http://localhost:4000/lectures/Week%2004%20-%20Numpy,%20Pandas,%20Graphing%20&%20Visualization/01%20-%20Descriptive%20Statistics.html",
    "relUrl": "/lectures/Week%2004%20-%20Numpy,%20Pandas,%20Graphing%20&%20Visualization/01%20-%20Descriptive%20Statistics.html"
  },
  "3": {
    "id": "3",
    "title": "01 - NumPy Introduction",
    "content": "Python Numpy Tutorial Source A NumPy tutorial for beginners in which you’ll learn how to create a NumPy array, use broadcasting, access values, manipulate arrays, and much more. NumPy is, just like SciPy, Scikit-Learn, Pandas, etc. one of the packages that you just can’t miss when you’re learning data science, mainly because this library provides you with an array data structure that holds some benefits over Python lists, such as: being more compact, faster access in reading and writing items, being more convenient and more efficient. Today we’ll focus precisely on this. This NumPy tutorial will not only show you what NumPy arrays actually are and how you can install Python, but you’ll also learn how to make arrays (even when your data comes from files!), how broadcasting works, how you can ask for help, how to manipulate your arrays and how to visualize them. Content What Is A Python Numpy Array? How To Make NumPy Arrays How NumPy Broadcasting Works How Do Array Mathematics Work? How To Subset, Slice, And Index Arrays How To Manipulate Arrays How To Visualize NumPy Arrays Beyond Data Analysis with NumPy What Is A Python Numpy Array? You already read in the introduction that NumPy arrays are a bit like Python lists, but still very much different at the same time. For those of you who are new to the topic, let’s clarify what it exactly is and what it’s good for. As the name gives away, a NumPy array is a central data structure of the numpy library. The library’s name is short for “Numeric Python” or “Numerical Python”. This already gives an idea of what you’re dealing with, right? In other words, NumPy is a Python library that is the core library for scientific computing in Python. It contains a collection of tools and techniques that can be used to solve on a computer mathematical models of problems in Science and Engineering. One of these tools is a high-performance multidimensional array object that is a powerful data structure for efficient computation of arrays and matrices. To work with these arrays, there’s a vast amount of high-level mathematical functions operate on these matrices and arrays. Then, what is an array? When you look at the print of a couple of arrays, you could see it as a grid that contains values of the same type: # import the library import numpy as np # create a 1-dimensional array my_array = np.array([1, 2, 3, 4, 5, 6, 7, 8 ,9, 10, 11, 12]) print(my_array) [ 1 2 3 4 5 6 7 8 9 10 11 12] # create a 2-dimensional array my_2d_array = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) print(my_2d_array) [[ 1 2 3 4] [ 5 6 7 8] [ 9 10 11 12]] # create a 3-dimensional array my_3d_array = np.array([[[1, 2, 3, 4], [5, 6, 7, 8]], [[9, 10, 11, 12], [13, 14, 15, 16]]]) print(my_3d_array) [[[ 1 2 3 4] [ 5 6 7 8]] [[ 9 10 11 12] [13 14 15 16]]] You see that, in the example above, the data are integers. The array holds and represents any regular data in a structured way. However, you should know that, on a structural level, an array is basically nothing but pointers. It’s a combination of a memory address, a data type, a shape, and strides: The data pointer indicates the memory address of the first byte in the array, The data type or dtype pointer describes the kind of elements that are contained within the array, The shape indicates the shape of the array, and The strides are the number of bytes that should be skipped in memory to go to the next element. If your strides are (10,1), you need to proceed one byte to get to the next column and 10 bytes to locate the next row. Or, in other words, an array contains information about the raw data, how to locate an element and how to interpret an element. You can easily test this by exploring the numpy array attributes: # Print out memory address print(&#39;Memory Address&#39;, my_2d_array.data) # Print out the shape of `my_array` print(&#39;Shape&#39;, my_2d_array.shape) # Print out the data type of `my_array` print(&#39;Data Type&#39;, my_2d_array.dtype) # Print out the stride of `my_array` print(&#39;Strides&#39;, my_2d_array.strides) Memory Address &lt;memory at 0x119c12dc8&gt; Shape (3, 4) Data Type int64 Strides (32, 8) You see that now, you get a lot more information: for example, the data type that is printed out is ‘int64’ or signed 32-bit integer type; This is a lot more detailed! That also means that the array is stored in memory as 64 bytes (as each integer takes up 8 bytes and you have an array of 8 integers). The strides of the array tell us that you have to skip 8 bytes (one value) to move to the next column, but 32 bytes (4 values) to get to the same position in the next row. As such, the strides for the array will be (32,8). Note that if you set the data type to int32, the strides tuple that you get back will be (16, 4), as you will still need to move one value to the next column and 4 values to get the same position. The only thing that will have changed is the fact that each integer will take up 4 bytes instead of 8. The array that you see above is, as its name already suggested, a 2-dimensional array: you have rows and columns. The rows are indicated as the “axis 0”, while the columns are the “axis 1”. The number of the axis goes up accordingly with the number of the dimensions: in 3-D arrays, of which you have also seen an example in the previous code chunk, you’ll have an additional “axis 2”. Note that these axes are only valid for arrays that have at least 2 dimensions, as there is no point in having this for 1-D arrays; These axes will come in handy later when you’re manipulating the shape of your NumPy arrays. How To Make NumPy Arrays To make a numpy array, you can just use the np.array() function. All you need to do is pass a list to it, and optionally, you can also specify the data type of the data. If you want to know more about the possible data types that you can pick, go here or consider taking a brief look at DataCamp’s NumPy cheat sheet. There’s no need to go and memorize these NumPy data types if you’re a new user; But you do have to know and care what data you’re dealing with. The data types are there when you need more control over how your data is stored in memory and on disk. Especially in cases where you’re working with extensive data, it’s good that you know to control the storage type. Don’t forget that, in order to work with the np.array() function, you need to make sure that the numpy library is present in your environment. The NumPy library follows an import convention: when you import this library, you have to make sure that you import it as np. By doing this, you’ll make sure that other Pythonistas understand your code more easily. In the following example you’ll create the my_array array that you have already played around with above: # Import `numpy` as `np` import numpy as np # Make the array `my_array` my_array = np.array([[1,2,3,4], [5,6,7,8]], dtype=np.int32) # Print `my_array` print(my_array, my_array.dtype) [[1 2 3 4] [5 6 7 8]] int32 However, sometimes you don’t know what data you want to put in your array, or you want to import data into a numpy array from another source. In those cases, you’ll make use of initial placeholders or functions to load data from text into arrays, respectively. The following sections will show you how to do this. How To Make An “Empty” NumPy Array What people often mean when they say that they are creating “empty” arrays is that they want to make use of initial placeholders, which you can fill up afterward. You can initialize arrays with ones or zeros, but you can also create arrays that get filled up with evenly spaced values, constant or random values. However, you can still make a totally empty array, too. Luckily for us, there are quite a lot of functions to make Try it all out below! # Create an array of ones np.ones((3, 4)) array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]) # Create an array of zeros np.zeros((2, 3, 4), dtype=np.int16) array([[[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]], [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]], dtype=int16) # Create an array with random values np.random.random((2, 2)) array([[0.49145717, 0.10493541], [0.93962816, 0.64711331]]) # Create an empty array np.empty((3, 2)) array([[0., 0.], [0., 0.], [0., 0.]]) # Create a full array np.full((2, 2), 7) array([[7, 7], [7, 7]]) # Create an array of evenly-spaced values print(np.arange(10, 25, 5)) [10 15 20] # Create an array of evenly-spaced values np.linspace(0, 2, 9) array([0. , 0.25, 0.5 , 0.75, 1. , 1.25, 1.5 , 1.75, 2. ]) For some, such as np.ones(), np.random.random(), np.empty(), np.full() or np.zeros() the only thing that you need to do in order to make arrays with ones or zeros is pass the shape of the array that you want to make. As an option to np.ones() and np.zeros(), you can also specify the data type. In the case of np.full(), you also have to specify the constant value that you want to insert into the array. With np.linspace() and np.arange() you can make arrays of evenly spaced values. The difference between these two functions is that the last value of the three that are passed in the code chunk above designates either the step value for np.linspace() or a number of samples for np.arange(). What happens in the first is that you want, for example, an array of 9 values that lie between 0 and 2. For the latter, you specify that you want an array to start at 10 and per steps of 5, generate values for the array that you’re creating. Remember that NumPy also allows you to create an identity array or matrix with np.eye() and np.identity(). An identity matrix is a square matrix of which all elements in the principal diagonal are ones, and all other elements are zeros. When you multiply a matrix with an identity matrix, the given matrix is left unchanged. How To Load NumPy Arrays From Text Creating arrays with the help of initial placeholders or with some example data is an excellent way of getting started with numpy. But when you want to get started with data analysis, you’ll need to load data from text files. With that what you have seen up until now, you won’t really be able to do much. Make use of some specific functions to load data from your files, such as loadtxt() or genfromtxt(). Let’s say you have the following text files with data: # Import your data x, y, z = np.loadtxt(&#39;data.txt&#39;, skiprows=1, unpack=True) print(x) print(y) print(z) [0.2536 0.4839 0.1292 0.1781 0.6253 0.6253] [0.1008 0.4536 0.6875 0.3049 0.3486 0.3486] [0.3857 0.3561 0.5929 0.8928 0.8791 0.8791] In the code above, you use loadtxt() to load the data in your environment. You see that the first argument that both functions take is the text file data.txt. Next, there are some specific arguments for each: in the first statement, you skip the first row, and you return the columns as separate arrays with unpack=TRUE. This means that the values in column Value1 will be put in x, and so on. Note that, in case you have comma-delimited data or if you want to specify the data type, there are also the arguments delimiter and dtype that you can add to the loadtxt() arguments. my_array2 = np.genfromtxt(&#39;data2.txt&#39;, skip_header=1, filling_values=-999) print(my_array2) [[ 4.839e-01 4.536e-01 3.561e-01] [ 1.292e-01 6.875e-01 -9.990e+02] [ 1.781e-01 3.049e-01 8.928e-01] [-9.990e+02 5.801e-01 2.038e-01] [ 5.993e-01 4.357e-01 7.410e-01]] You see that here, you resort to genfromtxt() to load the data. In this case, you have to handle some missing values that are indicated by the &#39;MISSING&#39; strings. Since the genfromtxt() function converts character strings in numeric columns to nan, you can convert these values to other ones by specifying the filling_values argument. In this case, you choose to set the value of these missing values to -999. If by any chance, you have values that don’t get converted to nan by genfromtxt(), there’s always the missing_values argument that allows you to specify what the missing values of your data exactly are. But this is not all. Tip: check out this page to see what other arguments you can add to import your data successfully. You now might wonder what the difference between these two functions really is. The examples indicated this maybe implicitly, but, in general, genfromtxt() gives you a little bit more flexibility; It’s more robust than loadtxt(). Let’s make this difference a little bit more practical: the latter, loadtxt(), only works when each row in the text file has the same number of values; So when you want to handle missing values easily, you’ll typically find it easier to use genfromtxt(). But this is definitely not the only reason. A brief look on the number of arguments that genfromtxt() has to offer will teach you that there is really a lot more things that you can specify in your import, such as the maximum number of rows to read or the option to automatically strip white spaces from variables. How To Save NumPy Arrays Once you have done everything that you need to do with your arrays, you can also save them to a file. If you want to save the array to a text file, you can use the savetxt() function to do this: x = np.arange(0.0, 5.0, 1.0) print(x) np.savetxt(&#39;test.out&#39;, x, delimiter=&#39;,&#39;) [0. 1. 2. 3. 4.] Remember that np.arange() creates a NumPy array of evenly-spaced values. The third value that you pass to this function is the step value. There are, of course, other ways to save your NumPy arrays to text files. Check out the functions in the table below if you want to get your data to binary files or archives:     save() Save an array to a binary file in NumPy .npy format savez() Save several arrays into an uncompressed .npz archive savez_compressed() Save several arrays into a compressed .npz archive How To Inspect Your NumPy Arrays Besides the array attributes that have been mentioned above, namely, data, shape, dtype and strides, there are some more that you can use to easily get to know more about your arrays. The ones that you might find interesting to use when you’re just starting out are the following: # Print the number of `my_array`&#39;s dimensions print(my_array.ndim) 2 # Print the number of `my_array`&#39;s elements print(my_array.size) 8 # Print information about `my_array`&#39;s memory layout print(my_array.flags) C_CONTIGUOUS : True F_CONTIGUOUS : False OWNDATA : True WRITEABLE : True ALIGNED : True WRITEBACKIFCOPY : False UPDATEIFCOPY : False # Print the length of one array element in bytes print(my_array.itemsize) 4 # Print the total consumed bytes by `my_array`&#39;s elements print(my_array.nbytes) 32 Also note that, besides the attributes, you also have some other ways of gaining more information on and even tweaking your array slightly: # Print the length of `my_array` print(len(my_array)) 2 # Change the data type of `my_array` my_array.astype(float) array([[1., 2., 3., 4.], [5., 6., 7., 8.]]) How NumPy Broadcasting Works Before you go deeper into scientific computing, it might be a good idea to first go over what broadcasting exactly is: it’s a mechanism that allows NumPy to work with arrays of different shapes when you’re performing arithmetic operations. To put it in a more practical context, you often have an array that’s somewhat larger and another one that’s slightly smaller. Ideally, you want to use the smaller array multiple times to perform an operation (such as a sum, multiplication, etc.) on the larger array. To do this, you use the broadcasting mechanism. However, there are some rules if you want to use it. And, before you already sigh, you’ll see that these “rules” are very simple and kind of straightforward! First off, to make sure that the broadcasting is successful, the dimensions of your arrays need to be compatible. Two dimensions are compatible when they are equal. Consider the following example: # Initialize `x` x = np.ones((3, 4)) # Check shape of `x` print(x.shape) print(x) # Initialize `y` y = np.random.random((3, 4)) # Check shape of `y` print(y.shape) print(y) # Add `x` and `y` x + y (3, 4) [[1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.]] (3, 4) [[0.4511468 0.14481101 0.58802688 0.24370081] [0.68376654 0.88216529 0.3002039 0.76107183] [0.75735922 0.02989146 0.3326997 0.29215762]] array([[1.4511468 , 1.14481101, 1.58802688, 1.24370081], [1.68376654, 1.88216529, 1.3002039 , 1.76107183], [1.75735922, 1.02989146, 1.3326997 , 1.29215762]]) Two dimensions are also compatible when one of them is 1: # Initialize `x` x = np.ones((3, 4)) # Check shape of `x` print(x.shape) print(x) # Initialize `y` y = np.arange(4) # Check shape of `y` print(y.shape) print(y) # Subtract `x` and `y` x - y (3, 4) [[1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.]] (4,) [0 1 2 3] array([[ 1., 0., -1., -2.], [ 1., 0., -1., -2.], [ 1., 0., -1., -2.]]) Note that if the dimensions are not compatible, you will get a ValueError. Tip: also test what the size of the resulting array is after you have done the computations! You’ll see that the size is actually the maximum size along each dimension of the input arrays. In other words, you see that the result of x-y gives an array with shape (3,4): y had a shape of (4,) and x had a shape of (3,4). The maximum size along each dimension of x and y is taken to make up the shape of the new, resulting array. Lastly, the arrays can only be broadcast together if they are compatible in all dimensions. Consider the following example: # Initialize `x` and `y` x = np.ones((3, 4)) y = np.random.random((5,1,4)) # Add `x` and `y` x + y array([[[1.52733314, 1.4260942 , 1.80696314, 1.57838685], [1.52733314, 1.4260942 , 1.80696314, 1.57838685], [1.52733314, 1.4260942 , 1.80696314, 1.57838685]], [[1.18964483, 1.24887704, 1.14078041, 1.68675731], [1.18964483, 1.24887704, 1.14078041, 1.68675731], [1.18964483, 1.24887704, 1.14078041, 1.68675731]], [[1.11607086, 1.3413738 , 1.99441401, 1.73364435], [1.11607086, 1.3413738 , 1.99441401, 1.73364435], [1.11607086, 1.3413738 , 1.99441401, 1.73364435]], [[1.15934104, 1.67822692, 1.79716903, 1.02368484], [1.15934104, 1.67822692, 1.79716903, 1.02368484], [1.15934104, 1.67822692, 1.79716903, 1.02368484]], [[1.98791283, 1.91882578, 1.30496902, 1.92508811], [1.98791283, 1.91882578, 1.30496902, 1.92508811], [1.98791283, 1.91882578, 1.30496902, 1.92508811]]]) You see that, even though x and y seem to have somewhat different dimensions, the two can be added together. That is because they are compatible in all dimensions: Array x has dimensions 3 X 4, Array y has dimensions 5 X 1 X 4 Since you have seen above that dimensions are also compatible if one of them is equal to 1, you see that these two arrays are indeed a good candidate for broadcasting! What you will notice is that in the dimension where y has size 1, and the other array has a size greater than 1 (that is, 3), the first array behaves as if it were copied along that dimension. Note that the shape of the resulting array will again be the maximum size along each dimension of x and y: the dimension of the result will be (5,3,4) In short, if you want to make use of broadcasting, you will rely a lot on the shape and dimensions of the arrays with which you’re working. But what if the dimensions are not compatible? What if they are not equal or if one of them is not equal to 1? You’ll have to fix this by manipulating your array! You’ll see how to do this in one of the next sections. How Do Array Mathematics Work? You’ve seen that broadcasting is handy when you’re doing arithmetic operations. In this section, you’ll discover some of the functions that you can use to do mathematics with arrays. As such, it probably won’t surprise you that you can just use +, -, *, / or % to add, subtract, multiply, divide or calculate the remainder of two (or more) arrays. However, a big part of why NumPy is so handy, is because it also has functions to do this. The equivalent functions of the operations that you have seen just now are, respectively, np.add(), np.subtract(), np.multiply(), np.divide() and np.remainder(). You can also easily do exponentiation and taking the square root of your arrays with np.exp() and np.sqrt(), or calculate the sines or cosines of your array with np.sin() and np.cos(). Lastly, its’ also useful to mention that there’s also a way for you to calculate the natural logarithm with np.log() or calculate the dot product by applying the dot() to your array. # Add `x` and `y` np.add(x, y) array([[[1.52733314, 1.4260942 , 1.80696314, 1.57838685], [1.52733314, 1.4260942 , 1.80696314, 1.57838685], [1.52733314, 1.4260942 , 1.80696314, 1.57838685]], [[1.18964483, 1.24887704, 1.14078041, 1.68675731], [1.18964483, 1.24887704, 1.14078041, 1.68675731], [1.18964483, 1.24887704, 1.14078041, 1.68675731]], [[1.11607086, 1.3413738 , 1.99441401, 1.73364435], [1.11607086, 1.3413738 , 1.99441401, 1.73364435], [1.11607086, 1.3413738 , 1.99441401, 1.73364435]], [[1.15934104, 1.67822692, 1.79716903, 1.02368484], [1.15934104, 1.67822692, 1.79716903, 1.02368484], [1.15934104, 1.67822692, 1.79716903, 1.02368484]], [[1.98791283, 1.91882578, 1.30496902, 1.92508811], [1.98791283, 1.91882578, 1.30496902, 1.92508811], [1.98791283, 1.91882578, 1.30496902, 1.92508811]]]) # Subtract `x` and `y` np.subtract(x, y) array([[[0.47266686, 0.5739058 , 0.19303686, 0.42161315], [0.47266686, 0.5739058 , 0.19303686, 0.42161315], [0.47266686, 0.5739058 , 0.19303686, 0.42161315]], [[0.81035517, 0.75112296, 0.85921959, 0.31324269], [0.81035517, 0.75112296, 0.85921959, 0.31324269], [0.81035517, 0.75112296, 0.85921959, 0.31324269]], [[0.88392914, 0.6586262 , 0.00558599, 0.26635565], [0.88392914, 0.6586262 , 0.00558599, 0.26635565], [0.88392914, 0.6586262 , 0.00558599, 0.26635565]], [[0.84065896, 0.32177308, 0.20283097, 0.97631516], [0.84065896, 0.32177308, 0.20283097, 0.97631516], [0.84065896, 0.32177308, 0.20283097, 0.97631516]], [[0.01208717, 0.08117422, 0.69503098, 0.07491189], [0.01208717, 0.08117422, 0.69503098, 0.07491189], [0.01208717, 0.08117422, 0.69503098, 0.07491189]]]) # Multiply `x` and `y` np.multiply(x, y) array([[[0.52733314, 0.4260942 , 0.80696314, 0.57838685], [0.52733314, 0.4260942 , 0.80696314, 0.57838685], [0.52733314, 0.4260942 , 0.80696314, 0.57838685]], [[0.18964483, 0.24887704, 0.14078041, 0.68675731], [0.18964483, 0.24887704, 0.14078041, 0.68675731], [0.18964483, 0.24887704, 0.14078041, 0.68675731]], [[0.11607086, 0.3413738 , 0.99441401, 0.73364435], [0.11607086, 0.3413738 , 0.99441401, 0.73364435], [0.11607086, 0.3413738 , 0.99441401, 0.73364435]], [[0.15934104, 0.67822692, 0.79716903, 0.02368484], [0.15934104, 0.67822692, 0.79716903, 0.02368484], [0.15934104, 0.67822692, 0.79716903, 0.02368484]], [[0.98791283, 0.91882578, 0.30496902, 0.92508811], [0.98791283, 0.91882578, 0.30496902, 0.92508811], [0.98791283, 0.91882578, 0.30496902, 0.92508811]]]) # Divide `x` and `y` np.divide(x, y) array([[[ 1.89633445, 2.34689889, 1.23921397, 1.72894664], [ 1.89633445, 2.34689889, 1.23921397, 1.72894664], [ 1.89633445, 2.34689889, 1.23921397, 1.72894664]], [[ 5.2730149 , 4.0180484 , 7.10326094, 1.45611847], [ 5.2730149 , 4.0180484 , 7.10326094, 1.45611847], [ 5.2730149 , 4.0180484 , 7.10326094, 1.45611847]], [[ 8.61542668, 2.92934023, 1.00561737, 1.36305826], [ 8.61542668, 2.92934023, 1.00561737, 1.36305826], [ 8.61542668, 2.92934023, 1.00561737, 1.36305826]], [[ 6.27584701, 1.47443278, 1.25443909, 42.22109204], [ 6.27584701, 1.47443278, 1.25443909, 42.22109204], [ 6.27584701, 1.47443278, 1.25443909, 42.22109204]], [[ 1.01223506, 1.08834561, 3.27902154, 1.08097811], [ 1.01223506, 1.08834561, 3.27902154, 1.08097811], [ 1.01223506, 1.08834561, 3.27902154, 1.08097811]]]) # Calculate the remainder of `x` and `y` np.remainder(x, y) array([[[0.47266686, 0.1478116 , 0.19303686, 0.42161315], [0.47266686, 0.1478116 , 0.19303686, 0.42161315], [0.47266686, 0.1478116 , 0.19303686, 0.42161315]], [[0.05177586, 0.00449183, 0.01453712, 0.31324269], [0.05177586, 0.00449183, 0.01453712, 0.31324269], [0.05177586, 0.00449183, 0.01453712, 0.31324269]], [[0.0714331 , 0.3172524 , 0.00558599, 0.26635565], [0.0714331 , 0.3172524 , 0.00558599, 0.26635565], [0.0714331 , 0.3172524 , 0.00558599, 0.26635565]], [[0.04395375, 0.32177308, 0.20283097, 0.00523653], [0.04395375, 0.32177308, 0.20283097, 0.00523653], [0.04395375, 0.32177308, 0.20283097, 0.00523653]], [[0.01208717, 0.08117422, 0.08509293, 0.07491189], [0.01208717, 0.08117422, 0.08509293, 0.07491189], [0.01208717, 0.08117422, 0.08509293, 0.07491189]]]) Remember how broadcasting works? Check out the dimensions and the shapes of both x and y in your IPython shell. Are the rules of broadcasting respected? But there is more. Check out this small list of aggregate functions:     a.sum() Array-wise sum a.min() Array-wise minimum value b.max(axis=0) Maximum value of an array row b.cumsum(axis=1) Cumulative sum of the elements a.mean() Mean b.median() Median a.corrcoef() Correlation coefficient np.std(b) Standard deviation Besides all of these functions, you might also find it useful to know that there are mechanisms that allow you to compare array elements. For example, if you want to check whether the elements of two arrays are the same, you might use the == operator. To check whether the array elements are smaller or bigger, you use the &lt; or &gt; operators. This all seems quite straightforward, yes? However, you can also compare entire arrays with each other! In this case, you use the np.array_equal() function. Just pass in the two arrays that you want to compare with each other, and you’re done. Note that, besides comparing, you can also perform logical operations on your arrays. You can start with np.logical_or(), np.logical_not() and np.logical_and(). This basically works like your typical OR, NOT and AND logical operations; In the simplest example, you use OR to see whether your elements are the same (for example, 1), or if one of the two array elements is 1. If both of them are 0, you’ll return FALSE. You would use AND to see whether your second element is also 1 and NOT to see if the second element differs from 1. # `x` AND `y` np.logical_and(x, y) array([[[ True, True, True, True], [ True, True, True, True], [ True, True, True, True]], [[ True, True, True, True], [ True, True, True, True], [ True, True, True, True]], [[ True, True, True, True], [ True, True, True, True], [ True, True, True, True]], [[ True, True, True, True], [ True, True, True, True], [ True, True, True, True]], [[ True, True, True, True], [ True, True, True, True], [ True, True, True, True]]]) # `x` OR `y` np.logical_or(x, y) array([[[ True, True, True, True], [ True, True, True, True], [ True, True, True, True]], [[ True, True, True, True], [ True, True, True, True], [ True, True, True, True]], [[ True, True, True, True], [ True, True, True, True], [ True, True, True, True]], [[ True, True, True, True], [ True, True, True, True], [ True, True, True, True]], [[ True, True, True, True], [ True, True, True, True], [ True, True, True, True]]]) How To Subset, Slice, And Index Arrays Besides mathematical operations, you might also consider taking just a part of the original array (or the resulting array) or just some array elements to use in further analysis or other operations. In such case, you will need to subset, slice and/or index your arrays. These operations are very similar to when you perform them on Python lists. If you want to check out the similarities for yourself, or if you want a more elaborate explanation, you might consider checking out DataCamp’s Python list tutorial. If you have no clue at all on how these operations work, it suffices for now to know these two basic things: You use square brackets [] as the index operator, and Generally, you pass integers to these square brackets, but you can also put a colon : or a combination of the colon with integers in it to designate the elements/rows/columns you want to select. Besides from these two points, the easiest way to see how this all fits together is by looking at some examples of subsetting: # Select the element at the 1st index print(my_array[1]) [5 6 7 8] # Select the element at row 1 column 2 print(my_2d_array[1][2]) 7 # Select the element at row 1 column 2 print(my_2d_array[1,2]) 7 # Select the element at row 1, column 2 and print(my_3d_array[1,1,2]) 15 Something a little bit more advanced than subsetting, if you will, is slicing. Here, you consider not just particular values of your arrays, but you go to the level of rows and columns. You’re basically working with “regions” of data instead of pure “locations”. # Select items at index 0 and 1 print(my_array[0:2]) [[1 2 3 4] [5 6 7 8]] # Select items at row 0 and 1, column 1 print(my_2d_array[0:2,1]) [2 6] # Select items at row 1 # This is the same as saying `my_3d_array[1,:,:] print(my_3d_array[1,...]) [[ 9 10 11 12] [13 14 15 16]] Lastly, there’s also indexing. When it comes to NumPy, there are boolean indexing and advanced or “fancy” indexing. First up is boolean indexing. Here, instead of selecting elements, rows or columns based on index number, you select those values from your array that fulfill a certain condition. # Try out a simple example mask = my_array &lt; 2 print(mask) print(my_array[mask]) [[ True False False False] [False False False False]] [1] # Try out a simple example mask = my_array &gt; 3 print(mask) print(my_array[mask]) [[False False False True] [ True True True True]] [4 5 6 7 8] # Specify a condition bigger_than_3 = (my_3d_array &gt;= 3) # Use the condition to index our 3d array print(my_3d_array[bigger_than_3]) [ 3 4 5 6 7 8 9 10 11 12 13 14 15 16] # Specify a condition mask = (my_3d_array &gt;= 3) &amp; (my_3d_array &lt; 10) # Use the condition to index our 3d array print(my_3d_array[mask]) [3 4 5 6 7 8 9] Note that, to specify a condition, you can also make use of the logical operators | (OR) and &amp; (AND). If you would want to rewrite the condition above in such a way (which would be inefficient, but I demonstrate it here for educational purposes :)), you would get bigger_than_3 = (my_3d_array &gt; 3) | (my_3d_array == 3). With the arrays that have been loaded in, there aren’t too many possibilities, but with arrays that contain for example, names or capitals, the possibilities could be endless! When it comes to fancy indexing, that what you basically do with it is the following: you pass a list or an array of integers to specify the order of the subset of rows you want to select out of the original array. # Select elements at (1,0), (0,1), (1,2) and (0,0) print(my_2d_array[[1, 0, 1, 0],[0, 1, 2, 0]]) [5 2 7 1] # Select a subset of the rows and columns print(my_2d_array[[1, 0, 1, 0]][:,[0,1,2,0]]) [[5 6 7 5] [1 2 3 1] [5 6 7 5] [1 2 3 1]] Now, the second statement might seem to make less sense to you at first sight. This is normal. It might make more sense if you break it down: If you just execute my_2d_array[[1,0,1,0]], the result is the following: my_2d_array[[1,0,1,0]] array([[5, 6, 7, 8], [1, 2, 3, 4], [5, 6, 7, 8], [1, 2, 3, 4]]) What the second part, namely, [:,[0,1,2,0]], is tell you that you want to keep all the rows of this result, but that you want to change the order of the columns around a bit. You want to display the columns 0, 1, and 2 as they are right now, but you want to repeat column 0 as the last column instead of displaying column number 3. This will give you the following result: my_2d_array[:,[0,1,2,0]] array([[ 1, 2, 3, 1], [ 5, 6, 7, 5], [ 9, 10, 11, 9]]) How To Manipulate Arrays Performing mathematical operations on your arrays is one of the things that you’ll be doing, but probably most importantly to make this and the broadcasting work is to know how to manipulate your arrays. Below are some of the most common manipulations that you’ll be doing. How To Transpose Your Arrays What transposing your arrays actually does is permuting the dimensions of it. Or, in other words, you switch around the shape of the array. Let’s take a small example to show you the effect of transposition: # Print `my_2d_array` print(my_2d_array) [[ 1 2 3 4] [ 5 6 7 8] [ 9 10 11 12]] # Transpose `my_2d_array` print(np.transpose(my_2d_array)) [[ 1 5 9] [ 2 6 10] [ 3 7 11] [ 4 8 12]] # Or use `T` to transpose `my_2d_array` print(my_2d_array.T) [[ 1 5 9] [ 2 6 10] [ 3 7 11] [ 4 8 12]] Reshaping Versus Resizing Your Arrays You might have read in the broadcasting section that the dimensions of your arrays need to be compatible if you want them to be good candidates for arithmetic operations. But the question of what you should do when that is not the case, was not answered yet. Well, this is where you get the answer! What you can do if the arrays don’t have the same dimensions, is resize your array. You will then return a new array that has the shape that you passed to the np.resize() function. If you pass your original array together with the new dimensions, and if that new array is larger than the one that you originally had, the new array will be filled with copies of the original array that are repeated as many times as is needed. However, if you just apply np.resize() to the array and you pass the new shape to it, the new array will be filled with zeros. # Print the shape of `x` print(x.shape) print(x) (3, 4) [[1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.]] # Resize `x` to ((6,4)) np.resize(x, (4, 3)) array([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) np.resize(x, (3, 4)) array([[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]) Besides resizing, you can also reshape your array. This means that you give a new shape to an array without changing its data. The key to reshaping is to make sure that the total size of the new array is unchanged. If you take the example of array x that was used above, which has a size of 3 X 4 or 12, you have to make sure that the new array also has a size of 12. If you want to calculate the size of an array with code, make sure to use the size attribute: x.size or x.reshape((2,6)).size: # Print the size of `x` to see what&#39;s possible print(x.size) 12 # Flatten `x` z = x.ravel() # Print `z` print(z) [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] If all else fails, you can also append an array to your original one or insert or delete array elements to make sure that your dimensions fit with the other array that you want to use for your computations. Another operation that you might keep handy when you’re changing the shape of arrays is ravel(). This function allows you to flatten your arrays. This means that if you ever have 2D, 3D or n-D arrays, you can just use this function to flatten it all out to a 1-D array. How To Append Arrays When you append arrays to your original array, they are “glued” to the end of that original array. If you want to make sure that what you append does not come at the end of the array, you might consider inserting it. Go to the next section if you want to know more. Appending is a pretty easy thing to do thanks to the NumPy library; You can just make use of the np.append(). # Append a 1D array to your `my_array` new_array = np.append(my_array, [7, 8, 9, 10, 11, 12]) # Print `new_array` print(my_array) print(new_array) [[1 2 3 4] [5 6 7 8]] [ 1 2 3 4 5 6 7 8 7 8 9 10 11 12] # Append an extra column to your `my_2d_array` new_2d_array = np.append(my_2d_array, [[7], [8], [9]], axis=1) # Print `new_2d_array` print(new_2d_array) [[ 1 2 3 4 7] [ 5 6 7 8 8] [ 9 10 11 12 9]] Note how, when you append an extra column to my_2d_array, the axis is specified. Remember that axis 1 indicates the columns, while axis 0 indicates the rows in 2-D arrays. How To Insert And Delete Array Elements Next to appending, you can also insert and delete array elements. As you might have guessed by now, the functions that will allow you to do these operations are np.insert() and np.delete(): # Insert `5` at index 1 np.insert(my_array, 1, 5) array([1, 5, 2, 3, 4, 5, 6, 7, 8], dtype=int32) # Delete the value at index 1 # np.delete(my_array,[1]) How To Join And Split Arrays You can also ‘merge’ or join your arrays. There are a bunch of functions that you can use for that purpose and most of them are listed below. Try them out, but also make sure to test out what the shape of the arrays is in the IPython shell. The arrays that have been loaded are x, my_array, my_resized_array and my_2d_array. # Concatentate `my_array` and `x` print(np.concatenate((my_array, x))) [[1. 2. 3. 4.] [5. 6. 7. 8.] [1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.]] # Stack arrays row-wise print(np.vstack((my_array, my_2d_array))) [[ 1 2 3 4] [ 5 6 7 8] [ 1 2 3 4] [ 5 6 7 8] [ 9 10 11 12]] my_resized_array = np.array([[91, 92, 93, 94], [91, 92, 93, 94], [91, 92, 93, 94]]) print(my_resized_array) [[91 92 93 94] [91 92 93 94] [91 92 93 94]] # Stack arrays row-wise print(np.r_[my_resized_array, my_2d_array]) [[91 92 93 94] [91 92 93 94] [91 92 93 94] [ 1 2 3 4] [ 5 6 7 8] [ 9 10 11 12]] # Stack arrays horizontally print(np.hstack((my_resized_array, my_2d_array))) [[91 92 93 94 1 2 3 4] [91 92 93 94 5 6 7 8] [91 92 93 94 9 10 11 12]] # Stack arrays column-wise print(np.column_stack((my_resized_array, my_2d_array))) [[91 92 93 94 1 2 3 4] [91 92 93 94 5 6 7 8] [91 92 93 94 9 10 11 12]] # Stack arrays column-wise print(np.c_[my_resized_array, my_2d_array]) [[91 92 93 94 1 2 3 4] [91 92 93 94 5 6 7 8] [91 92 93 94 9 10 11 12]] You’ll note a few things as you go through the functions: The number of dimensions needs to be the same if you want to concatenate two arrays with np.concatenate(). As such, if you want to concatenate an array with my_array, which is 1-D, you’ll need to make sure that the second array that you have, is also 1-D. With np.vstack(), you effortlessly combine my_array with my_2d_array. You just have to make sure that, as you’re stacking the arrays row-wise, that the number of columns in both arrays is the same. As such, you could also add an array with shape (2,4) or (3,4) to my_2d_array, as long as the number of columns matches. Stated differently, the arrays must have the same shape along all but the first axis. The same holds also for when you want to use np.r[]. For np.hstack(), you have to make sure that the number of dimensions is the same and that the number of rows in both arrays is the same. That means that you could stack arrays such as (2,3) or (2,4) to my_2d_array, which itself as a shape of (2,4). Anything is possible as long as you make sure that the number of rows matches. This function is still supported by NumPy, but you should prefer np.concatenate() or np.stack(). With np.column_stack(), you have to make sure that the arrays that you input have the same first dimension. In this case, both shapes are the same, but if my_resized_array were to be (2,1) or (2,), the arrays still would have been stacked. np.c_[] is another way to concatenate. Here also, the first dimension of both arrays needs to match. When you have joined arrays, you might also want to split them at some point. Just like you can stack them horizontally, you can also do the same but then vertically. You use np.hsplit() and np.vsplit(), respectively: my_stacked_array = np.r_[my_resized_array, my_2d_array] # Split `my_stacked_array` horizontally at the 2nd index print(np.hsplit(my_stacked_array, 2)) [array([[91, 92], [91, 92], [91, 92], [ 1, 2], [ 5, 6], [ 9, 10]]), array([[93, 94], [93, 94], [93, 94], [ 3, 4], [ 7, 8], [11, 12]])] # Split `my_stacked_array` vertically at the 2nd index print(np.vsplit(my_stacked_array, 2)) [array([[91, 92, 93, 94], [91, 92, 93, 94], [91, 92, 93, 94]]), array([[ 1, 2, 3, 4], [ 5, 6, 7, 8], [ 9, 10, 11, 12]])] What you need to keep in mind when you’re using both of these split functions is probably the shape of your array. Let’s take the above case as an example: my_stacked_array has a shape of (2,8). If you want to select the index at which you want the split to occur, you have to keep the shape in mind. How To Visualize NumPy Arrays Lastly, something that will definitely come in handy is to know how you can plot your arrays. This can especially be handy in data exploration, but also in later stages of the data science workflow, when you want to visualize your arrays. With np.histogram() Contrary to what the function might suggest, the np.histogram() function doesn’t draw the histogram but it does compute the occurrences of the array that fall within each bin; This will determine the area that each bar of your histogram takes up. What you pass to the np.histogram() function then is first the input data or the array that you’re working with. The array will be flattened when the histogram is computed. # Initialize your array my_3d_array = np.array([[[1,2,3,4], [5,6,7,8]], [[1,2,3,4], [9,10,11,12]]], dtype=np.int64) # Pass the array to `np.histogram()` print(np.histogram(my_3d_array)) (array([4, 2, 2, 1, 1, 1, 1, 1, 1, 2]), array([ 1. , 2.1, 3.2, 4.3, 5.4, 6.5, 7.6, 8.7, 9.8, 10.9, 12. ])) # Specify the number of bins print(np.histogram(my_3d_array, bins=range(0,13))) (array([0, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2]), array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])) You’ll see that as a result, the histogram will be computed: the first array lists the frequencies for all the elements of your array, while the second array lists the bins that would be used if you don’t specify any bins. If you do specify a number of bins, the result of the computation will be different: the floats will be gone and you’ll see all integers for the bins. There are still some other arguments that you can specify that can influence the histogram that is computed. You can find all of them here. But what is the point of computing such a histogram if you can’t visualize it? Visualization is a piece of cake with the help of Matplotlib, but you don’t need np.histogram() to compute the histogram. plt.hist() does this for itself when you pass it the (flattened) data and the bins: # Import numpy and matplotlib import numpy as np import matplotlib.pyplot as plt # Construct the histogram with a flattened 3d array and a range of bins plt.hist(my_3d_array.ravel(), bins=range(0,13)) # Add a title to the plot plt.title(&#39;Frequency of My 3D Array Elements&#39;) # Show the plot plt.show() Using np.meshgrid() Another way to (indirectly) visualize your array is by using np.meshgrid(). The problem that you face with arrays is that you need 2-D arrays of x and y coordinate values. With the above function, you can create a rectangular grid out of an array of x values and an array of y values: the np.meshgrid() function takes two 1D arrays and produces two 2D matrices corresponding to all pairs of (x, y) in the two arrays. Then, you can use these matrices to make all sorts of plots. np.meshgrid() is particularly useful if you want to evaluate functions on a grid, as the code below demonstrates: # Import NumPy and Matplotlib import numpy as np import matplotlib.pyplot as plt # Create an array points = np.arange(-5, 5, 0.01) # Make a meshgrid xs, ys = np.meshgrid(points, points) z = np.sqrt(xs ** 2 + ys ** 2) # Display the image on the axes plt.imshow(z, cmap=plt.cm.gray) # Draw a color bar plt.colorbar() # Show the plot plt.show()",
    "url": "http://localhost:4000/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth/01%20-%20NumPy%20Introduction.html",
    "relUrl": "/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth/01%20-%20NumPy%20Introduction.html"
  },
  "4": {
    "id": "4",
    "title": "01.a - File Processing",
    "content": "Files Python File I/O Open Files f = open(&#39;file.txt&#39;) Python File Modes Mode Description ‘r’ Open a file for reading. (default) ‘w’ Open a file for writing. Creates a new file if it does not exist or truncates the file if it exists. ‘x’ Open a file for exclusive creation. If the file already exists, the operation fails. ‘a’ Open for appending at the end of the file without truncating it. Creates a new file if it does not exist. ‘t’ Open in text mode. (default) ‘b’ Open in binary mode. ’+’ Open a file for updating (reading and writing) f = open(&quot;test.txt&quot;) # equivalent to &#39;r&#39; or &#39;rt&#39; f = open(&quot;test.txt&quot;, &#39;w&#39;) # write in text mode f = open(&quot;python.png&quot;,&#39;r+b&#39;) # read and write in binary mode File Encodings Unlike other languages, the character ‘a’ does not imply the number 97 until it is encoded using ASCII (or other equivalent encodings). The default encoding is platform dependent. In Windows it is ‘cp1252’ In Linux it is ‘utf-8’ You cannot rely on the default encoding or else our code will behave differently in different platforms. It is highly recommended to specify the encoding type when working with text files. f = open(&quot;file.txt&quot;, mode=&#39;r&#39;, encoding=&#39;utf-8&#39;) Closing Files f = open(&quot;file.txt&quot;, encoding=&#39;utf-8&#39;) # perform file operations f.close() In the last example exceptions could crash your program. Exception handlig is a topic in itself, but here we’ll simply wrap the code in a try…catch block. Now the file handle will be closed regardless of whether or not there was an exception. In the example above, an exeption might result in the file remaining open (and potentially locked) from other applications in the event of an exception. try: f = open(&quot;file.txt&quot;,encoding = &#39;utf-8&#39;) # perform file operations finally: f.close() Using with The best way to ensure that you close your files when the code block terminates is by using the with statement. When using the with statement you do not have to explicitly call the file’s close() method. with open(&#39;file.txt&#39;) as f: text = f.read() print(text) # f.close() # not necessary hello class python is fun let&#39;s get started Writing Files with open(&quot;file.txt&quot;, &#39;w&#39;, encoding=&#39;utf-8&#39;) as f: print(type(f)) f.write(&quot;hello class n&quot; ) f.write(&quot;python is fun n n&quot;) f.write(&quot;let&#39;s get started n&quot;) &lt;class &#39;_io.TextIOWrapper&#39;&gt; Reading Files f = open(&quot;file.txt&quot;, &#39;r&#39;, encoding=&#39;utf-8&#39;) print(&#39;1:&#39;, f.read(3)) # read the 1st 3 characters print(&#39;2:&#39;, f.read(3)) # read the next 3 characters print(&#39;3:&#39;, f.read()) # read until the end print(&#39;4:&#39;, f.read()) # return&#39;s an empty string 1: hel 2: lo 3: class python is fun let&#39;s get started 4: f.tell() # get the current file position 45 f.seek(0) # bring file cursor to initial position 0 f.read() # read the entire file &quot;hello class npython is fun n nlet&#39;s get started n&quot; f.seek(0) # reset the cursor 0 # read line by line for line in f: print(line, end=&#39;&#39;) hello class python is fun let&#39;s get started f.seek(0) # reset the cursor 0 # read line by line f.readline() &#39;hello class n&#39; f.readline() &#39;python is fun n&#39; f.readline() &#39; n&#39; line = f.readline() print(type(line), line) &lt;class &#39;str&#39;&gt; let&#39;s get started f.readline() &#39;&#39; f.seek(0) # reset the cursor 0 # read all lines at once f.readlines() [&#39;hello class n&#39;, &#39;python is fun n&#39;, &#39; n&#39;, &quot;let&#39;s get started n&quot;] Some Notes on Printing print(&#39;abcd&#39;) print(&#39;efgh&#39;) abcd efgh print(&#39;abcd&#39;, end=&#39;&#39;) print(&#39;efgh&#39;) abcdefgh text = &#39; abcd &#39; print(text, end=&#39;&#39;) print(text) abcd abcd text = &#39; abcd &#39; text = text.strip() print(text, end=&#39;&#39;) print(text) abcdabcd print? print(&#39;abc&#39;, &#39;def&#39;, &#39;xyz&#39;, sep=&#39;,&#39;) abc,def,xyz",
    "url": "http://localhost:4000/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/01.a%20-%20File%20Processing.html",
    "relUrl": "/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/01.a%20-%20File%20Processing.html"
  },
  "5": {
    "id": "5",
    "title": "01.a - Getting Data from Web Pages",
    "content": "Webscraping with BeautifulSoup Source Additional References https://css-tricks.com/how-css-selectors-work/ https://scrapy.org/ https://www.seleniumhq.org/ https://automatetheboringstuff.com/chapter11/ Lets Scrape the wall of shame from the U.S. Department of Health and Human Services Office for Civil Rights (You could just download the data file, but where is the fun in that!) Step 1 - Import all of the libraries you’ll need requests pandas numpy matplotlib.pyplot Beautiful Soup import requests, pandas, numpy, matplotlib.pyplot from bs4 import BeautifulSoup Step 2 - Download the data 2.a Use the requests library to grab the content of this page https://ocrportal.hhs.gov/ocr/breach/breach_report.jsf page = requests.get(&quot;https://ocrportal.hhs.gov/ocr/breach/breach_report.jsf&quot;) page.content.decode(&#39;utf-8&#39;)[:1000] &#39;&lt;!DOCTYPE html&gt; n&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; xml:lang=&quot;en&quot; lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&lt;head id=&quot;j_idt2&quot;&gt; n t t t&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=9&quot; /&gt;&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;/ocr/javax.faces.resource/theme.css.jsf?ln=primefaces-aristo&quot; /&gt;&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;/ocr/javax.faces.resource/components.css.jsf;jsessionid=EE6706ED5CF081A68BBC83244A33344F?ln=primefaces&amp;amp;v=6.1&quot; /&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;/ocr/javax.faces.resource/jquery/jquery.js.jsf;jsessionid=EE6706ED5CF081A68BBC83244A33344F?ln=primefaces&amp;amp;v=6.1&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;/ocr/javax.faces.resource/jquery/jquery-plugins.js.jsf;jsessionid=EE6706ED5CF081A68BBC83244A33344F?ln=primefaces&amp;amp;v=6.1&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;/ocr/javax.faces.resource/core.js.jsf;jsessionid=EE6706ED5CF081A68BBC83244A33344F?ln=primefaces&amp;amp;v=6.1&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;/ocr/javax.faces.resource/components.js.jsf;j&#39; 2.b Check thte status code of the page and print it to the screen page.status_code 200 Step 3 - BeautifulSoup 3.a Load the page content into a BeautifulSoup object named soup soup = BeautifulSoup(page.content, &#39;html.parser&#39;) 3.b Display the soup object to visually interrogate print(type(soup), &#39; n&#39;, soup) &lt;class &#39;bs4.BeautifulSoup&#39;&gt; &lt;!DOCTYPE html&gt; &lt;html dir=&quot;ltr&quot; lang=&quot;en&quot; xml:lang=&quot;en&quot; xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;&lt;head id=&quot;j_idt2&quot;&gt; &lt;meta content=&quot;IE=9&quot; http-equiv=&quot;X-UA-Compatible&quot;/&gt;&lt;link href=&quot;/ocr/javax.faces.resource/theme.css.jsf?ln=primefaces-aristo&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt;&lt;link href=&quot;/ocr/javax.faces.resource/components.css.jsf;jsessionid=EE6706ED5CF081A68BBC83244A33344F?ln=primefaces&amp;amp;v=6.1&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt;&lt;script src=&quot;/ocr/javax.faces.resource/jquery/jquery.js.jsf;jsessionid=EE6706ED5CF081A68BBC83244A33344F?ln=primefaces&amp;amp;v=6.1&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;&lt;script src=&quot;/ocr/javax.faces.resource/jquery/jquery-plugins.js.jsf;jsessionid=EE6706ED5CF081A68BBC83244A33344F?ln=primefaces&amp;amp;v=6.1&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;&lt;script src=&quot;/ocr/javax.faces.resource/core.js.jsf;jsessionid=EE6706ED5CF081A68BBC83244A33344F?ln=primefaces&amp;amp;v=6.1&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;&lt;script src=&quot;/ocr/javax.faces.resource/components.js.jsf;jsessionid=EE6706ED5CF081A68BBC83244A33344F?ln=primefaces&amp;amp;v=6.1&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt;if(window.PrimeFaces){PrimeFaces.settings.locale=&#39;en&#39;;}&lt;/script&gt; &lt;meta content=&quot;text/html; charset=utf-8&quot; http-equiv=&quot;Content-Type&quot;/&gt; &lt;title&gt;U.S. Department of Health &amp;amp; Human Services - Office for Civil Rights&lt;/title&gt; &lt;link href=&quot;/ocr/images/favicon.ico&quot; rel=&quot;Shortcut Icon&quot; type=&quot;image/x-icon&quot;/&gt; &lt;link href=&quot;/ocr/css/ocr-portal.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt; &lt;link href=&quot;/ocr/css/navigation_ocr.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt; &lt;link href=&quot;/ocr/css/primary.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt; &lt;link href=&quot;/ocr/css/skip.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt; &lt;link href=&quot;/ocr/css/headerNavigation.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt; &lt;link href=&quot;/ocr/css/content.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt; &lt;link href=&quot;/ocr/css/breach.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt; &lt;script src=&quot;/ocr/js/util.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/ocr/js/locale.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; &lt;script src=&quot;/ocr/js/ocr-portal.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=&quot;top&quot;&gt;&lt;/div&gt; &lt;div id=&quot;container&quot;&gt; &lt;form action=&quot;/ocr/breach/breach_report.jsf;jsessionid=EE6706ED5CF081A68BBC83244A33344F&quot; enctype=&quot;application/x-www-form-urlencoded&quot; id=&quot;headerNavigation&quot; method=&quot;post&quot; name=&quot;headerNavigation&quot;&gt; &lt;input name=&quot;headerNavigation&quot; type=&quot;hidden&quot; value=&quot;headerNavigation&quot;/&gt; &lt;div class=&quot;&quot; id=&quot;skip&quot;&gt; &lt;ul id=&quot;skiplinks&quot;&gt; &lt;li&gt;&lt;a href=&quot;#bodyContent&quot; tabindex=&quot;0&quot; title=&quot;Skip&quot;&gt;Skip to content&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div id=&quot;level1&quot;&gt; &lt;div class=&quot;header&quot;&gt; &lt;div id=&quot;navigationNew&quot;&gt; &lt;div class=&quot;site-controls-greybar&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;28&quot; src=&quot;/ocr/images/cap_left_dkgrey_systemutil.gif;jsessionid=EE6706ED5CF081A68BBC83244A33344F&quot; style=&quot;border: 0; vertical-align: middle&quot; width=&quot;19&quot;/&gt;&lt;script src=&quot;/ocr/javax.faces.resource/jsf.js.jsf;jsessionid=EE6706ED5CF081A68BBC83244A33344F?ln=javax.faces&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;&lt;a class=&quot;headerLink&quot; href=&quot;#&quot; onclick=&quot;mojarra.jsfcljs(document.getElementById(&#39;headerNavigation&#39;),{&#39;headerNavigation:j_idt9&#39;:&#39;headerNavigation:j_idt9&#39;},&#39;&#39;);return false&quot;&gt;File a Breach&lt;/a&gt; | &lt;a class=&quot;headerLink&quot; href=&quot;http://www.hhs.gov&quot;&gt;HHS&lt;/a&gt; | &lt;a class=&quot;headerLink&quot; href=&quot;http://www.hhs.gov/ocr/office/index.html&quot;&gt;Office for Civil Rights&lt;/a&gt; | &lt;a class=&quot;headerLink&quot; href=&quot;https://www.hhs.gov/ocr/about-us/contact-us/index.html&quot;&gt;Contact Us&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;site-controls-greybar-lt&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;28&quot; src=&quot;/ocr/images/back_left_ltgrey_systemutil_sm.gif;jsessionid=EE6706ED5CF081A68BBC83244A33344F&quot; style=&quot;border: 0; vertical-align: middle&quot; width=&quot;25&quot;/&gt; &lt;div class=&quot;site-controls-greybar-lt-bkgrnd&quot;&gt;&lt;img alt=&quot;&quot; height=&quot;28&quot; src=&quot;/ocr/images/clear.gif;jsessionid=EE6706ED5CF081A68BBC83244A33344F&quot; style=&quot;border: 0; vertical-align: middle&quot; width=&quot;1&quot;/&gt; &lt;img align=&quot;absmiddle&quot; alt=&quot;user icon&quot; border=&quot;0&quot; class=&quot;sc-icon&quot; height=&quot;16&quot; src=&quot;/ocr/images/icons/icon_user.gif&quot; title=&quot;Welcome&quot; width=&quot;16&quot;/&gt; Welcome &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;h1 class=&quot;h1&quot; id=&quot;header-logo&quot;&gt; &lt;div id=&quot;titleContent&quot;&gt; U.S. Department of Health and Human Services&lt;br/&gt; Office for Civil Rights&lt;br/&gt; &lt;div class=&quot;titleDivider&quot;&gt;&lt;/div&gt; Breach Portal: Notice to the Secretary of HHS Breach of Unsecured Protected Health Information &lt;/div&gt; &lt;/h1&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=&quot;bannerSection&quot;&gt; &lt;div id=&quot;bannerImageWrapper&quot;&gt; &lt;img alt=&quot;Person sitting at a laptop&quot; class=&quot;bannerImage&quot; height=&quot;100&quot; src=&quot;/ocr/images/1680x100sittingAtComputer2.jpg&quot; width=&quot;1680&quot;/&gt; &lt;/div&gt; &lt;/div&gt;&lt;input autocomplete=&quot;off&quot; id=&quot;j_id1:javax.faces.ViewState:0&quot; name=&quot;javax.faces.ViewState&quot; type=&quot;hidden&quot; value=&quot;-1375118855781670739:3296133768900446413&quot;/&gt; &lt;/form&gt; &lt;div class=&quot;divider&quot;&gt;&lt;/div&gt; &lt;div id=&quot;mainContent&quot;&gt; &lt;div class=&quot;pageInstructions&quot;&gt; &lt;a name=&quot;bodyContent&quot;&gt;&lt;/a&gt;&lt;div aria-live=&quot;polite&quot; class=&quot;ui-messages ui-widget&quot; id=&quot;ocrMessage&quot;&gt;&lt;/div&gt; &lt;div class=&quot;content&quot;&gt; &lt;form action=&quot;/ocr/breach/breach_report.jsf;jsessionid=EE6706ED5CF081A68BBC83244A33344F&quot; enctype=&quot;multipart/form-data&quot; id=&quot;ocrForm&quot; method=&quot;post&quot; name=&quot;ocrForm&quot;&gt; &lt;input name=&quot;ocrForm&quot; type=&quot;hidden&quot; value=&quot;ocrForm&quot;/&gt; &lt;script&gt; function doArchiveButtonClicked() { setTimeout( &quot;PF(&#39;archiveRptButton&#39;).disable()&quot;, 100 ); PF(&#39;waitDlgVar&#39;).show(); return true; } function doUnderInvButtonClicked() { setTimeout( &quot;PF(&#39;underInvRptButton&#39;).disable()&quot;, 100 ); PF(&#39;waitDlgVar&#39;).show(); return true; } &lt;/script&gt;&lt;div class=&quot;ui-panel ui-widget ui-widget-content ui-corner-all banner&quot; data-widget=&quot;widget_ocrForm_j_idt22&quot; id=&quot;ocrForm:j_idt22&quot;&gt;&lt;div class=&quot;ui-panel-content ui-widget-content&quot; id=&quot;ocrForm:j_idt22_content&quot;&gt;&lt;button class=&quot;ui-button ui-widget ui-state-default ui-corner-all ui-button-text-only&quot; id=&quot;ocrForm:j_idt23&quot; name=&quot;ocrForm:j_idt23&quot; onclick=&quot;PrimeFaces.bcn(this,event,[function(event){return doUnderInvButtonClicked();},function(event){PrimeFaces.onPost();}]);&quot; type=&quot;submit&quot;&gt;&lt;span class=&quot;ui-button-text ui-c&quot;&gt;Under Investigation&lt;/span&gt;&lt;/button&gt;&lt;script id=&quot;ocrForm:j_idt23_s&quot; type=&quot;text/javascript&quot;&gt;PrimeFaces.cw(&quot;CommandButton&quot;,&quot;underInvRptButton&quot;,{id:&quot;ocrForm:j_idt23&quot;});&lt;/script&gt;&lt;button class=&quot;ui-button ui-widget ui-state-default ui-corner-all ui-button-text-only&quot; id=&quot;ocrForm:j_idt24&quot; name=&quot;ocrForm:j_idt24&quot; onclick=&quot;PrimeFaces.bcn(this,event,[function(event){return doArchiveButtonClicked();},function(event){PrimeFaces.onPost();}]);&quot; type=&quot;submit&quot;&gt;&lt;span class=&quot;ui-button-text ui-c&quot;&gt;Archive&lt;/span&gt;&lt;/button&gt;&lt;script id=&quot;ocrForm:j_idt24_s&quot; type=&quot;text/javascript&quot;&gt;PrimeFaces.cw(&quot;CommandButton&quot;,&quot;archiveRptButton&quot;,{id:&quot;ocrForm:j_idt24&quot;});&lt;/script&gt;&lt;button class=&quot;ui-button ui-widget ui-state-default ui-corner-all ui-button-text-only&quot; id=&quot;ocrForm:j_idt25&quot; name=&quot;ocrForm:j_idt25&quot; onclick=&#39;PrimeFaces.ab({s:&quot;ocrForm:j_idt25&quot;,u:&quot;ocrForm:breachReports ocrForm:results&quot;});return false;&#39; type=&quot;submit&quot;&gt;&lt;span class=&quot;ui-button-text ui-c&quot;&gt;Help for Consumers&lt;/span&gt;&lt;/button&gt;&lt;script id=&quot;ocrForm:j_idt25_s&quot; type=&quot;text/javascript&quot;&gt;PrimeFaces.cw(&quot;CommandButton&quot;,&quot;widget_ocrForm_j_idt25&quot;,{id:&quot;ocrForm:j_idt25&quot;});&lt;/script&gt;&lt;/div&gt;&lt;/div&gt;&lt;script id=&quot;ocrForm:j_idt22_s&quot; type=&quot;text/javascript&quot;&gt;PrimeFaces.cw(&quot;Panel&quot;,&quot;widget_ocrForm_j_idt22&quot;,{id:&quot;ocrForm:j_idt22&quot;});&lt;/script&gt;&lt;br/&gt;&lt;br/&gt;&lt;span id=&quot;ocrForm:breachReports&quot;&gt;&lt;span id=&quot;ocrForm:underInvestigationFilterPanel&quot; style=&quot;margin-bottom:10px;&quot;&gt; &lt;style&gt; /* Calendar widget&#39;s size is too big. Limit it. */ div.ui-datepicker{ font-size:0.9em; } &lt;/style&gt; &lt;script&gt; function applyFilterButtonClicked() { setTimeout( &quot;PF(&#39;applyFilterButton&#39;).disable()&quot;, 100 ); PF(&#39;waitDlgVar&#39;).show(); return true; } &lt;/script&gt;&lt;table class=&quot;ui-panelgrid ui-widget noBorders&quot; id=&quot;ocrForm:j_idt29&quot; role=&quot;grid&quot;&gt;&lt;tbody&gt;&lt;tr class=&quot;ui-widget-content ui-panelgrid-even&quot; role=&quot;row&quot;&gt;&lt;td class=&quot;ui-panelgrid-cell&quot; colspan=&quot;4&quot; role=&quot;gridcell&quot;&gt;As required by section 13402(e)(4) of the HITECH Act, the Secretary must post a list of breaches of unsecured protected health information affecting 500 or more individuals. The following breaches have been reported to the Secretary: &lt;br/&gt;&lt;br/&gt;&lt;span style=&quot;font-size: 1.5em; font-weight: bold&quot;&gt;Cases Currently Under Investigation&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-panelgrid-odd&quot; role=&quot;row&quot;&gt;&lt;td class=&quot;ui-panelgrid-cell&quot; colspan=&quot;4&quot; role=&quot;gridcell&quot;&gt;This page lists all breaches reported within the last 24 months that are currently under investigation by the Office for Civil Rights.&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-panelgrid-even&quot; role=&quot;row&quot;&gt;&lt;td class=&quot;ui-panelgrid-cell&quot; colspan=&quot;4&quot; role=&quot;gridcell&quot;&gt;  &lt;a class=&quot;ui-commandlink ui-widget&quot; href=&quot;#&quot; id=&quot;ocrForm:j_idt41&quot; onclick=&#39;PrimeFaces.ab({s:&quot;ocrForm:j_idt41&quot;,p:&quot;ocrForm:j_idt41&quot;,u:&quot;ocrForm:underInvestigationAdvancedOptionsTable ocrForm:j_idt41&quot;,ps:true});return false;&#39;&gt;Show Advanced Options&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;span id=&quot;ocrForm:underInvestigationAdvancedOptionsTable&quot;&gt;&lt;/span&gt;&lt;div class=&quot;ui-dialog ui-widget ui-widget-content ui-corner-all ui-shadow ui-hidden-container&quot; id=&quot;ocrForm:waitDlgIN&quot;&gt;&lt;div class=&quot;ui-dialog-content ui-widget-content&quot;&gt;&lt;span id=&quot;ocrForm:waitDlgIN_title&quot;&gt;&lt;/span&gt;We are generating the report for you. Please wait......&lt;/div&gt;&lt;/div&gt;&lt;script id=&quot;ocrForm:waitDlgIN_s&quot; type=&quot;text/javascript&quot;&gt;$(function(){PrimeFaces.cw(&quot;Dialog&quot;,&quot;waitDlgINI&quot;,{id:&quot;ocrForm:waitDlgIN&quot;,resizable:false,modal:true});});&lt;/script&gt;&lt;/span&gt;&lt;/span&gt;&lt;span id=&quot;ocrForm:results&quot;&gt; &lt;br/&gt;&lt;span id=&quot;ocrForm:resultsPanel&quot; style=&quot;margin-bottom:10px;&quot;&gt; &lt;style&gt; .column1{width: 20%} .column2{width: 80%} &lt;/style&gt;&lt;span style=&quot;float: right&quot;&gt;&lt;a href=&quot;#&quot; onclick=&quot;mojarra.jsfcljs(document.getElementById(&#39;ocrForm&#39;),{&#39;ocrForm:j_idt360&#39;:&#39;ocrForm:j_idt360&#39;},&#39;&#39;);return false&quot;&gt;&lt;img alt=&quot;Excel&quot; id=&quot;ocrForm:j_idt361&quot; src=&quot;/ocr/images/icons/excel.png;jsessionid=EE6706ED5CF081A68BBC83244A33344F?pfdrid_c=true&quot; style=&quot;border-style: none&quot; title=&quot;Export as Excel&quot; width=&quot;24&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;#&quot; onclick=&quot;mojarra.jsfcljs(document.getElementById(&#39;ocrForm&#39;),{&#39;ocrForm:j_idt362&#39;:&#39;ocrForm:j_idt362&#39;},&#39;&#39;);return false&quot;&gt;&lt;img alt=&quot;PDF&quot; id=&quot;ocrForm:j_idt363&quot; src=&quot;/ocr/images/icons/pdf.png;jsessionid=EE6706ED5CF081A68BBC83244A33344F?pfdrid_c=true&quot; style=&quot;border-style: none&quot; title=&quot;Export as PDF&quot; width=&quot;24&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;#&quot; onclick=&quot;mojarra.jsfcljs(document.getElementById(&#39;ocrForm&#39;),{&#39;ocrForm:j_idt364&#39;:&#39;ocrForm:j_idt364&#39;},&#39;&#39;);return false&quot;&gt;&lt;img alt=&quot;CSV&quot; id=&quot;ocrForm:j_idt365&quot; src=&quot;/ocr/images/icons/csv.png;jsessionid=EE6706ED5CF081A68BBC83244A33344F?pfdrid_c=true&quot; style=&quot;border-style: none&quot; title=&quot;Export as CSV&quot; width=&quot;24&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;#&quot; onclick=&quot;mojarra.jsfcljs(document.getElementById(&#39;ocrForm&#39;),{&#39;ocrForm:j_idt366&#39;:&#39;ocrForm:j_idt366&#39;},&#39;&#39;);return false&quot;&gt;&lt;img alt=&quot;XML&quot; id=&quot;ocrForm:j_idt367&quot; src=&quot;/ocr/images/icons/xml.png;jsessionid=EE6706ED5CF081A68BBC83244A33344F?pfdrid_c=true&quot; style=&quot;border-style: none&quot; title=&quot;Export as XML&quot; width=&quot;24&quot;/&gt;&lt;/a&gt;&lt;/span&gt;&lt;div class=&quot;ui-datatable ui-widget&quot; id=&quot;ocrForm:reportResultTable&quot; style=&quot;margin-bottom:20px&quot;&gt;&lt;div class=&quot;ui-datatable-header ui-widget-header ui-corner-top&quot;&gt; Breach Report Results &lt;/div&gt;&lt;div class=&quot;ui-datatable-tablewrapper&quot;&gt;&lt;table role=&quot;grid&quot; style=&quot;table-layout: auto;&quot;&gt;&lt;caption class=&quot;ui-helper-hidden-accessible&quot;&gt;&lt;/caption&gt;&lt;thead id=&quot;ocrForm:reportResultTable_head&quot;&gt;&lt;tr role=&quot;row&quot;&gt;&lt;th class=&quot;ui-state-default&quot; id=&quot;ocrForm:reportResultTable:j_idt369&quot; role=&quot;columnheader&quot; scope=&quot;col&quot; style=&quot;width:50px&quot;&gt;&lt;span class=&quot;ui-column-title&quot;&gt;&lt;a class=&quot;ui-commandlink ui-widget&quot; href=&quot;#&quot; id=&quot;ocrForm:reportResultTable:j_idt370&quot; onclick=&#39;PrimeFaces.ab({s:&quot;ocrForm:reportResultTable:j_idt370&quot;,u:&quot;ocrForm:reportResultTable:j_idt370 ocrForm:reportResultTable&quot;});return false;&#39;&gt;Expand All&lt;/a&gt;&lt;/span&gt;&lt;/th&gt;&lt;th aria-label=&quot;Name of Covered Entity&quot; class=&quot;ui-state-default ui-sortable-column&quot; id=&quot;ocrForm:reportResultTable:j_idt372&quot; role=&quot;columnheader&quot; scope=&quot;col&quot;&gt;&lt;span class=&quot;ui-column-title&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Name of Covered Entity&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;ui-sortable-column-icon ui-icon ui-icon-carat-2-n-s&quot;&gt;&lt;/span&gt;&lt;/th&gt;&lt;th aria-label=&quot;State&quot; class=&quot;ui-state-default ui-sortable-column&quot; id=&quot;ocrForm:reportResultTable:j_idt375&quot; role=&quot;columnheader&quot; scope=&quot;col&quot;&gt;&lt;span class=&quot;ui-column-title&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;State&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;ui-sortable-column-icon ui-icon ui-icon-carat-2-n-s&quot;&gt;&lt;/span&gt;&lt;/th&gt;&lt;th aria-label=&quot;Covered Entity Type&quot; class=&quot;ui-state-default ui-sortable-column&quot; id=&quot;ocrForm:reportResultTable:j_idt378&quot; role=&quot;columnheader&quot; scope=&quot;col&quot;&gt;&lt;span class=&quot;ui-column-title&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Covered Entity Type&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;ui-sortable-column-icon ui-icon ui-icon-carat-2-n-s&quot;&gt;&lt;/span&gt;&lt;/th&gt;&lt;th aria-label=&quot;Individuals Affected&quot; class=&quot;ui-state-default ui-sortable-column&quot; id=&quot;ocrForm:reportResultTable:j_idt381&quot; role=&quot;columnheader&quot; scope=&quot;col&quot;&gt;&lt;span class=&quot;ui-column-title&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Individuals Affected&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;ui-sortable-column-icon ui-icon ui-icon-carat-2-n-s&quot;&gt;&lt;/span&gt;&lt;/th&gt;&lt;th aria-label=&quot;Breach Submission Date&quot; class=&quot;ui-state-default ui-sortable-column&quot; id=&quot;ocrForm:reportResultTable:j_idt384&quot; role=&quot;columnheader&quot; scope=&quot;col&quot;&gt;&lt;span class=&quot;ui-column-title&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Breach Submission Date&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;ui-sortable-column-icon ui-icon ui-icon-carat-2-n-s&quot;&gt;&lt;/span&gt;&lt;/th&gt;&lt;th aria-label=&quot;Type of Breach&quot; class=&quot;ui-state-default&quot; id=&quot;ocrForm:reportResultTable:j_idt387&quot; role=&quot;columnheader&quot; scope=&quot;col&quot;&gt;&lt;span class=&quot;ui-column-title&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Type of Breach&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;&lt;th aria-label=&quot;Location of Breached Information&quot; class=&quot;ui-state-default&quot; id=&quot;ocrForm:reportResultTable:j_idt390&quot; role=&quot;columnheader&quot; scope=&quot;col&quot;&gt;&lt;span class=&quot;ui-column-title&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Location of Breached Information&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;&lt;th aria-label=&quot;Business Associate Present&quot; class=&quot;ui-state-default&quot; id=&quot;ocrForm:reportResultTable:j_idt396&quot; role=&quot;columnheader&quot; scope=&quot;col&quot; style=&quot;display: none&quot;&gt;&lt;span class=&quot;ui-column-title&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Business Associate Present&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;&lt;th aria-label=&quot;Web Description&quot; class=&quot;ui-state-default&quot; id=&quot;ocrForm:reportResultTable:j_idt399&quot; role=&quot;columnheader&quot; scope=&quot;col&quot; style=&quot;display: none&quot;&gt;&lt;span class=&quot;ui-column-title&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Web Description&lt;/span&gt;&lt;/span&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody class=&quot;ui-datatable-data ui-widget-content&quot; id=&quot;ocrForm:reportResultTable_data&quot;&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;0&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Byham&#39;s Insurance Services Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;PA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Clearing House&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1600&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/27/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Desktop Computer, Email, Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;1&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Addison County Home Health &amp;amp; Hospice&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;VT&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;758&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/25/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;2&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Boulevard Surgical Associates&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;CA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;542&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/20/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Theft&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Paper/Films&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;3&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;EyeCare Partners, LLC [on behalf of affiliated covered entities]&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MO&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;141165&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/19/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;4&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Brenda LaTowsky, M.D., PLC&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;AZ&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1282&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/17/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Theft&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Laptop, Other Portable Electronic Device&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;5&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Community Healthlink&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;4598&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/17/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;6&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Inform Diagnostics, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TX&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;173617&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/14/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;7&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Desert Healthcare Services, LLC&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;AZ&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;8000&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/11/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;8&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Kansas City VAMC&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MO&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;534&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/11/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Paper/Films&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;9&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Sunshine State Health Plan, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;FL&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Plan&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;2000&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/07/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Other&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;10&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Kingman Healthcare Incorporated&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;AZ&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1100&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/07/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Other&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;11&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Elim Care&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MN&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;2500&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/07/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;12&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Worcester Eye Consultants&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;2634&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/07/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Loss&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Other&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;13&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;CAPITOL CARDIOLOGY ASSOCIATES&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MD&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1980&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/07/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Desktop Computer&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;14&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;SOUTHERN MARYLAND MEDICAL GROUP LLC&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MD&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1400&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/07/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Desktop Computer&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;15&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Shingle Springs Health and Wellness Center&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;CA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;21513&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/05/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;16&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Rosenbaum Dental Group&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;FL&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1200&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/04/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Desktop Computer&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;17&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Humana Inc&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;KY&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Plan&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;863&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;06/03/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;18&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Quest Systems, Inc. &lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;NY&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;28910&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/31/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;19&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;City of Georgetown Fire Department&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TX&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;719&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/31/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Loss&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Other Portable Electronic Device&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;20&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Broome County, New York&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;NY&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;7048&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/31/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;21&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Cerpassrx, LLC&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TX&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Plan&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;2513&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/31/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;22&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;The Union Labor Life Insurance Company&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MD&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Plan&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;87400&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/31/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;23&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Capital City Paincare&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;OH&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1012&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/31/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;24&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Takai, Hoover, and Hsu, P.A.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MD&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;16542&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/29/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Desktop Computer, Electronic Medical Record&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;25&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Sunshine Family Dentistry&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TX&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;800&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/27/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Theft&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;26&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Monroe County Hospital&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;GA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;10970&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/25/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;27&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Huggins Insurance Services, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;OR&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Business Associate&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;667&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/24/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;28&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Maranatha Village Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MO&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;520&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/24/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;29&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthfirst&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;NY&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Plan&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1811&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/24/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Paper/Films&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;30&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Talley Medical Surgical Eyecare Associates, PC&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;IN&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;106000&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/24/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Desktop Computer, Electronic Medical Record, Email, Laptop, Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;31&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;TriHealth Physician Practices&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;OH&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;2433&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/24/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;32&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Mercy Health Saint Mary&#39;s&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MI&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;978&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/24/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;33&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Centura Health&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;CO&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;7515&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/22/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;34&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Partington Plastic Surgery&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;WA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;9000&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/22/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Laptop&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;35&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Northwestern Health Sciences University&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MN&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1198&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/21/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;36&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hematology Oncology Associates, PC&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;OR&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;16073&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/21/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;37&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Penn Medicine&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;PA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;917&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/21/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Electronic Medical Record&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;38&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Special Health Resources for Texas, Inc. &lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TX&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;567&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/21/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Electronic Medical Record&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;39&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Acadia Montana Treatment Center&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MT&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;14794&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/17/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;40&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Aeroflow Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;NC&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;4450&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/16/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;41&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Communities Connected for Kids, Inc. &lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;FL&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Business Associate&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;501&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/15/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;42&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Aging Disability and Transit Services of Rockingham County &lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;NC&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;500&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/15/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;43&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Youth Opportunity Center, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;IN&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1150&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/14/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Paper/Films&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;44&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Net, LLC.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;CA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Plan&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;2404&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/13/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Paper/Films&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;45&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Professional Dental Alliance of Florida PLLC d/b/a All Smiles Dentistry&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;FL&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1505&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/13/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Desktop Computer, Electronic Medical Record&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;46&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Encompass Family and internal medicine group&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;CA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;26000&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/13/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Desktop Computer, Electronic Medical Record&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;47&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Memorial Hermann Health System&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TX&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;604&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/13/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Electronic Medical Record, Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;48&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Midwest Medical Center&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;IL&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;8010&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/10/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;49&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;University Medical Center Physicians&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TX&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;3300&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/10/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server, Other&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;50&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Cancer Treatment Centers of America® (CTCA) at Southeastern Regional Medical Center&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;GA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;16819&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/10/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;51&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;United Seating and Mobility LLC dba Numotion&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;CT&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;3578&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/09/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Theft&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Laptop, Other Portable Electronic Device, Paper/Films&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;52&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Bloodworks Northwest&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;WA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1893&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/08/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Loss&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Paper/Films&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;53&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Independent Health Association, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;NY&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Plan&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;7605&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/08/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;54&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Inmediata Health Group, Corp.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Clearing House&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1565338&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/07/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;55&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hospice Care Plus, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;KY&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;2000&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/06/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Laptop&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;56&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;American Indian Health &amp;amp; Services, Inc. &lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;CA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;3784&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/06/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;57&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Community Health Network, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;IN&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;3600&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/06/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;58&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;American Medical Response, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TX&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;4300&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/06/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;59&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;American Baptist Homes of the Midwest&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MN&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;10993&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/06/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email, Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;60&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Verity Health System of California, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;CA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Business Associate&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;662&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/03/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;61&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Kelsey Research Foundation&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TX&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Business Associate&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1228&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/03/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;62&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Inspira Behavioral Care, Corp&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;4246&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/02/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Theft&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Desktop Computer&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;63&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;The Southeastern Council on Alcoholism and Drug Dependence&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;CT&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;25148&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;05/01/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;64&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;AA OBGYN PLLC&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TX&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;930&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/30/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Other&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;65&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;The City of Fort Lauderdale&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;FL&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Plan&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;757&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/29/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Other&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;66&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Partners In Care&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;OR&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;3048&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/26/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;67&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Medical Oncology Hematology Consultants, PA&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;DE&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;8591&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/26/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;68&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Care Service Corporation&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;IL&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Plan&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;676&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/24/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Other Portable Electronic Device&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;69&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Logansport Memorial Hospital&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;IN&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;3568&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/23/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;70&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Doctors Management Services, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Business Associate&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;206695&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/22/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;71&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;LISA ROSE DURSO, M.D. PLLC&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;NY&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;537&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/22/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;72&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Area Agency on Aging and Disabilities of Southwest Washington&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;WA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Plan&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;7000&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/22/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;73&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;EmCare, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;FL&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;31236&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/20/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;74&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Bodybuilding.com LLC, operated by Vitalize, LLC (“Vitalize, LLC”)&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;ID&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Plan&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;3193&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/19/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;75&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;People, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;NY&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;970&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/19/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;76&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Blue Cross of Idaho Health Service, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;ID&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Plan&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;6045&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/19/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Other&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;77&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Partners For Quality, Inc. &lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;PA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;3673&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/19/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;78&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;KIM P. KORNEGAY, DMD&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;AL&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;27000&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/19/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Theft&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Desktop Computer, Electronic Medical Record, Paper/Films&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;79&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;AltaMed Health Services Corporation&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;CA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;5500&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/18/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Yes&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;80&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Pediatric Orthopedic Specialties, PA, dba ActivYouth Orthopaedics&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;NJ&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;24176&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/18/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;81&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Gary W Peer MD&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;CA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;3400&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/18/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;82&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;ELENA MARIA BURUIANA PHYSICIAN P.C.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;NY&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1308&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/18/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;83&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Madison Parish Hospital Service District&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;LA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1436&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/18/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Desktop Computer, Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;84&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Alana Healthcare&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TN&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;2691&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/18/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;85&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Center for Sight &amp;amp; Hearing&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;IL&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;5319&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/18/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;86&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Centrelake Medical Group, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;CA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;197661&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/16/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;87&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Gardner Family Health Network&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;CA&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;5064&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/16/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Paper/Films&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;88&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Tower Imaging, LLC&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;FL&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;810&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/16/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Theft&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Laptop&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;89&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Delta Dental of Illinois&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;IL&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Health Plan&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;5092&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/16/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;90&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Minnesota Eye Consultants&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MN&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;4556&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/16/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Improper Disposal&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Paper/Films&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;91&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;National Seating &amp;amp; Mobility, Inc. &lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TN&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;3800&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/15/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;92&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Metro Santurce, Inc. d/b/a Hospital Pavia Santurce and Metro Hato Rey, Inc. d/b/a Hospital Pavia Hato Rey&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;305737&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/13/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;93&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Mid-Cities Home Medical Delivery Service, LLC&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TX&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;4000&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/12/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Loss&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Paper/Films&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;94&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Harbor&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;OH&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;2290&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/12/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;95&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Questcare Medical Services, PLLC&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;TX&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;5573&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/12/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;96&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Dakota County&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MN&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;1026&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/12/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;97&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Riverplace Counseling Center, Inc.&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MN&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;11639&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/11/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Network Server&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-even&quot; data-ri=&quot;98&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Martinsburg VA Medical Center&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;WV&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;4882&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/11/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Unauthorized Access/Disclosure&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Paper/Films&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=&quot;ui-widget-content ui-datatable-odd&quot; data-ri=&quot;99&quot; role=&quot;row&quot;&gt;&lt;td role=&quot;gridcell&quot; style=&quot;width:50px&quot;&gt;&lt;div aria-expanded=&quot;false&quot; aria-label=&quot;Toggle Row&quot; class=&quot;ui-row-toggler ui-icon ui-icon-circle-triangle-e&quot; role=&quot;button&quot; tabindex=&quot;0&quot;&gt;&lt;/div&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Minnesota Department of Human Services&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;MN&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Healthcare Provider&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;10263&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;04/09/2019&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Hacking/IT Incident&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;Email&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;No&lt;/span&gt;&lt;/td&gt;&lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;div aria-label=&quot;Pagination&quot; class=&quot;ui-paginator ui-paginator-bottom ui-widget-header ui-corner-bottom&quot; id=&quot;ocrForm:reportResultTable_paginator_bottom&quot; role=&quot;navigation&quot;&gt;&lt;span class=&quot;ui-paginator-current&quot;&gt;(Displaying 1 - 100 of 493)&lt;/span&gt; &lt;a aria-label=&quot;First Page&quot; class=&quot;ui-paginator-first ui-state-default ui-corner-all ui-state-disabled&quot; href=&quot;#&quot; tabindex=&quot;-1&quot;&gt;&lt;span class=&quot;ui-icon ui-icon-seek-first&quot;&gt;F&lt;/span&gt;&lt;/a&gt;&lt;a aria-label=&quot;Previous Page&quot; class=&quot;ui-paginator-prev ui-state-default ui-corner-all ui-state-disabled&quot; href=&quot;#&quot; tabindex=&quot;-1&quot;&gt;&lt;span class=&quot;ui-icon ui-icon-seek-prev&quot;&gt;P&lt;/span&gt;&lt;/a&gt;&lt;span class=&quot;ui-paginator-pages&quot;&gt;&lt;a class=&quot;ui-paginator-page ui-state-default ui-state-active ui-corner-all&quot; href=&quot;#&quot; tabindex=&quot;0&quot;&gt;1&lt;/a&gt;&lt;a class=&quot;ui-paginator-page ui-state-default ui-corner-all&quot; href=&quot;#&quot; tabindex=&quot;0&quot;&gt;2&lt;/a&gt;&lt;a class=&quot;ui-paginator-page ui-state-default ui-corner-all&quot; href=&quot;#&quot; tabindex=&quot;0&quot;&gt;3&lt;/a&gt;&lt;a class=&quot;ui-paginator-page ui-state-default ui-corner-all&quot; href=&quot;#&quot; tabindex=&quot;0&quot;&gt;4&lt;/a&gt;&lt;a class=&quot;ui-paginator-page ui-state-default ui-corner-all&quot; href=&quot;#&quot; tabindex=&quot;0&quot;&gt;5&lt;/a&gt;&lt;/span&gt;&lt;a aria-label=&quot;Next Page&quot; class=&quot;ui-paginator-next ui-state-default ui-corner-all&quot; href=&quot;#&quot; tabindex=&quot;0&quot;&gt;&lt;span class=&quot;ui-icon ui-icon-seek-next&quot;&gt;N&lt;/span&gt;&lt;/a&gt;&lt;a aria-label=&quot;Last Page&quot; class=&quot;ui-paginator-last ui-state-default ui-corner-all&quot; href=&quot;#&quot; tabindex=&quot;0&quot;&gt;&lt;span class=&quot;ui-icon ui-icon-seek-end&quot;&gt;E&lt;/span&gt;&lt;/a&gt;&lt;label class=&quot;ui-paginator-rpp-label ui-helper-hidden&quot; for=&quot;ocrForm:reportResultTable:j_id2&quot; id=&quot;ocrForm:reportResultTable_rppLabel&quot;&gt;Rows Per Page&lt;/label&gt;&lt;select aria-labelledby=&quot;ocrForm:reportResultTable_rppLabel&quot; autocomplete=&quot;off&quot; class=&quot;ui-paginator-rpp-options ui-widget ui-state-default ui-corner-left&quot; id=&quot;ocrForm:reportResultTable:j_id2&quot; name=&quot;ocrForm:reportResultTable_rppDD&quot; value=&quot;100&quot;&gt;&lt;option value=&quot;10&quot;&gt;10&lt;/option&gt;&lt;option value=&quot;20&quot;&gt;20&lt;/option&gt;&lt;option value=&quot;50&quot;&gt;50&lt;/option&gt;&lt;option selected=&quot;selected&quot; value=&quot;100&quot;&gt;100&lt;/option&gt;&lt;/select&gt;&lt;/div&gt;&lt;/div&gt;&lt;script id=&quot;ocrForm:reportResultTable_s&quot; type=&quot;text/javascript&quot;&gt;$(function(){PrimeFaces.cw(&quot;DataTable&quot;,&quot;widget_ocrForm_reportResultTable&quot;,{id:&quot;ocrForm:reportResultTable&quot;,paginator:{id:[&#39;ocrForm:reportResultTable_paginator_bottom&#39;],rows:100,rowCount:493,page:0,currentPageTemplate:&#39;(Displaying {startRecord} - {endRecord} of {totalRecords})&#39;},expansion:true,rowExpandMode:&quot;multiple&quot;,groupColumnIndexes:[],behaviors:{page:function(ext,event) {PrimeFaces.ab({s:&quot;ocrForm:reportResultTable&quot;,e:&quot;page&quot;,p:&quot;ocrForm:reportResultTable&quot;},ext);}}});});&lt;/script&gt;&lt;/span&gt;&lt;/span&gt;&lt;div class=&quot;ui-dialog ui-widget ui-widget-content ui-corner-all ui-shadow ui-hidden-container&quot; id=&quot;ocrForm:waitDlg&quot;&gt;&lt;div class=&quot;ui-dialog-content ui-widget-content&quot;&gt;&lt;span id=&quot;ocrForm:waitDlg_title&quot;&gt;&lt;/span&gt;We are generating the report for you. Please wait......&lt;/div&gt;&lt;/div&gt;&lt;script id=&quot;ocrForm:waitDlg_s&quot; type=&quot;text/javascript&quot;&gt;$(function(){PrimeFaces.cw(&quot;Dialog&quot;,&quot;waitDlgVar&quot;,{id:&quot;ocrForm:waitDlg&quot;,resizable:false,modal:true});});&lt;/script&gt;&lt;input autocomplete=&quot;off&quot; id=&quot;j_id1:javax.faces.ViewState:1&quot; name=&quot;javax.faces.ViewState&quot; type=&quot;hidden&quot; value=&quot;-1375118855781670739:3296133768900446413&quot;/&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt;  &lt;/div&gt; &lt;div id=&quot;footerNew&quot;&gt; &lt;div id=&quot;footerContent&quot;&gt; U.S. Department of Health &amp;amp; Human Services - 200 Independence Avenue, S.W. - Washington, D.C. 20201 &lt;br/&gt;&lt;span style=&quot;color : #4d4947&quot;&gt;OCR Portal CS10.5 Production Server (Port1). Build Date: 05/22/2019 22:45&lt;/span&gt; &lt;/div&gt; &lt;div id=&quot;footerPadding&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/body&gt; &lt;/html&gt; Step 4 - Parse the Breach data After inspecting the page we found that &lt;td role=&quot;gridcell&quot;&gt; usually precedes the breach records. 4.a find the gridcells and store in a variable named python gridCells = soup.find_all(role=&quot;gridcell&quot;) print(gridCells[:2]) [&lt;td class=&quot;ui-panelgrid-cell&quot; colspan=&quot;4&quot; role=&quot;gridcell&quot;&gt;As required by section 13402(e)(4) of the HITECH Act, the Secretary must post a list of breaches of unsecured protected health information affecting 500 or more individuals. The following breaches have been reported to the Secretary: &lt;br/&gt;&lt;br/&gt;&lt;span style=&quot;font-size: 1.5em; font-weight: bold&quot;&gt;Cases Currently Under Investigation&lt;/span&gt;&lt;/td&gt;, &lt;td class=&quot;ui-panelgrid-cell&quot; colspan=&quot;4&quot; role=&quot;gridcell&quot;&gt;This page lists all breaches reported within the last 24 months that are currently under investigation by the Office for Civil Rights.&lt;/td&gt;] tr = soup.find_all(&#39;tr&#39;) len(tr) 104 4.b display the gridCells to inspect gridCells[0] &lt;td class=&quot;ui-panelgrid-cell&quot; colspan=&quot;4&quot; role=&quot;gridcell&quot;&gt;As required by section 13402(e)(4) of the HITECH Act, the Secretary must post a list of breaches of unsecured protected health information affecting 500 or more individuals. The following breaches have been reported to the Secretary: &lt;br/&gt;&lt;br/&gt;&lt;span style=&quot;font-size: 1.5em; font-weight: bold&quot;&gt;Cases Currently Under Investigation&lt;/span&gt;&lt;/td&gt; gridCells[-1] &lt;td role=&quot;gridcell&quot; style=&quot;display: none&quot;&gt;&lt;span style=&quot;white-space:pre-line;&quot;&gt;&lt;/span&gt;&lt;/td&gt; We’ve decided that we want to store the contents of the breach data into lists named: singleBreachList - contains the tokenized breach data from the web page We’ll use singleBreachList to construct the following lists nameCoveredEntityList - singleBreachList item 0 stateList - singleBreachList item 1 coveredEntityTypeList - singleBreachList item 2 affectIndividualsList - singleBreachList item 3 breachSubmittedDateList - singleBreachList item 4 typeOfBreachList - singleBreachList item 5 locationOfBreachedInformationList - singleBreachList item 6 Also notice that not all of “gridcell” was breach data, we need to skip a couple lines to get to the good stuff. Use a counter to do this, specifically skipTheBoringStuffCounter There also appears to be a pattern in how the gridcell data is organized, there is a new event every 8 lines. Use a counter for that as well, specifically theGoodStuffCounter 4.c Initialize all of the lists to empty lists and the counters to zero. nameCoveredEntityList = [] stateList = [] coveredEntityTypeList = [] affectIndividualsList = [] breachSubmittedDateList = [] typeOfBreachList = [] locationOfBreachedInformationList = [] singleBreachList = [] skipTheBoringStuffCounter = 0 theGoodStuffCounter = 0 4.d Parse the Data for c in gridCells: if skipTheBoringStuffCounter &lt;= 4: skipTheBoringStuffCounter = skipTheBoringStuffCounter + 1 if skipTheBoringStuffCounter &gt; 4: c = c.get_text().strip() if c != &#39;&#39;: singleBreachList.append(c) theGoodStuffCounter = theGoodStuffCounter + 1 if theGoodStuffCounter == 8: nameCoveredEntityList.append(singleBreachList[0]) stateList.append(singleBreachList[1]) coveredEntityTypeList.append(singleBreachList[2]) affectIndividualsList.append(singleBreachList[3]) breachSubmittedDateList.append(singleBreachList[4]) typeOfBreachList.append(singleBreachList[5]) locationOfBreachedInformationList.append(singleBreachList[6]) theGoodStuffCounter = 0 singleBreachList = [] nameCoveredEntityList[0:3] [&#39;EmCare, Inc.&#39;, &#39;Partners For Quality, Inc.&#39;, &#39;AltaMed Health Services Corporation&#39;] Step 5 - Create a Dataframe and Visualize the Data # create a dataframe using the newly scraped data breachDF = pandas.DataFrame({ &quot;Company Name&quot;:nameCoveredEntityList, &quot;State&quot;:stateList, &quot;Company Type&quot;:coveredEntityTypeList, &quot;Affected Individuals&quot;:affectIndividualsList, &quot;Breach Date&quot;:breachSubmittedDateList, &quot;Breach Type&quot;:typeOfBreachList, &quot;Data location&quot;:locationOfBreachedInformationList }) breachDF.head() Company Name State Company Type Affected Individuals Breach Date Breach Type Data location 0 EmCare, Inc. FL Healthcare Provider 31236 04/20/2019 Hacking/IT Incident Email 1 Partners For Quality, Inc. PA Healthcare Provider 3673 04/19/2019 Hacking/IT Incident Email 2 AltaMed Health Services Corporation CA Healthcare Provider 5500 04/18/2019 Hacking/IT Incident Network Server 3 Gary W Peer MD CA Healthcare Provider 3400 04/18/2019 Hacking/IT Incident Network Server 4 ELENA MARIA BURUIANA PHYSICIAN P.C. NY Healthcare Provider 1308 04/18/2019 Hacking/IT Incident Network Server # group by the Breach Type breachDF.groupby(&#39;Breach Type&#39;).size() Breach Type Hacking/IT Incident 67 Improper Disposal 1 Loss 1 Theft 10 Unauthorized Access/Disclosure 21 dtype: int64 # allow matplotlib graphs to show in the notebook %matplotlib inline # group by the Breach Type breachDist = breachDF.groupby(&#39;Breach Type&#39;).size() # plot the data breachDist.plot(kind=&#39;bar&#39;) &lt;matplotlib.axes._subplots.AxesSubplot at 0x120a83fd0&gt;",
    "url": "http://localhost:4000/lectures/Week%2006%20-%20Web%20Scraping,%20Databases,%20and%20Other%20Data%20Sources/01.a%20-%20Getting%20Data%20from%20Web%20Pages.html",
    "relUrl": "/lectures/Week%2006%20-%20Web%20Scraping,%20Databases,%20and%20Other%20Data%20Sources/01.a%20-%20Getting%20Data%20from%20Web%20Pages.html"
  },
  "6": {
    "id": "6",
    "title": "01.a - Python Functions",
    "content": "Python Functions Python Function Tutorial Functions are used to encapsulate a set of relatred instructions that you want to use within your program to carry out a specific task. This helps with the organization of your code as well as code reusability. Oftent times functions accept parameters and return values, but that’s not always the case. There are three types of functions in Python: Built-in functions, such as help() to ask for help, min() to get the minimum value, print() to print an object to the terminal,… You can find an overview with more of these functions here. User-Defined Functions (UDFs), which are functions that users create to help them out; And Anonymous functions, which are also called lambda functions because they are not declared with the standard def keyword. Functions vs. Methods A method is a function that’s part of a class which we’ll discuss in another lecture. Keep in mind all methods are functions but not all functions are methods. Parameters vs. Arguments Parameters are the names used when defining a function or a method, and into which arguments will be mapped. In other words, arguments are the things which are supplied to any function or method call, while the function or method code refers to the arguments by their parameter names. Consider the function def sum(a, b): return a + b sum has 2 parameters a and b. If you call the sum function with values 2 and 3 then 2 and 3 are the arguments. Defining User Functions The four steps to defining a function in Python are the following: Use the keyword def to declare the function and follow this up with the function name. Add parameters to the function: they should be within the parentheses of the function. End your line with a colon. Add statements that the functions should execute. End your function with a return statement if the function should output something. Without the return statement, your function will return an object None. # takes no parameters, returns none def say_hello(): print(&#39;hello&#39;) x = say_hello() print(type(x), x) # takes parameters, returns none def say_something(message): print(message) x = say_something(&#39;hello class&#39;) print(type(x), x) The return Statement Sometimes it’s useful to reuturn values from functions. We’ll refactor our code to return values. def get_message(): return &#39;hello class&#39; def say_something(): message = get_message() print(message) x = get_message() print(type(x), x) say_something() print(type(say_something())) x = say_something() print(type(x), x) returning multiple values In python you can return values in a variety of data types including primitive data structures such as integers, floats, strings, &amp; booleans as well as non-primitive data structures such as arrays, lists, tuples, dictionaries, sets, and files. # returning a list def get_messages(): return [&#39;hello class&#39;, &#39;python is great&#39;, &#39;here we &#39;re retuning a list&#39;] messages = get_messages() print(type(messages), messages) for message in messages: print(type(message), message) # returning a tuple... more on tuples later def get_message(): return (&#39;hello class&#39;, 3) message = get_message() print(type(message), message) for i in range(0, message[1]): print(message[0]) def get_message(): return &#39;hello class&#39;, 3 # (&#39;s are optional message = get_message() print(type(message), message) for i in range(0, message[1]): print(message[0]) message, iterations = get_message() print(type(message), message) for i in range(0, iterations): print(message) Function Arguments in Python There are four types of arguments that Python functions can take: Default arguments Required arguments Keyword arguments Variable number of arguments Default Arguments Default arguments are those that take a default value if no argument value is passed during the function call. You can assign this default value by with the assignment operator =, just like in the following example: import random def get_random_numbers(n=1): if n == 1: return random.random() elif n &gt; 1: numbers = [] for i in range(0, n): numbers.append(random.random()) return numbers w = get_random_numbers() print(&#39;w:&#39;, type(w), w) x = get_random_numbers(1) print(&#39;x:&#39;, type(x), x) y = get_random_numbers(n=3) print(&#39;y:&#39;, type(y), y) z = get_random_numbers(n=-1) print(&#39;z:&#39;, type(z), z) w: &lt;class &#39;float&#39;&gt; 0.6141949340866538 x: &lt;class &#39;float&#39;&gt; 0.7236096904538915 y: &lt;class &#39;list&#39;&gt; [0.21366182254549937, 0.8084507728839393, 0.5814525467640246] z: &lt;class &#39;NoneType&#39;&gt; None Required Arguments Required arguments are mandatory and you will generate an error if they’re not present. Required arguments must be passed in precisely the right order, just like in the following example: def say_something(message, number_of_times): for i in range(0, number_of_times): print(message) # arguments passed in the proper order say_something(&#39;hello&#39;, 3) hello hello hello # arguments passed incorrectly say_something(3, &#39;hello&#39;) TypeError Traceback (most recent call last) &lt;ipython-input-18-b19729b65905&gt; in &lt;module&gt; 1 # arguments passed incorrectly -&gt; 2 say_something(3, &#39;hello&#39;) &lt;ipython-input-17-70cae7a69ece&gt; in say_something(message, number_of_times) 1 def say_something(message, number_of_times): -&gt; 2 for i in range(0, number_of_times): 3 print(message) 4 5 # arguments passed in the proper order TypeError: &#39;str&#39; object cannot be interpreted as an integer Keyword Arguments You can use keyword arguments to make sure that you call all the parameters in the right order. You can do so by specifying their parameter name in the function call. say_something(message=&#39;hello&#39;, number_of_times=3) say_something(number_of_times=3, message=&#39;hello&#39;) hello hello hello hello hello hello Variable Number of Arguments In cases where you don’t know the exact number of arguments that you want to pass to a function, you can use the following syntax with *args: def add(*x): print(type(x), x) total = 0 for x in x: total += x return total total = add(1) print(total) total = add(1, 1) print(total) total = add(1, 2, 3, 4, 5) print(total) &lt;class &#39;tuple&#39;&gt; (1,) 1 &lt;class &#39;tuple&#39;&gt; (1, 1) 2 &lt;class &#39;tuple&#39;&gt; (1, 2, 3, 4, 5) 15 The asterisk * is placed before the variable name that holds the values of all nonkeyword variable arguments. Note here that you might as well have passed *varint, *var_int_args or any other name to the plus() function. # You can spedify any combination of required, keyword, and variable arguments. def add(a, b, *args): total = a for arg in args: total += arg return total total = add(1, 1) print(total) total = add(1, 1, 2) print(total) total = add(1, 2, 3, 4, 5) print(total) 1 3 13 Global vs Local Variables In general, variables that are defined inside a function body have a local scope, and those defined outside have a global scope. That means that local variables are defined within a function block and can only be accessed inside that function, while global variables can be obtained by all functions that might be in your script: # global variable score = 0 def player_hit(): global score hit_points = -10 # local variable score += hit_points def enemy_hit(): global score hit_points = 5 # local variable score += hit_points enemy_hit() enemy_hit() enemy_hit() enemy_hit() player_hit() enemy_hit() player_hit() print(score) 5 Anonymous Functions in Python Anonymous functions are also called lambda functions in Python because instead of declaring them with the standard def keyword, you use the lambda keyword. double = lambda x: x * 2 y = double(3) print(y) 6 sdlfjsdk = lambda x, n: x if n &lt; 5 else 0 result = sdlfjsdk(4, 6) print(result) 0 add = lambda x, y: x + y x = add(2, 3) print(x) 5 You use anonymous functions when you require a nameless function for a short period of time, and that is created at runtime. Specific contexts in which this would be relevant is when you’re working with filter(), map() and reduce(): filter() function filters the original input list on the basis of a criterion &gt; 10. map() applies a function to all items of the list reduce() is part of the functools library. You use this function cumulatively to the items of the my_list list, from left to right and reduce the sequence to a single value. from functools import reduce my_list = [1,2,3,4,5,6,7,8,9,10] # Use lambda function with `filter()` filtered_list = list(filter(lambda x: (x * 2 &gt; 10), my_list)) # Use lambda function with `map()` mapped_list = list(map(lambda x: x * 2, my_list)) # Use lambda function with `reduce()` reduced_list = reduce(lambda x, y: x + y, my_list) print(filtered_list) print(mapped_list) print(reduced_list) [6, 7, 8, 9, 10] [2, 4, 6, 8, 10, 12, 14, 16, 18, 20] 55 Using main() as a Function You can easily define a main() function and call it just like you have done with all of the other functions above: # Define `main()` function def main(): print(&quot;This is a main function&quot;) main() This is a main function However, as it stands now, the code of your main() function will be called when you import it as a module. To make sure that this doesn’t happen, you call the main() function when __name__ == &#39;__main__&#39;. # Define `main()` function def main(): print(&quot;This is a main function&quot;) # Execute `main()` function if __name__ == &#39;__main__&#39;: main() This is a main function",
    "url": "http://localhost:4000/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/01.a%20-%20Python%20Functions.html",
    "relUrl": "/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/01.a%20-%20Python%20Functions.html"
  },
  "7": {
    "id": "7",
    "title": "01.a - Terminal Application",
    "content": "Basic Terminal Apps Basic Terminal Apps # Show a simple message print(&#39;hello class&#39;) hello class Print a title bar import os # Display a title bar. print(&quot;**********************************************&quot;) print(&quot;*** Hello to everyone in class today! ***&quot;) print(&quot;**********************************************&quot;) # Display a bunch of output, representing a long-running program. for week in range(1, 8): print(f&quot;We will learn interesting things in Week {week:02}&quot;) print(f&quot;We will learn interesting things in Week {week:02}&quot;) ********************************************** *** Hello to everyone in class today! *** ********************************************** We will learn interesting things in Week 01 We will learn interesting things in Week 01 We will learn interesting things in Week 02 We will learn interesting things in Week 02 We will learn interesting things in Week 03 We will learn interesting things in Week 03 We will learn interesting things in Week 04 We will learn interesting things in Week 04 We will learn interesting things in Week 05 We will learn interesting things in Week 05 We will learn interesting things in Week 06 We will learn interesting things in Week 06 We will learn interesting things in Week 07 We will learn interesting things in Week 07 The sleep function import os from time import sleep # Display a title bar. print(&quot;**********************************************&quot;) print(&quot;*** Hello to everyone in class today! ***&quot;) print(&quot;**********************************************&quot;) # Display a bunch of output, representing a long-running program. for week in range(1,8): sleep(1) print(f&quot;We will learn interesting things in Week {week:02}&quot;) ********************************************** *** Hello to everyone in class today! *** ********************************************** We will learn interesting things in Week 01 We will learn interesting things in Week 02 We will learn interesting things in Week 03 We will learn interesting things in Week 04 We will learn interesting things in Week 05 We will learn interesting things in Week 06 We will learn interesting things in Week 07 Accepting arguments You can pass arguments into your application to dynamically change the behavior at run time. See terminal_1.py import sys from time import sleep adjective = sys.argv[1] num_weeks = int(sys.argv[2]) print(&quot;**********************************************&quot;) print(&quot;*** Hello to everyone in class today! ***&quot;) print(&quot;**********************************************&quot;) for week in range(1, num_weeks + 1): sleep(1) print(f&quot;We will learn {adjective} things in Week {week:02}&quot;) Note: sys.argv[1] is the 1st parameter passed in. sys.argv[0] represents the path of the file being run all arguments are strings by default, you can cast these to other data types !python terminal_1.py fun 3 ********************************************** *** Hello to everyone in class today! *** ********************************************** We will learn fun things in Week 01 We will learn fun things in Week 02 We will learn fun things in Week 03 Here we slightly modify the code to process a list of arguments. Since all arguments are strings we’ll pass in a comma separated list of values. See terminal_2.py import sys from time import sleep adjectives = sys.argv[1] print(&quot;**********************************************&quot;) print(&quot;*** Hello to everyone in class today! ***&quot;) print(&quot;**********************************************&quot;) for week, adjective in enumerate(adjectives.split(&#39;,&#39;)): sleep(1) print(f&quot;We will learn {adjective} things in Week {(week + 1):02}&quot;) Note: adjectives is a string which we’ll split on commas to create a list we use enumerate to keep track of the index we’re currently processing since index is zero based, we’ll add 1 in the print statement to associate the index with the correct week !python terminal_2.py &quot;fun,interesting,exciting&quot; ********************************************** *** Hello to everyone in class today! *** ********************************************** We will learn fun things in Week 01 We will learn interesting things in Week 02 We will learn exciting things in Week 03",
    "url": "http://localhost:4000/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/01.a%20-%20Terminal%20Application.html",
    "relUrl": "/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/01.a%20-%20Terminal%20Application.html"
  },
  "8": {
    "id": "8",
    "title": "01.b - Argparse",
    "content": "Argparse What is Argparse? Argparse Tutorial Argparse is a parser for command-line options, arguments and subcommands. This library makes it easy to write user-friendly command-line interfaces by: defines what arguments it requires and figuring out how to parse those out of sys.argv. The argparse module automatically generates help and usage messages and issues errors when users give the program invalid arguments. Getting Started See agrparse_1.py # import the library import argparse # initialize the parser parser = argparse.ArgumentParser() # parse arguments from sys.argv parser.parse_args() # run the code and ask for help !python argparse_1.py --help usage: argparse_1.py [-h] optional arguments: -h, --help show this help message and exit Positional Arguments See argparse_2.py import argparse parser = argparse.ArgumentParser() parser.add_argument(&quot;name&quot;) parser.add_argument(&quot;age&quot;) parser.add_argument(&quot;city&quot;) args = parser.parse_args() print(args.name, args.age, args.city) !python argparse_2.py --help usage: argparse_2.py [-h] name age city positional arguments: name age city optional arguments: -h, --help show this help message and exit !python argparse_2.py Ben 37 Pittsburgh Ben 37 Pittsburgh !python argparse_2.py Brian &quot;??&quot; Pittsburgh Brian ?? Pittsburgh Extending the help text See argparse_3.py import argparse parser = argparse.ArgumentParser() parser.add_argument(&quot;name&quot;, help=&quot;the name of the person you want to find&quot;) parser.add_argument(&quot;age&quot;, help=&quot;the age of the person you&#39;d like to find&quot;) parser.add_argument(&quot;city&quot;, help=&quot;the city you&#39;d like to search&quot;) args = parser.parse_args() !python argparse_3.py --help usage: argparse_3.py [-h] name age city positional arguments: name the name of the person you want to find age the age of the person you&#39;d like to find city the city you&#39;d like to search optional arguments: -h, --help show this help message and exit Changing the default argument type Argparse treats all arguments as strings by default. You can change the expected data type when you add each argument. See argparse_4.py import argparse parser = argparse.ArgumentParser() parser.add_argument(&quot;name&quot;, help=&quot;the name of the person you want to find&quot;) parser.add_argument(&quot;age&quot;, help=&quot;the age of the person you&#39;d like to find&quot;, type=int) parser.add_argument(&quot;city&quot;, help=&quot;the city you&#39;d like to search&quot;) args = parser.parse_args() !python argparse_4.py Ben abc Pittsburgh usage: argparse_4.py [-h] name age city argparse_4.py: error: argument age: invalid int value: &#39;abc&#39; !python argparse_4.py Ben 37 Pittsburgh Optional arguments See argparse_5.py import argparse parser = argparse.ArgumentParser() parser.add_argument(&quot;--verbose&quot;, help=&quot;increase output verbosity&quot;, action=&quot;store_true&quot;) args = parser.parse_args() if args.verbose: print(&quot;verbosity turned on&quot;) An optional argument (or option) is (by default) given None as a value when its not being used. Using the –verbosity option, only two values are actually useful, True or False. The keyword “action” is being given the value “store_true” which means that if the option is specifed, then assign the value “True” to args.verbose Not specifying the option implies False. !python argparse_5.py --help usage: argparse_5.py [-h] [--verbose] optional arguments: -h, --help show this help message and exit --verbose increase output verbosity !python argparse_5.py --verbose verbosity turned on !python argparse_5.py Short options See argparse_6.py import argparse parser = argparse.ArgumentParser() parser.add_argument(&quot;-n&quot;, &quot;--name&quot;, help=&quot;the name of the person you want to find&quot;) parser.add_argument(&quot;-a&quot;, &quot;--age&quot;, help=&quot;the age of the person you&#39;d like to find&quot;, type=int) parser.add_argument(&quot;-c&quot;, &quot;--city&quot;, help=&quot;the city you&#39;d like to search&quot;) parser.add_argument(&quot;-v&quot;, &quot;--verbose&quot;, help=&quot;increase output verbosity&quot;, action=&quot;store_true&quot;) args = parser.parse_args() if args.verbose: print(f&quot;Searching for {args.name} {args.age} years of age in or around {args.city}&quot;) else: print(f&quot;Searching for {args.name}&quot;) !python argparse_6.py --help usage: argparse_6.py [-h] [-n NAME] [-a AGE] [-c CITY] [-v] optional arguments: -h, --help show this help message and exit -n NAME, --name NAME the name of the person you want to find -a AGE, --age AGE the age of the person you&#39;d like to find -c CITY, --city CITY the city you&#39;d like to search -v, --verbose increase output verbosity !python argparse_6.py -n Ben -a 37 -c Pittsburgh Searching for Ben !python argparse_6.py --name Ben --age 37 --city Pittsburgh Searching for Ben !python argparse_6.py --name Ben --age 37 --city Pittsburgh --verbose Searching for Ben 37 years of age in or around Pittsburgh",
    "url": "http://localhost:4000/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/01.b%20-%20Argparse.html",
    "relUrl": "/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/01.b%20-%20Argparse.html"
  },
  "9": {
    "id": "9",
    "title": "01.b - CSV Files",
    "content": "Reading CSV files Reading with open # open and print line by line with open(&#39;mock.csv&#39;) as f: for line in f: print(line) id,first_name,last_name,email,gender,ip_address 1,Finn,Burchmore,fburchmore0@epa.gov,Male,74.20.172.212 2,Coral,Grigorey,cgrigorey1@cdc.gov,Female,151.91.212.169 3,Harold,McCormack,hmccormack2@marketwatch.com,Male,72.36.41.150 4,Thacher,Woodvine,twoodvine3@marketwatch.com,Male,66.50.122.48 5,Querida,Allmann,qallmann4@people.com.cn,Female,236.145.83.165 6,Irving,Loughman,iloughman5@globo.com,Male,19.142.188.98 7,Meghann,Vittet,mvittet6@cyberchimps.com,Female,235.59.102.124 8,Wolfgang,Mishow,wmishow7@gnu.org,Male,189.36.37.25 9,Babbie,Reide,breide8@jiathis.com,Female,129.226.63.38 10,Carson,Vowdon,cvowdon9@slashdot.org,Male,51.228.124.19 with open(&#39;mock.csv&#39;) as f: # use enumerate to get the index as you iterate for index, line in enumerate(f): print(index, line) 0 id,first_name,last_name,email,gender,ip_address 1 1,Finn,Burchmore,fburchmore0@epa.gov,Male,74.20.172.212 2 2,Coral,Grigorey,cgrigorey1@cdc.gov,Female,151.91.212.169 3 3,Harold,McCormack,hmccormack2@marketwatch.com,Male,72.36.41.150 4 4,Thacher,Woodvine,twoodvine3@marketwatch.com,Male,66.50.122.48 5 5,Querida,Allmann,qallmann4@people.com.cn,Female,236.145.83.165 6 6,Irving,Loughman,iloughman5@globo.com,Male,19.142.188.98 7 7,Meghann,Vittet,mvittet6@cyberchimps.com,Female,235.59.102.124 8 8,Wolfgang,Mishow,wmishow7@gnu.org,Male,189.36.37.25 9 9,Babbie,Reide,breide8@jiathis.com,Female,129.226.63.38 10 10,Carson,Vowdon,cvowdon9@slashdot.org,Male,51.228.124.19 index = 0 processed_header = False with open(&#39;mock.csv&#39;) as f: for line in f: # handle the header differently if processed_header == False: print(&quot;header&quot;, index, line) processed_header = True else: print(&quot;row&quot;, index, line) index += 1 header 0 id,first_name,last_name,email,gender,ip_address row 1 1,Finn,Burchmore,fburchmore0@epa.gov,Male,74.20.172.212 row 2 2,Coral,Grigorey,cgrigorey1@cdc.gov,Female,151.91.212.169 row 3 3,Harold,McCormack,hmccormack2@marketwatch.com,Male,72.36.41.150 row 4 4,Thacher,Woodvine,twoodvine3@marketwatch.com,Male,66.50.122.48 row 5 5,Querida,Allmann,qallmann4@people.com.cn,Female,236.145.83.165 row 6 6,Irving,Loughman,iloughman5@globo.com,Male,19.142.188.98 row 7 7,Meghann,Vittet,mvittet6@cyberchimps.com,Female,235.59.102.124 row 8 8,Wolfgang,Mishow,wmishow7@gnu.org,Male,189.36.37.25 row 9 9,Babbie,Reide,breide8@jiathis.com,Female,129.226.63.38 row 10 10,Carson,Vowdon,cvowdon9@slashdot.org,Male,51.228.124.19 with open(&#39;mock.csv&#39;) as f: for index, line in enumerate(f): # handle the header differently if index == 0: print(&quot;header&quot;, index, line) else: print(&quot;row&quot;, index, line) header 0 id,first_name,last_name,email,gender,ip_address row 1 1,Finn,Burchmore,fburchmore0@epa.gov,Male,74.20.172.212 row 2 2,Coral,Grigorey,cgrigorey1@cdc.gov,Female,151.91.212.169 row 3 3,Harold,McCormack,hmccormack2@marketwatch.com,Male,72.36.41.150 row 4 4,Thacher,Woodvine,twoodvine3@marketwatch.com,Male,66.50.122.48 row 5 5,Querida,Allmann,qallmann4@people.com.cn,Female,236.145.83.165 row 6 6,Irving,Loughman,iloughman5@globo.com,Male,19.142.188.98 row 7 7,Meghann,Vittet,mvittet6@cyberchimps.com,Female,235.59.102.124 row 8 8,Wolfgang,Mishow,wmishow7@gnu.org,Male,189.36.37.25 row 9 9,Babbie,Reide,breide8@jiathis.com,Female,129.226.63.38 row 10 10,Carson,Vowdon,cvowdon9@slashdot.org,Male,51.228.124.19 headers = [] with open(&#39;mock.csv&#39;) as f: for index, line in enumerate(f): line = line.strip() if index == 0: # split the headers headers = line.split(&#39;,&#39;) else: pass print(&#39;header fields&#39;, headers) header fields [&#39;id&#39;, &#39;first_name&#39;, &#39;last_name&#39;, &#39;email&#39;, &#39;gender&#39;, &#39;ip_address&#39;] headers = [] rows = [] with open(&#39;mock.csv&#39;) as f: for index, line in enumerate(f): line = line.strip() if index == 0: headers = line.split(&#39;,&#39;) else: # append the rows rows.append(line.split(&#39;,&#39;)) print(&#39;header fields&#39;, headers) print(&#39;rows fields&#39;, rows) header fields [&#39;id&#39;, &#39;first_name&#39;, &#39;last_name&#39;, &#39;email&#39;, &#39;gender&#39;, &#39;ip_address&#39;] rows fields [[&#39;1&#39;, &#39;Finn&#39;, &#39;Burchmore&#39;, &#39;fburchmore0@epa.gov&#39;, &#39;Male&#39;, &#39;74.20.172.212&#39;], [&#39;2&#39;, &#39;Coral&#39;, &#39;Grigorey&#39;, &#39;cgrigorey1@cdc.gov&#39;, &#39;Female&#39;, &#39;151.91.212.169&#39;], [&#39;3&#39;, &#39;Harold&#39;, &#39;McCormack&#39;, &#39;hmccormack2@marketwatch.com&#39;, &#39;Male&#39;, &#39;72.36.41.150&#39;], [&#39;4&#39;, &#39;Thacher&#39;, &#39;Woodvine&#39;, &#39;twoodvine3@marketwatch.com&#39;, &#39;Male&#39;, &#39;66.50.122.48&#39;], [&#39;5&#39;, &#39;Querida&#39;, &#39;Allmann&#39;, &#39;qallmann4@people.com.cn&#39;, &#39;Female&#39;, &#39;236.145.83.165&#39;], [&#39;6&#39;, &#39;Irving&#39;, &#39;Loughman&#39;, &#39;iloughman5@globo.com&#39;, &#39;Male&#39;, &#39;19.142.188.98&#39;], [&#39;7&#39;, &#39;Meghann&#39;, &#39;Vittet&#39;, &#39;mvittet6@cyberchimps.com&#39;, &#39;Female&#39;, &#39;235.59.102.124&#39;], [&#39;8&#39;, &#39;Wolfgang&#39;, &#39;Mishow&#39;, &#39;wmishow7@gnu.org&#39;, &#39;Male&#39;, &#39;189.36.37.25&#39;], [&#39;9&#39;, &#39;Babbie&#39;, &#39;Reide&#39;, &#39;breide8@jiathis.com&#39;, &#39;Female&#39;, &#39;129.226.63.38&#39;], [&#39;10&#39;, &#39;Carson&#39;, &#39;Vowdon&#39;, &#39;cvowdon9@slashdot.org&#39;, &#39;Male&#39;, &#39;51.228.124.19&#39;]] Reading with csv Reading and Writing CSV Files in Python import csv with open(&#39;mock.csv&#39;) as f: reader = csv.reader(f, delimiter=&#39;,&#39;) for row in reader: print(row) [&#39;id&#39;, &#39;first_name&#39;, &#39;last_name&#39;, &#39;email&#39;, &#39;gender&#39;, &#39;ip_address&#39;] [&#39;1&#39;, &#39;Finn&#39;, &#39;Burchmore&#39;, &#39;fburchmore0@epa.gov&#39;, &#39;Male&#39;, &#39;74.20.172.212&#39;] [&#39;2&#39;, &#39;Coral&#39;, &#39;Grigorey&#39;, &#39;cgrigorey1@cdc.gov&#39;, &#39;Female&#39;, &#39;151.91.212.169&#39;] [&#39;3&#39;, &#39;Harold&#39;, &#39;McCormack&#39;, &#39;hmccormack2@marketwatch.com&#39;, &#39;Male&#39;, &#39;72.36.41.150&#39;] [&#39;4&#39;, &#39;Thacher&#39;, &#39;Woodvine&#39;, &#39;twoodvine3@marketwatch.com&#39;, &#39;Male&#39;, &#39;66.50.122.48&#39;] [&#39;5&#39;, &#39;Querida&#39;, &#39;Allmann&#39;, &#39;qallmann4@people.com.cn&#39;, &#39;Female&#39;, &#39;236.145.83.165&#39;] [&#39;6&#39;, &#39;Irving&#39;, &#39;Loughman&#39;, &#39;iloughman5@globo.com&#39;, &#39;Male&#39;, &#39;19.142.188.98&#39;] [&#39;7&#39;, &#39;Meghann&#39;, &#39;Vittet&#39;, &#39;mvittet6@cyberchimps.com&#39;, &#39;Female&#39;, &#39;235.59.102.124&#39;] [&#39;8&#39;, &#39;Wolfgang&#39;, &#39;Mishow&#39;, &#39;wmishow7@gnu.org&#39;, &#39;Male&#39;, &#39;189.36.37.25&#39;] [&#39;9&#39;, &#39;Babbie&#39;, &#39;Reide&#39;, &#39;breide8@jiathis.com&#39;, &#39;Female&#39;, &#39;129.226.63.38&#39;] [&#39;10&#39;, &#39;Carson&#39;, &#39;Vowdon&#39;, &#39;cvowdon9@slashdot.org&#39;, &#39;Male&#39;, &#39;51.228.124.19&#39;] with open(&#39;mock.csv&#39;) as f: reader = csv.reader(f, delimiter=&#39;,&#39;) for index, row in enumerate(reader): if index == 0: print(f&#39;{&quot;, &quot;.join(row)}&#39;) else: print(f&#39;id: {row[0]} first_name: {row[1]} last_name: {row[2]} email: {row[3]}&#39;) id, first_name, last_name, email, gender, ip_address id: 1 first_name: Finn last_name: Burchmore email: fburchmore0@epa.gov id: 2 first_name: Coral last_name: Grigorey email: cgrigorey1@cdc.gov id: 3 first_name: Harold last_name: McCormack email: hmccormack2@marketwatch.com id: 4 first_name: Thacher last_name: Woodvine email: twoodvine3@marketwatch.com id: 5 first_name: Querida last_name: Allmann email: qallmann4@people.com.cn id: 6 first_name: Irving last_name: Loughman email: iloughman5@globo.com id: 7 first_name: Meghann last_name: Vittet email: mvittet6@cyberchimps.com id: 8 first_name: Wolfgang last_name: Mishow email: wmishow7@gnu.org id: 9 first_name: Babbie last_name: Reide email: breide8@jiathis.com id: 10 first_name: Carson last_name: Vowdon email: cvowdon9@slashdot.org Reading CSV Files Into a Dictionary With csv with open(&#39;mock.csv&#39;) as f: reader = csv.DictReader(f) for index, row in enumerate(reader): print(f&#39;id: {row[&quot;id&quot;]} first_name: {row[&quot;first_name&quot;]} last_name: {row[&quot;last_name&quot;]} email: {row[&quot;email&quot;]}&#39;) id: 1 first_name: Finn last_name: Burchmore email: fburchmore0@epa.gov id: 2 first_name: Coral last_name: Grigorey email: cgrigorey1@cdc.gov id: 3 first_name: Harold last_name: McCormack email: hmccormack2@marketwatch.com id: 4 first_name: Thacher last_name: Woodvine email: twoodvine3@marketwatch.com id: 5 first_name: Querida last_name: Allmann email: qallmann4@people.com.cn id: 6 first_name: Irving last_name: Loughman email: iloughman5@globo.com id: 7 first_name: Meghann last_name: Vittet email: mvittet6@cyberchimps.com id: 8 first_name: Wolfgang last_name: Mishow email: wmishow7@gnu.org id: 9 first_name: Babbie last_name: Reide email: breide8@jiathis.com id: 10 first_name: Carson last_name: Vowdon email: cvowdon9@slashdot.org Optional Python CSV reader Parameters delimiter specifies the character used to separate each field. The default is the comma (‘,’). quotechar specifies the character used to surround fields that contain the delimiter character. The default is a double quote (‘ “ ‘). escapechar specifies the character used to escape the delimiter character, in case quotes aren’t used. The default is no escape character. Writing CSV Files With csv with open(&#39;scores.csv&#39;, mode=&#39;w&#39;) as employee_file: writer = csv.writer(employee_file, delimiter=&#39;,&#39;, quotechar=&#39;&quot;&#39;, quoting=csv.QUOTE_MINIMAL) writer.writerow([&#39;2019-05-01&#39;, &#39;Pirates&#39;, 0, &#39;Cubs&#39;, 10]) writer.writerow([&#39;2019-05-15&#39;, &#39;Reds&#39;, 7, &#39;Pirates&#39;, 0]) If quoting is set to csv.QUOTE_MINIMAL, then .writerow() will quote fields only if they contain the delimiter or the quotechar. This is the default case. If quoting is set to csv.QUOTE_ALL, then .writerow() will quote all fields. If quoting is set to csv.QUOTE_NONNUMERIC, then .writerow() will quote all fields containing text data and convert all numeric fields to the float data type. If quoting is set to csv.QUOTE_NONE, then .writerow() will escape delimiters instead of quoting them. In this case, you also must provide a value for the escapechar optional parameter. Writing CSV File From a Dictionary With csv with open(&#39;scores.csv&#39;, mode=&#39;w&#39;) as csv_file: fieldnames = [&#39;date&#39;, &#39;home_team&#39;, &#39;home_score&#39;, &#39;away_team&#39;, &#39;away_score&#39;] writer = csv.DictWriter(csv_file, fieldnames=fieldnames) writer.writeheader() writer.writerow({&#39;date&#39;: &#39;2019-05-01&#39;, &#39;home_team&#39;: &#39;Pirates&#39;, &#39;home_score&#39;: 0, &#39;away_team&#39;: &#39;Cubs&#39;, &#39;away_score&#39;: 10}) writer.writerow({&#39;date&#39;: &#39;2019-05-15&#39;, &#39;home_team&#39;: &#39;Reds&#39;, &#39;home_score&#39;: 7, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;away_score&#39;: 0}) Some Notes on typecasting x = &quot;1&quot; print(x + str(3)) 13 x = &quot;1&quot; n = float(x) print(n + n) print(n * 3) 2.0 3.0 x = &quot;blah&quot; print(x) x = 125 print(x) blah 125",
    "url": "http://localhost:4000/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/01.b%20-%20CSV%20Files.html",
    "relUrl": "/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/01.b%20-%20CSV%20Files.html"
  },
  "10": {
    "id": "10",
    "title": "01.b - Getting Data from Web Pages",
    "content": "Using Python BeautifulSoup to scrape DataCamp Tutorials &amp; Analyze Source In this tutorial, we are going to scrape the tutorials section of the DataCamp website and try to get some insights. Most contributing authors Timeline of contributors (How it all started!) Comparing upvotes vs. number of articles published Before that, the website will be scraped using python’s BeautifulSoup package. To understand the page structure, Chrome browser developer tools will need to be used. This is done to identify the Classes that will be searched to get the required information. The following information will be gathered from the page: Author Publish Date Title Description Up Votes Importing Libraries We’ll start by importing the necessary libraries as follows: import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline import re import time from datetime import datetime import matplotlib.dates as mdates import matplotlib.ticker as ticker from urllib.request import urlopen from bs4 import BeautifulSoup Determining Pages to be Scraped A sample URL that we’re going to loop and scrape is the following https://www.datacamp.com/community/tutorials?page=2. As we can see, the page=2 argument changes for each page. In order to loop through all the pages to get the necessary dataset, we need to find out the number of pages. The following lines of code do just that. url = &quot;https://www.datacamp.com/community/tutorials&quot; html = urlopen(url) soup = BeautifulSoup(html, &#39;html&#39;) pages = [i.text for i in soup.find_all(&#39;a&#39;) if &#39;community/tutorials?page=&#39; in str(i)] lastpage = pages[-1] print(lastpage) 22 The illustration is as follows: Specified the url to a variable Opened the url using urlopen which was imported earlier Scraped the specified page and assigned it to soup variable Identified all hyperlinks on the page using list comprehension and filtered for those having community/tutorials?page= in it The text value of the last found url is the last page that needs to be scraped We proceed by declaring list variables that will hold the scraped values for the columns we intend as mentioned earlier description=[] upvote=[] author=[] publishdate=[] title=[] Doing the Actual Scrape Now that we know how many pages we need to scrape and have declared our variables, we will now use a for loop and go through each page one by one to get our fields of interest as shown below. Note that we will end up having list of lists for each column of interest, but later we will be flattening the list further so that it can be used for Data Frames. for cp in np.arange(1,int(lastpage)+1): url = &quot;https://www.datacamp.com/community/tutorials?page=&quot; + str(cp) html = urlopen(url) soup = BeautifulSoup(html, &#39;html&#39;) description.append([i.text for i in soup.find_all(class_=&#39;jsx-379356511 blocText description&#39;)]) # upvote.append([i.text for i in soup.find_all(class_=&#39;jsx-4192737526 voted&#39;)]) upvote.append([i.text for i in soup.find_all(class_=&#39;jsx-1972554161 voted&#39;)]) author.append([i.text for i in soup.find_all(class_=&#39;jsx-566588255 name&#39;)]) publishdate.append([i.text for i in soup.find_all(class_=&#39;jsx-566588255 date&#39;)]) title.append([i.text for i in soup.find_all(class_=&#39;jsx-379356511 blue&#39;)]) time.sleep(3) print (&quot;Done!&quot;) Done! Here is what happened in the above code segment Set the url to a variable Opened the url using urlopen which was imported earlier Scraped the specified page and assigned it to soup variable Identified and extracted values for Description, Up Vote, Author, Publish Date, Title by using their relevant class names. These class names were found using Developer Tools The time function has been used to be easy on the website this time :)### 3.b Display the soup object to visually interrogate Flattening List of Lists Since the values we got are list of lists, they will now be flatted using the following code segment: descriptionflat = [y for x in description for y in x] len(descriptionflat) 312 upvoteflat = [y for x in upvote for y in x] len(upvoteflat) 312 authorflat = [y for x in author for y in x] len(authorflat) 312 publishdateflat = [y for x in publishdate for y in x] len(publishdateflat) 312 titleflat = [y for x in title for y in x] len(titleflat) 312 publishdateformatted = [datetime.strptime(re.sub(&#39;rd, &#39;, &#39;, &#39;, re.sub(&#39;st, &#39;, &#39;, &#39;, re.sub(&#39;nd, &#39;, &#39;, &#39;, re.sub(&#39;th, &#39;,&#39;, &#39;,a)))), &quot;%B %d, %Y&quot;) for a in publishdateflat] len(publishdateformatted) 312 The last statement in the cell above converts the date values (which are currently in String Format) to DateTime. Making a Data Frame and Saving as CSV File The lists will now be grouped into a dictionary, and a data frame will be created for further analysis. The last command saves the data frame to a CSV file so that it can be used later on. cdata = {&quot;author&quot;:authorflat, &quot;publishdate&quot;:publishdateformatted, &quot;title&quot;:titleflat, &quot;description&quot;:descriptionflat, &quot;upvote&quot;:upvoteflat} df = pd.DataFrame(data=cdata) df.to_csv(&quot;datacamp.csv&quot;, header=True, index=False) Reading CSV File Now we are attempting to read into the collected dataset from the CSV file we just created. data = pd.read_csv(&quot;datacamp.csv&quot;, parse_dates=[&quot;publishdate&quot;], infer_datetime_format=True) data.shape (311, 5) The above command tells us we’re dealing with a dataset of 176 rows and 5 columns. data.head() author publishdate title description upvote 0 Aditya Sharma 2019-04-26 Graphs in Spreadsheets In this tutorial, you&#39;ll learn how to create v... 9 1 Sayak Paul 2019-04-24 Cleaning Data in SQL In this tutorial, you&#39;ll learn techniques on h... 4 2 Francisco Javier Carrera Arias 2019-04-19 SQLite in R In this tutorial, you will learn about using S... 4 3 Parul Pandey 2019-04-18 Data Visualization with Power BI Learn how to analyze and display data using Po... 8 4 Sayak Paul 2019-04-17 Aggregate Functions in SQL Learn how to use aggregate functions for summa... 4 Showing the first 5 rows of the dataset above using the head function. data[&#39;publishyymm&#39;] = data[&#39;publishdate&#39;].dt.strftime(&quot;%Y-%b&quot;) data[&quot;posts&quot;] = 1 The first line in the above code section creates a new column with the publish date formatted as a Year-Month format. The second line assigns value 1 to a new column posts being used later. Tutorials Count by Time Here we will organize the count of Tutorials over Timeline of Year and Month: datacamp.groupby([datacamp[&#39;publishdate&#39;].dt.year, datacamp[&#39;publishdate&#39;].dt.month]).size().plot(kind=&#39;bar&#39;, figsize=(15,7), color=&#39;b&#39;) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1a1a2bda90&gt; Since 2017 January Since the duration from 2013 till 2016 represents very few posts, we will be ignoring them from now and considering posts starting Jan 2017. A filter will be applied for that as shown below data[data[&quot;publishdate&quot;]&gt;=&#39;2017-01-01&#39;] .sort_values(by=&quot;publishdate&quot;, ascending=True) .groupby([data[&#39;publishyymm&#39;]],sort=False) .size() .plot(kind=&#39;bar&#39;, figsize=(15,7), color=&#39;b&#39;) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1a1627b828&gt; Tutorials have paced up in 2018 with especially starting March onwards with a consistent upwards pace. Since this data was pulled in mid-August and almost crossing the middle line of July’s tutorials count, we might be having August as the month with highest posts so far this year! Top Authors Graph While we’re pacing up on all these tutorials, who have been contributing on them along the way? Here we go with a simple bar chart highlighting this very fact. data[data[&quot;publishdate&quot;]&gt;=&#39;2017-01-01&#39;][&quot;author&quot;] .value_counts(sort=True, ascending=False)[:10] .plot(kind=&#39;bar&#39;) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1a1b218f60&gt; Top Authors List Let’s build a list of these as well while we are at it. We’ll be using this soon below: topauthors = data[data[&quot;publishdate&quot;]&gt;=&#39;2017-01-01&#39;][&quot;author&quot;] .value_counts(sort=True, ascending=False)[:10] .index This is what happened in the code section above. Limited Result set to Tutorials since 2017 January Select only Author field Aggregated results using the value_counts function Sorted the result set in descending order and limited it to the first 10 rows Tutorials Paced over Timeline Now what we’re going to focus on is since when and at what pace have these top 10 contributors been posting tutorials. For this, we will be using the list we just created along with some transformations to come up with a stacked bar chart that we need. dh = data[data[&quot;publishdate&quot;]&gt;=&#39;2017-01-01&#39;] .sort_values(by=&quot;publishdate&quot;, ascending=True) # .set_index([&quot;publishdate&quot;]) dh.head() author publishdate title description upvote publishyymm posts 289 Karlijn Willems 2017-01-10 15 Easy Solutions To Your Data Frame Problems ... Discover how to create a data frame in R, chan... 49 2017-Jan 1 288 Ted Kwartler 2017-01-12 Web Scraping and Parsing Data in R | Explorin... Learn how to scrape data from the web, preproc... 14 2017-Jan 1 287 Ted Kwartler 2017-01-19 Exploring H-1B Data with R: Part 2 Learn even more about exploratory data analysi... 4 2017-Jan 1 286 Ted Kwartler 2017-01-26 Exploring H-1B Data with R: Part 3 Learn how to geocode locations and map them wi... 6 2017-Jan 1 285 Yao-Jen Kuo 2017-01-27 Scikit-Learn 教學：Python 與機器學習 簡單易懂的 scikit-learn 教學，適合想要使用 Python 實作機器學習的初學者閱讀。 36 2017-Jan 1 dh[&quot;publishdateone&quot;] = pd.to_datetime(dh.publishdate.astype(str).str[0:7]+&#39;-01&#39;) This is what happened in the code section above. Limited Result set to Tutorials since 2017 January Sorted by Publish Date Making Publish Date as the Index column Now that we’re going to visualize using a stacked bar chart, the data set will now be pivoted by having the date field as the Index, Posts as values which are to be aggregated, and Authors as columns. dhp = dh[dh[&quot;author&quot;].isin(topauthors)] .pivot_table(index=&quot;publishdateone&quot;,values=&quot;posts&quot;,columns=&quot;author&quot;, aggfunc=np.sum) fig, ax = plt.subplots(figsize=(15,7)) dhp.plot(ax=ax, kind=&#39;bar&#39;, stacked=True) ticklabels = [item.strftime(&#39;%Y %b&#39;) for item in dhp.index] ax.xaxis.set_major_formatter(ticker.FixedFormatter(ticklabels)) Here is what we possibly get out of the above Chart along with considering the earlier visualization of Tutorial Counts by Authors. Looking at Upvotes vs. Tutorials When a reader likes a tutorial, an upvote is signaled respectively. Let’s see who’s managed to get a good amount of upvotes vs. number of tutorials they have posted! We’ll be considering the top 10 contributors in this case as well. This will be done by using a scatter plot. upvotes = dh[dh[&quot;author&quot;].isin(topauthors)] .groupby([&#39;author&#39;], as_index=False) .agg({&#39;posts&#39;:&quot;sum&quot;, &#39;upvote&#39;: &quot;sum&quot;}) sns.lmplot(&#39;posts&#39;, &#39;upvote&#39;, data=upvotes, fit_reg=False, hue=&quot;author&quot;, scatter_kws={&quot;marker&quot;: &quot;D&quot;, &quot;s&quot;: 100}) &lt;seaborn.axisgrid.FacetGrid at 0x1a1a985c18&gt; Conclusion In this tutorial, we have managed to achieve the following: Scrape tutorials list across all pages Create a Data Frame and save it as CSV for later reference and Analysis Explored it using Pandas and Matplotlib along with some transformations Used Line, Bar, Stacked Bar and Scatter Plots to visualize",
    "url": "http://localhost:4000/lectures/Week%2006%20-%20Web%20Scraping,%20Databases,%20and%20Other%20Data%20Sources/01.b%20-%20Getting%20Data%20from%20Web%20Pages.html",
    "relUrl": "/lectures/Week%2006%20-%20Web%20Scraping,%20Databases,%20and%20Other%20Data%20Sources/01.b%20-%20Getting%20Data%20from%20Web%20Pages.html"
  },
  "11": {
    "id": "11",
    "title": "01.b - Python Tuples",
    "content": "Python Tuple Python Tuple What is tuple? In Python programming, a tuple is similar to a list. The difference between the two is that we cannot change the elements of a tuple once it is assigned whereas in a list, elements can be changed. Advantages of Tuple over List Since, tuples are quite similiar to lists, both of them are used in similar situations as well. However, there are certain advantages of implementing a tuple over a list. Below listed are some of the main advantages: We generally use tuple for heterogeneous (different) datatypes and list for homogeneous (similar) datatypes. Since tuple are immutable, iterating through tuple is faster than with list. So there is a slight performance boost. Tuples that contain immutable elements can be used as key for a dictionary. With list, this is not possible. If you have data that doesn’t change, implementing it as tuple will guarantee that it remains write-protected. Creating a Tuple A tuple is created by placing all the items (elements) inside a parentheses (), separated by comma. The parentheses are optional but is a good practice to write it. A tuple can have any number of items and they may be of different types (integer, float, list, string etc.). # empty tuple # Output: () my_tuple = () print(type(my_tuple), my_tuple) &lt;class &#39;tuple&#39;&gt; () # tuple having integers # Output: (1, 2, 3) my_tuple = (1, 2, 3) print(my_tuple) (1, 2, 3) # tuple with mixed datatypes # Output: (1, &quot;Hello&quot;, 3.4) my_tuple = (1, &quot;Hello&quot;, 3.4) print(my_tuple) (1, &#39;Hello&#39;, 3.4) # nested tuple # Output: (&quot;mouse&quot;, [8, 4, 6], (1, 2, 3)) my_tuple = (&quot;mouse&quot;, [8, 4, 6], (1, 2, 3)) print(my_tuple) (&#39;mouse&#39;, [8, 4, 6], (1, 2, 3)) # tuple can be created without parentheses # also called tuple packing # Output: 3, 4.6, &quot;dog&quot; my_tuple = 3, 4.6, &quot;dog&quot; print(my_tuple) (3, 4.6, &#39;dog&#39;) Creating a tuple with one element is a bit tricky. Having one element within parentheses is not enough. We will need a trailing comma to indicate that it is in fact a tuple. # only parentheses is not enough # Output: &lt;class &#39;str&#39;&gt; my_tuple = (&quot;hello&quot;) print(type(my_tuple)) &lt;class &#39;str&#39;&gt; # need a comma at the end # Output: &lt;class &#39;tuple&#39;&gt; my_tuple = (&quot;hello&quot;) print(type(my_tuple), my_tuple) &lt;class &#39;str&#39;&gt; hello # what if i forget a comma # Output: &lt;class &#39;tuple&#39;&gt; my_tuple = (&quot;hello&quot; &quot;bye&quot;) print(type(my_tuple), my_tuple) &lt;class &#39;str&#39;&gt; hellobye # parentheses is optional # Output: &lt;class &#39;tuple&#39;&gt; my_tuple = &quot;hello&quot;, print(type(my_tuple)) &lt;class &#39;tuple&#39;&gt; Accessing Elements in a Tuple Indexing n_tuple = (&quot;mouse&quot;, [8, 4, 6], (1, 2, 3)) print(n_tuple[1][2]) 6 n_tuple = (&quot;mouse&quot;, [8, 4, 6], (1, 2, 3)) print(type(n_tuple[0][2]), n_tuple[0][2]) &lt;class &#39;str&#39;&gt; u Negative indexing n_tuple = (&quot;mouse&quot;, [8, 4, 6], (1, 2, 3)) print(n_tuple[-1][-3], &#39; is the same as &#39;, n_tuple[2][0]) 1 is the same as 1 n_tuple = (&quot;mouse&quot;, [8, 4, 6], (1, 2, 3)) print(n_tuple[0][0], &#39; is the same as &#39;, n_tuple[-3][-5]) m is the same as m n_tuple = (&quot;mouse&quot;, [8, 4, 6], (1, 2, 3)) print(n_tuple[-1][1]) 2 Slicing letter_tuple = (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;, &#39;j&#39;) # prints items at position 0, 1, and 2 but not 3 print(letter_tuple[0:3]) (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) # prints items at position 3, 4, and 5 but not 6 print(letter_tuple[3:6]) (&#39;d&#39;, &#39;e&#39;, &#39;f&#39;) # start at the beginning print(letter_tuple[:6]) (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;) # go until the end print(letter_tuple[3:]) (&#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;, &#39;j&#39;) stepping over a tuple (or list) # every element print(letter_tuple[0:10:1]) (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;, &#39;j&#39;) # every 3rd element print(letter_tuple[0:10:3]) (&#39;a&#39;, &#39;d&#39;, &#39;g&#39;, &#39;j&#39;) # elements at even positions print(letter_tuple[0::2]) (&#39;a&#39;, &#39;c&#39;, &#39;e&#39;, &#39;g&#39;, &#39;i&#39;) # elements at odd positions print(letter_tuple[1::2]) (&#39;b&#39;, &#39;d&#39;, &#39;f&#39;, &#39;h&#39;, &#39;j&#39;) reversing a tuple (or list) print(letter_tuple[len(letter_tuple)::-1]) (&#39;j&#39;, &#39;i&#39;, &#39;h&#39;, &#39;g&#39;, &#39;f&#39;, &#39;e&#39;, &#39;d&#39;, &#39;c&#39;, &#39;b&#39;, &#39;a&#39;) print(letter_tuple[len(letter_tuple)::-2]) (&#39;j&#39;, &#39;h&#39;, &#39;f&#39;, &#39;d&#39;, &#39;b&#39;) Changing a Tuple Unlike lists, tuples are immutable. This means that elements of a tuple cannot be changed once it has been assigned. x_tuple = (4, 2, 3, [6, 5]) x_tuple[1] = 8 # throws an error TypeError Traceback (most recent call last) &lt;ipython-input-58-ca0ecf3b2f0d&gt; in &lt;module&gt; 1 x_tuple = (4, 2, 3, [6, 5]) 2 -&gt; 3 x_tuple[1] = 8 # throws an error TypeError: &#39;tuple&#39; object does not support item assignment But, if the element is itself a mutable datatype like list, its nested items can be changed. x_tuple[3][0] = 9 # but item of mutable element can be changed print(x_tuple) (4, 2, 3, [9, 5]) Deleting a Tuple We cannot change the elements in a tuple. That also means we cannot delete or remove items from a tuple. But deleting a tuple entirely is possible using the keyword del. a_tuple = (1, 2, 3) print(a_tuple) (1, 2, 3) del a_tuple print(a_tuple) NameError Traceback (most recent call last) &lt;ipython-input-61-301a8601cf95&gt; in &lt;module&gt; 1 del a_tuple -&gt; 2 print(a_tuple) NameError: name &#39;a_tuple&#39; is not defined Other Tuple Methods count(x) - Return the number of items that is equal to x index(x) - Return index of first item that is equal to x my_tuple = (&#39;r&#39;, &#39;e&#39;, &#39;d&#39;, &#39;&#39;, &#39;a&#39;, &#39;p&#39;, &#39;p&#39;, &#39;l&#39;, &#39;e&#39;,) print(my_tuple.count(&#39;p&#39;)) 2 print(my_tuple.index(&#39;p&#39;)) 5",
    "url": "http://localhost:4000/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/01.b%20-%20Python%20Tuples.html",
    "relUrl": "/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/01.b%20-%20Python%20Tuples.html"
  },
  "12": {
    "id": "12",
    "title": "01.c - JSON Files",
    "content": "JSON Files Working With JSON Data in Python from pprint import pprint # scores dictionary games = { &#39;games&#39;:[ { &#39;date&#39;: &#39;2019-05-01&#39;, &#39;home_team&#39;: &#39;Pirates&#39;, &#39;home_score&#39;: 0, &#39;away_team&#39;: &#39;Cubs&#39;, &#39;away_score&#39;: 10 }, { &#39;date&#39;: &#39;2019-05-15&#39;, &#39;home_team&#39;: &#39;Reds&#39;, &#39;home_score&#39;: 7, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;away_score&#39;: 0 }, { &#39;date&#39;: &#39;2019-05-17&#39;, &#39;home_team&#39;: &#39;Reds&#39;, &#39;home_score&#39;: 12, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;away_score&#39;: 0 }, { &#39;date&#39;: &#39;2019-05-18&#39;, &#39;home_team&#39;: &#39;Reds&#39;, &#39;home_score&#39;: 8, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;away_score&#39;: 0 }, { &#39;date&#39;: &#39;2019-05-21&#39;, &#39;home_team&#39;: &#39;Pirates&#39;, &#39;home_score&#39;: 1, &#39;away_team&#39;: &#39;Brewers&#39;, &#39;away_score&#39;: 11 } ] } pprint(games) {&#39;games&#39;: [{&#39;away_score&#39;: 10, &#39;away_team&#39;: &#39;Cubs&#39;, &#39;date&#39;: &#39;2019-05-01&#39;, &#39;home_score&#39;: 0, &#39;home_team&#39;: &#39;Pirates&#39;}, {&#39;away_score&#39;: 0, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;date&#39;: &#39;2019-05-15&#39;, &#39;home_score&#39;: 7, &#39;home_team&#39;: &#39;Reds&#39;}, {&#39;away_score&#39;: 0, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;date&#39;: &#39;2019-05-17&#39;, &#39;home_score&#39;: 12, &#39;home_team&#39;: &#39;Reds&#39;}, {&#39;away_score&#39;: 0, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;date&#39;: &#39;2019-05-18&#39;, &#39;home_score&#39;: 8, &#39;home_team&#39;: &#39;Reds&#39;}, {&#39;away_score&#39;: 11, &#39;away_team&#39;: &#39;Brewers&#39;, &#39;date&#39;: &#39;2019-05-21&#39;, &#39;home_score&#39;: 1, &#39;home_team&#39;: &#39;Pirates&#39;}]} Python Serialization In this instance, serialization is the process of converting the python objects to JSON. Python object types get serialized to the following JSON types. Python JSON dict object list, tuple array str string int, long, float number True true False false None null import json pprint(games) print() games_json = json.dumps(games) pprint(games_json) {&#39;games&#39;: [{&#39;away_score&#39;: 10, &#39;away_team&#39;: &#39;Cubs&#39;, &#39;date&#39;: &#39;2019-05-01&#39;, &#39;home_score&#39;: 0, &#39;home_team&#39;: &#39;Pirates&#39;}, {&#39;away_score&#39;: 0, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;date&#39;: &#39;2019-05-15&#39;, &#39;home_score&#39;: 7, &#39;home_team&#39;: &#39;Reds&#39;}, {&#39;away_score&#39;: 0, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;date&#39;: &#39;2019-05-17&#39;, &#39;home_score&#39;: 12, &#39;home_team&#39;: &#39;Reds&#39;}, {&#39;away_score&#39;: 0, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;date&#39;: &#39;2019-05-18&#39;, &#39;home_score&#39;: 8, &#39;home_team&#39;: &#39;Reds&#39;}, {&#39;away_score&#39;: 11, &#39;away_team&#39;: &#39;Brewers&#39;, &#39;date&#39;: &#39;2019-05-21&#39;, &#39;home_score&#39;: 1, &#39;home_team&#39;: &#39;Pirates&#39;}]} (&#39;{&quot;games&quot;: [{&quot;date&quot;: &quot;2019-05-01&quot;, &quot;home_team&quot;: &quot;Pirates&quot;, &quot;home_score&quot;: 0, &#39; &#39;&quot;away_team&quot;: &quot;Cubs&quot;, &quot;away_score&quot;: 10}, {&quot;date&quot;: &quot;2019-05-15&quot;, &quot;home_team&quot;: &#39; &#39;&quot;Reds&quot;, &quot;home_score&quot;: 7, &quot;away_team&quot;: &quot;Pirates&quot;, &quot;away_score&quot;: 0}, {&quot;date&quot;: &#39; &#39;&quot;2019-05-17&quot;, &quot;home_team&quot;: &quot;Reds&quot;, &quot;home_score&quot;: 12, &quot;away_team&quot;: &quot;Pirates&quot;, &#39; &#39;&quot;away_score&quot;: 0}, {&quot;date&quot;: &quot;2019-05-18&quot;, &quot;home_team&quot;: &quot;Reds&quot;, &quot;home_score&quot;: &#39; &#39;8, &quot;away_team&quot;: &quot;Pirates&quot;, &quot;away_score&quot;: 0}, {&quot;date&quot;: &quot;2019-05-21&quot;, &#39; &#39;&quot;home_team&quot;: &quot;Pirates&quot;, &quot;home_score&quot;: 1, &quot;away_team&quot;: &quot;Brewers&quot;, &#39; &#39;&quot;away_score&quot;: 11}]}&#39;) # changing whitespace games_json = json.dumps(games, indent=4) print(games_json) { &quot;games&quot;: [ { &quot;date&quot;: &quot;2019-05-01&quot;, &quot;home_team&quot;: &quot;Pirates&quot;, &quot;home_score&quot;: 0, &quot;away_team&quot;: &quot;Cubs&quot;, &quot;away_score&quot;: 10 }, { &quot;date&quot;: &quot;2019-05-15&quot;, &quot;home_team&quot;: &quot;Reds&quot;, &quot;home_score&quot;: 7, &quot;away_team&quot;: &quot;Pirates&quot;, &quot;away_score&quot;: 0 }, { &quot;date&quot;: &quot;2019-05-17&quot;, &quot;home_team&quot;: &quot;Reds&quot;, &quot;home_score&quot;: 12, &quot;away_team&quot;: &quot;Pirates&quot;, &quot;away_score&quot;: 0 }, { &quot;date&quot;: &quot;2019-05-18&quot;, &quot;home_team&quot;: &quot;Reds&quot;, &quot;home_score&quot;: 8, &quot;away_team&quot;: &quot;Pirates&quot;, &quot;away_score&quot;: 0 }, { &quot;date&quot;: &quot;2019-05-21&quot;, &quot;home_team&quot;: &quot;Pirates&quot;, &quot;home_score&quot;: 1, &quot;away_team&quot;: &quot;Brewers&quot;, &quot;away_score&quot;: 11 } ] } # compacting games_json = json.dumps(games, separators=(&#39;,&#39;, &#39;:&#39;)) print(games_json) {&quot;games&quot;:[{&quot;date&quot;:&quot;2019-05-01&quot;,&quot;home_team&quot;:&quot;Pirates&quot;,&quot;home_score&quot;:0,&quot;away_team&quot;:&quot;Cubs&quot;,&quot;away_score&quot;:10},{&quot;date&quot;:&quot;2019-05-15&quot;,&quot;home_team&quot;:&quot;Reds&quot;,&quot;home_score&quot;:7,&quot;away_team&quot;:&quot;Pirates&quot;,&quot;away_score&quot;:0},{&quot;date&quot;:&quot;2019-05-17&quot;,&quot;home_team&quot;:&quot;Reds&quot;,&quot;home_score&quot;:12,&quot;away_team&quot;:&quot;Pirates&quot;,&quot;away_score&quot;:0},{&quot;date&quot;:&quot;2019-05-18&quot;,&quot;home_team&quot;:&quot;Reds&quot;,&quot;home_score&quot;:8,&quot;away_team&quot;:&quot;Pirates&quot;,&quot;away_score&quot;:0},{&quot;date&quot;:&quot;2019-05-21&quot;,&quot;home_team&quot;:&quot;Pirates&quot;,&quot;home_score&quot;:1,&quot;away_team&quot;:&quot;Brewers&quot;,&quot;away_score&quot;:11}]} Writing JSON files with open(&quot;games.json&quot;, &quot;w&quot;) as f: json.dump(games, f) Reading JSON files # open and print line by line with open(&#39;games.json&#39;, &quot;r&quot;) as f: games = json.load(f) print(games) {&#39;games&#39;: [{&#39;date&#39;: &#39;2019-05-01&#39;, &#39;home_team&#39;: &#39;Pirates&#39;, &#39;home_score&#39;: 0, &#39;away_team&#39;: &#39;Cubs&#39;, &#39;away_score&#39;: 10}, {&#39;date&#39;: &#39;2019-05-15&#39;, &#39;home_team&#39;: &#39;Reds&#39;, &#39;home_score&#39;: 7, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;away_score&#39;: 0}, {&#39;date&#39;: &#39;2019-05-17&#39;, &#39;home_team&#39;: &#39;Reds&#39;, &#39;home_score&#39;: 12, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;away_score&#39;: 0}, {&#39;date&#39;: &#39;2019-05-18&#39;, &#39;home_team&#39;: &#39;Reds&#39;, &#39;home_score&#39;: 8, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;away_score&#39;: 0}, {&#39;date&#39;: &#39;2019-05-21&#39;, &#39;home_team&#39;: &#39;Pirates&#39;, &#39;home_score&#39;: 1, &#39;away_team&#39;: &#39;Brewers&#39;, &#39;away_score&#39;: 11}]} Using JSONPath Source One of the biggest strengths of XML is XPath, the query-oriented language to query subsections of an XML document. In the same line, JSONPath is a query language with features similar to XPath that lets you extract just the bits of a JSON document your application needs. JSONPath Syntax As XPath, JSONPath also has syntax to follow: $ – symbol refers to the root object or element. @ – symbol refers to the current object or element. . – operator is the dot-child operator, which you use to denote a child element of the current element. [ ] – is the subscript operator, which you use to denote a child element of the current element (by name or index). * – operator is a wildcard, returning all objects or elements regardless of their names. , – operator is the union operator, which returns the union of the children or indexes indicated. : – operator is the array slice operator, so you can slice collections using the syntax [start:end:step] to return a subcollection of a collection. ( ) – operator lets you pass a script expression in the underlying implementation’s script language. It’s not supported by every implementation of JSONPath, however. ? ( ) – to query all items that meet a certain criteria. There are many online jsonpath validators out there, and I encourage you to try a few. Using JSONPath in Python To use JSONPath, you will need to include its dependency and then use it. The library we’ll use is jsonpath-rw-ext pip install jsonpath-rw-ext Once installed we’re ready to use it. Finding Information about Pirate Games Lets try to parse a JSON file a few different ways. First, we need to load the data as a JSON object into memory. with open(&#39;games.json&#39;, &quot;r&quot;) as f: games = json.load(f) pprint(games) {&#39;games&#39;: [{&#39;away_score&#39;: 10, &#39;away_team&#39;: &#39;Cubs&#39;, &#39;date&#39;: &#39;2019-05-01&#39;, &#39;home_score&#39;: 0, &#39;home_team&#39;: &#39;Pirates&#39;}, {&#39;away_score&#39;: 0, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;date&#39;: &#39;2019-05-15&#39;, &#39;home_score&#39;: 7, &#39;home_team&#39;: &#39;Reds&#39;}, {&#39;away_score&#39;: 0, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;date&#39;: &#39;2019-05-17&#39;, &#39;home_score&#39;: 12, &#39;home_team&#39;: &#39;Reds&#39;}, {&#39;away_score&#39;: 0, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;date&#39;: &#39;2019-05-18&#39;, &#39;home_score&#39;: 8, &#39;home_team&#39;: &#39;Reds&#39;}, {&#39;away_score&#39;: 11, &#39;away_team&#39;: &#39;Brewers&#39;, &#39;date&#39;: &#39;2019-05-21&#39;, &#39;home_score&#39;: 1, &#39;home_team&#39;: &#39;Pirates&#39;}]} Now that the data is loaded, we can try to answer a few questions. What dates were the games played on? # json parsing game_dates = [] for game in games[&#39;games&#39;]: game_date = game[&#39;date&#39;] game_dates.append(game_date) print(game_dates) [&#39;2019-05-01&#39;, &#39;2019-05-15&#39;, &#39;2019-05-17&#39;, &#39;2019-05-18&#39;, &#39;2019-05-21&#39;] # jsonpath parsing # import the library import jsonpath_rw_ext as jp # create a jsonpath expression and match game_dates = jp.match(&quot;$.games[*].date&quot;, games) print(game_dates) [&#39;2019-05-01&#39;, &#39;2019-05-15&#39;, &#39;2019-05-17&#39;, &#39;2019-05-18&#39;, &#39;2019-05-21&#39;] # this also works game_dates = jp.match(&quot;$.games..date&quot;, games) print(game_dates) [&#39;2019-05-01&#39;, &#39;2019-05-15&#39;, &#39;2019-05-17&#39;, &#39;2019-05-18&#39;, &#39;2019-05-21&#39;] What were the scores for the Pirates home games? # json parsing home_scores = [] for game in games[&#39;games&#39;]: if game[&#39;home_team&#39;] == &#39;Pirates&#39;: home_scores.append(game) pprint(home_scores) [{&#39;away_score&#39;: 10, &#39;away_team&#39;: &#39;Cubs&#39;, &#39;date&#39;: &#39;2019-05-01&#39;, &#39;home_score&#39;: 0, &#39;home_team&#39;: &#39;Pirates&#39;}, {&#39;away_score&#39;: 11, &#39;away_team&#39;: &#39;Brewers&#39;, &#39;date&#39;: &#39;2019-05-21&#39;, &#39;home_score&#39;: 1, &#39;home_team&#39;: &#39;Pirates&#39;}] # jsonpath parsing home_scores = jp.match(&quot;$.games[?(@.home_team==&#39;Pirates&#39;)]&quot;, games) pprint(home_scores) [{&#39;away_score&#39;: 10, &#39;away_team&#39;: &#39;Cubs&#39;, &#39;date&#39;: &#39;2019-05-01&#39;, &#39;home_score&#39;: 0, &#39;home_team&#39;: &#39;Pirates&#39;}, {&#39;away_score&#39;: 11, &#39;away_team&#39;: &#39;Brewers&#39;, &#39;date&#39;: &#39;2019-05-21&#39;, &#39;home_score&#39;: 1, &#39;home_team&#39;: &#39;Pirates&#39;}] What were the scores after May 15th # json parsing game_scores = [] for game in games[&#39;games&#39;]: if game[&#39;date&#39;] &gt; &#39;2019-05-15&#39;: game_scores.append(game) pprint(game_scores) [{&#39;away_score&#39;: 0, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;date&#39;: &#39;2019-05-17&#39;, &#39;home_score&#39;: 12, &#39;home_team&#39;: &#39;Reds&#39;}, {&#39;away_score&#39;: 0, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;date&#39;: &#39;2019-05-18&#39;, &#39;home_score&#39;: 8, &#39;home_team&#39;: &#39;Reds&#39;}, {&#39;away_score&#39;: 11, &#39;away_team&#39;: &#39;Brewers&#39;, &#39;date&#39;: &#39;2019-05-21&#39;, &#39;home_score&#39;: 1, &#39;home_team&#39;: &#39;Pirates&#39;}] # jsonpath parsing game_scores = jp.match(&quot;$.games[?(@.date &gt; &#39;2019-05-15&#39;)]&quot;, games) pprint(game_scores) [{&#39;away_score&#39;: 0, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;date&#39;: &#39;2019-05-17&#39;, &#39;home_score&#39;: 12, &#39;home_team&#39;: &#39;Reds&#39;}, {&#39;away_score&#39;: 0, &#39;away_team&#39;: &#39;Pirates&#39;, &#39;date&#39;: &#39;2019-05-18&#39;, &#39;home_score&#39;: 8, &#39;home_team&#39;: &#39;Reds&#39;}, {&#39;away_score&#39;: 11, &#39;away_team&#39;: &#39;Brewers&#39;, &#39;date&#39;: &#39;2019-05-21&#39;, &#39;home_score&#39;: 1, &#39;home_team&#39;: &#39;Pirates&#39;}]",
    "url": "http://localhost:4000/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/01.c%20-%20JSON%20Files.html",
    "relUrl": "/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/01.c%20-%20JSON%20Files.html"
  },
  "13": {
    "id": "13",
    "title": "01.c - Loops",
    "content": "for loops # for loops for i in range(1, 10, 2): print(i) 1 3 5 7 9 # for...else loop for i in range(1, 5): print(i) else: print(&#39;done&#39;) 1 2 3 4 done # for...else loop with a break for i in range(1, 5): print(i) if i % 2 == 0: break else: print(&#39;done&#39;) 1 2 while loops # while loop condition = True i = 0 while condition: print(i) i += 1 if i &gt; 3: condition = False 0 1 2 3 # while...else loop condition = True i = 0 while condition: print(i) i += 1 if i &gt; 3: condition = False else: print(&#39;done&#39;) 0 1 2 3 done # while...else loop with a break condition = True i = 0 while condition: print(i) i += 1 if i &gt; 3: break else: print(&#39;done&#39;) 0 1 2 3 nested loops width = 5 chars = &quot;*@&quot; for char in chars: for i in range(1, width): print(char * i) for j in range(width, 0, -1): print(char * j) * ** *** **** ***** **** *** ** * @ @@ @@@ @@@@ @@@@@ @@@@ @@@ @@ @ width = 5 chars = &quot;*@&quot; for char in chars: for i in range(1, width): for spaces in range(width - i, 0, -1): print(&#39; &#39;, end=&#39;&#39;) print(char * i) for j in range(width, 0, -1): for spaces in range(width - j, 0, -1): print(&#39; &#39;, end=&#39;&#39;) print(char * j) * ** *** **** ***** **** *** ** * @ @@ @@@ @@@@ @@@@@ @@@@ @@@ @@ @",
    "url": "http://localhost:4000/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/01.c%20-%20Loops.html",
    "relUrl": "/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/01.c%20-%20Loops.html"
  },
  "14": {
    "id": "14",
    "title": "01.d - XML Files",
    "content": "XML Files Python XML with ElementTree: Beginner’s Guide # scores dictionary scores_xml = &quot;&quot;&quot; &lt;?xml version=&quot;1.0&quot;?&gt; &lt;scores&gt; &lt;score&gt; &lt;date&gt;2019-05-01&lt;/date&gt; &lt;home-team&gt;Pirates&lt;/home-team&gt; &lt;home-score&gt;0&lt;/home-score&gt; &lt;away-team&gt;Cubs&lt;/away-team&gt; &lt;away-score&gt;10&lt;/away-score&gt; &lt;/score&gt; &lt;score&gt; &lt;date&gt;2019-05-15&lt;/date&gt; &lt;home-team&gt;Reds&lt;/home-team&gt; &lt;home-score&gt;7&lt;/home-score&gt; &lt;away-team&gt;Pirates&lt;/away-team&gt; &lt;away-score&gt;0&lt;/away-score&gt; &lt;/score&gt; &lt;/scores&gt; &quot;&quot;&quot; print(scores_xml) &lt;?xml version=&quot;1.0&quot;?&gt; &lt;scores&gt; &lt;score&gt; &lt;date&gt;2019-05-01&lt;/date&gt; &lt;home-team&gt;Pirates&lt;/home-team&gt; &lt;home-score&gt;0&lt;/home-score&gt; &lt;away-team&gt;Cubs&lt;/away-team&gt; &lt;away-score&gt;10&lt;/away-score&gt; &lt;/score&gt; &lt;score&gt; &lt;date&gt;2019-05-15&lt;/date&gt; &lt;home-team&gt;Reds&lt;/home-team&gt; &lt;home-score&gt;7&lt;/home-score&gt; &lt;away-team&gt;Pirates&lt;/away-team&gt; &lt;away-score&gt;0&lt;/away-score&gt; &lt;/score&gt; &lt;/scores&gt; scores_xsd = &quot;&quot;&quot; &lt;xs:schema attributeFormDefault=&quot;unqualified&quot; elementFormDefault=&quot;qualified&quot; xmlns:xs=&quot;http://www.w3.org/2001/XMLSchema&quot;&gt; &lt;xs:element name=&quot;scores&quot;&gt; &lt;xs:complexType&gt; &lt;xs:sequence&gt; &lt;xs:element name=&quot;score&quot; maxOccurs=&quot;unbounded&quot; minOccurs=&quot;0&quot;&gt; &lt;xs:complexType&gt; &lt;xs:sequence&gt; &lt;xs:element type=&quot;xs:date&quot; name=&quot;date&quot;/&gt; &lt;xs:element type=&quot;xs:string&quot; name=&quot;home-team&quot;/&gt; &lt;xs:element type=&quot;xs:int&quot; name=&quot;home-score&quot;/&gt; &lt;xs:element type=&quot;xs:string&quot; name=&quot;away-team&quot;/&gt; &lt;xs:element type=&quot;xs:int&quot; name=&quot;away-score&quot;/&gt; &lt;/xs:sequence&gt; &lt;/xs:complexType&gt; &lt;/xs:element&gt; &lt;/xs:sequence&gt; &lt;/xs:complexType&gt; &lt;/xs:element&gt; &lt;/xs:schema&gt; &quot;&quot;&quot; print(scores_xsd) &lt;xs:schema attributeFormDefault=&quot;unqualified&quot; elementFormDefault=&quot;qualified&quot; xmlns:xs=&quot;http://www.w3.org/2001/XMLSchema&quot;&gt; &lt;xs:element name=&quot;scores&quot;&gt; &lt;xs:complexType&gt; &lt;xs:sequence&gt; &lt;xs:element name=&quot;score&quot; maxOccurs=&quot;unbounded&quot; minOccurs=&quot;0&quot;&gt; &lt;xs:complexType&gt; &lt;xs:sequence&gt; &lt;xs:element type=&quot;xs:date&quot; name=&quot;date&quot;/&gt; &lt;xs:element type=&quot;xs:string&quot; name=&quot;home-team&quot;/&gt; &lt;xs:element type=&quot;xs:int&quot; name=&quot;home-score&quot;/&gt; &lt;xs:element type=&quot;xs:string&quot; name=&quot;away-team&quot;/&gt; &lt;xs:element type=&quot;xs:int&quot; name=&quot;away-score&quot;/&gt; &lt;/xs:sequence&gt; &lt;/xs:complexType&gt; &lt;/xs:element&gt; &lt;/xs:sequence&gt; &lt;/xs:complexType&gt; &lt;/xs:element&gt; &lt;/xs:schema&gt; Parsing using ElementTree import xml.etree.ElementTree as ET tree = ET.parse(&#39;scores.xml&#39;) root = tree.getroot() print(root.tag) scores print(root.attrib) {&#39;{http://www.w3.org/2001/XMLSchema-instance}noNamespaceSchemaLocation&#39;: &#39;scores.xsd&#39;} for loops for child in root: print(child.tag, child.attrib) score {} score {} Typically it is helpful to know all the elements in the entire tree. A useful function for doing that is root.iter(). You can put this function into a “for” loop and it will iterate over the entire tree. for elem in root.iter(): print(elem.tag) scores score date home-team home-score away-team away-score score date home-team home-score away-team away-score If you need to print the entire string you can use ElementTree.tostring(). However, you must specify both the encoding and decoding of the document you are displaying as the string because ElementTree is a powerful library that can interpret more than just XML, For XMLs, use utf8 - this is the typical document format type for an XML. print(ET.tostring(root, encoding=&#39;utf8&#39;).decode(&#39;utf8&#39;)) &lt;?xml version=&#39;1.0&#39; encoding=&#39;utf8&#39;?&gt; &lt;scores xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;scores.xsd&quot;&gt; &lt;score&gt; &lt;date&gt;2019-05-01&lt;/date&gt; &lt;home-team&gt;Pirates&lt;/home-team&gt; &lt;home-score&gt;0&lt;/home-score&gt; &lt;away-team&gt;Cubs&lt;/away-team&gt; &lt;away-score&gt;10&lt;/away-score&gt; &lt;/score&gt; &lt;score&gt; &lt;date&gt;2019-05-15&lt;/date&gt; &lt;home-team&gt;Reds&lt;/home-team&gt; &lt;home-score&gt;7&lt;/home-score&gt; &lt;away-team&gt;Pirates&lt;/away-team&gt; &lt;away-score&gt;0&lt;/away-score&gt; &lt;/score&gt; &lt;/scores&gt; Iterating over specific elements for game_date in root.iter(&#39;date&#39;): print(game_date.text) 2019-05-01 2019-05-15 XPath Expressions for score in root.findall(&#39;./score[date=&quot;2019-05-01&quot;]/date&#39;): print(score.text) 2019-05-01 Writing xml files tree.write(&quot;scores2.xml&quot;)",
    "url": "http://localhost:4000/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/01.d%20-%20XML%20Files.html",
    "relUrl": "/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/01.d%20-%20XML%20Files.html"
  },
  "15": {
    "id": "15",
    "title": "02 - Basic Medical Data Visualization",
    "content": "Basic Medical Data Exploration Visualization  Heart Diseases Source In this lecture we’re going to learn how to use matplotlib and seaborn by following along with the following example. As always, the source author’s link is listed for reference. This page will evolve over time. Dataset The dataset we’ll use here is the Heart Disease Data Set containing 302 patient data each with 75 attributes. However, this example only uses 14 of them which can be seen below. The columns used include: age: age in years sex: sex 1 = male 0 = female cp: chest pain type Value 1: typical angina Value 2: atypical angina Value 3: non-anginal pain Value 4: asymptomatic trestbps: resting blood pressure (in mm Hg on admission to the hospital) chol: serum cholestoral in mg/dl fbs: fasting blood sugar &gt; 120 mg/dl 1 = true 0 = false restecg: restecg: resting electrocardiographic results Value 0: normal Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of &gt; 0.05 mV) Value 2: showing probable or definite left ventricular hypertrophy by Estes’ criteria thalach: maximum heart rate achieved exang: exercise induced angina 1 = yes 0 = no oldpeak: ST depression induced by exercise relative to rest slope: the slope of the peak exercise ST segment Value 1: upsloping Value 2: flat Value 3: downsloping ca: number of major vessels (0-3) colored by flourosopy thal: 3 = normal 6 = fixed defect 7 = reversable defect num: diagnosis of heart disease (angiographic disease status) Value 0: &lt; 50% diameter narrowing Value 1: &gt; 50% diameter narrowing columns = [&quot;age&quot;, &quot;sex&quot;, &quot;cp&quot;, &quot;trestbps&quot;, &quot;chol&quot;, &quot;fbs&quot;, &quot;restecg&quot;, &quot;thalach&quot;, &quot;exang&quot;, &quot;oldpeak&quot;, &quot;slope&quot;, &quot;ca&quot;, &quot;thal&quot;, &quot;num&quot;] # disable warnings for lecture import warnings warnings.filterwarnings(&#39;ignore&#39;) Overview of the Data Set , Cleaning, and Viewing import pandas as pd # import the data and see the basic description df = pd.read_csv(&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data&quot;) df.columns = columns print(&quot;- Describe -&quot;) print(df.describe()) - Describe - age sex cp trestbps chol fbs count 302.000000 302.000000 302.000000 302.000000 302.000000 302.000000 mean 54.410596 0.678808 3.165563 131.645695 246.738411 0.145695 std 9.040163 0.467709 0.953612 17.612202 51.856829 0.353386 min 29.000000 0.000000 1.000000 94.000000 126.000000 0.000000 25% 48.000000 0.000000 3.000000 120.000000 211.000000 0.000000 50% 55.500000 1.000000 3.000000 130.000000 241.500000 0.000000 75% 61.000000 1.000000 4.000000 140.000000 275.000000 0.000000 max 77.000000 1.000000 4.000000 200.000000 564.000000 1.000000 restecg thalach exang oldpeak slope num count 302.000000 302.000000 302.000000 302.000000 302.000000 302.000000 mean 0.986755 149.605960 0.327815 1.035430 1.596026 0.940397 std 0.994916 22.912959 0.470196 1.160723 0.611939 1.229384 min 0.000000 71.000000 0.000000 0.000000 1.000000 0.000000 25% 0.000000 133.250000 0.000000 0.000000 1.000000 0.000000 50% 0.500000 153.000000 0.000000 0.800000 2.000000 0.000000 75% 2.000000 166.000000 1.000000 1.600000 2.000000 2.000000 max 2.000000 202.000000 1.000000 6.200000 3.000000 4.000000 print(&#39;- Info --&#39;) print(df.info()) - Info -- &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 302 entries, 0 to 301 Data columns (total 14 columns): age 302 non-null float64 sex 302 non-null float64 cp 302 non-null float64 trestbps 302 non-null float64 chol 302 non-null float64 fbs 302 non-null float64 restecg 302 non-null float64 thalach 302 non-null float64 exang 302 non-null float64 oldpeak 302 non-null float64 slope 302 non-null float64 ca 302 non-null object thal 302 non-null object num 302 non-null int64 dtypes: float64(11), int64(1), object(2) memory usage: 33.1+ KB None We notice above that the ca and thal data elements are objects which we’ll likely want to remap. Let’s take a look at the data. df[&#39;thal&#39;].unique() array([&#39;3.0&#39;, &#39;7.0&#39;, &#39;6.0&#39;, &#39;?&#39;], dtype=object) df[&#39;ca&#39;].unique() array([&#39;3.0&#39;, &#39;2.0&#39;, &#39;0.0&#39;, &#39;1.0&#39;, &#39;?&#39;], dtype=object) From the codbook above we see these are coded values that we can remap. # Replace Every Number greater than 0 to 1 to mark heart disease df.loc[df[&#39;num&#39;] &gt; 0 , &#39;num&#39;] = 1 df.ca = pd.to_numeric(df.ca, errors=&#39;coerce&#39;).fillna(0) df.thal = pd.to_numeric(df.thal, errors=&#39;coerce&#39;).fillna(0) df[&#39;thal&#39;].unique() array([3., 7., 6., 0.]) df[&#39;ca&#39;].unique() array([3., 2., 0., 1.]) Now we can view the datatypes of the remapped data to float64 and int64. print(&#39;- Dtype -&#39;) print(df.dtypes) - Dtype - age float64 sex float64 cp float64 trestbps float64 chol float64 fbs float64 restecg float64 thalach float64 exang float64 oldpeak float64 slope float64 ca float64 thal float64 num int64 dtype: object Next we’ll want to print(&#39;- Null Data -&#39;) # count how many null values exist print(df.isnull().sum()) - Null Data - age 0 sex 0 cp 0 trestbps 0 chol 0 fbs 0 restecg 0 thalach 0 exang 0 oldpeak 0 slope 0 ca 0 thal 0 num 0 dtype: int64 # quickly check to see if there are any null values print(df.isnull().values.any()) False After doing simple clean up, changing non-numerical value to NaN and replacing NaN with 0 we can safely say our data is somewhat clean. First / Last 10 Rows # print the first 10 and last 10 print(&#39; First 10 -&#39;) df.head(10) First 10 - age sex cp trestbps chol fbs restecg thalach exang oldpeak slope ca thal num 0 67.0 1.0 4.0 160.0 286.0 0.0 2.0 108.0 1.0 1.5 2.0 3.0 3.0 1 1 67.0 1.0 4.0 120.0 229.0 0.0 2.0 129.0 1.0 2.6 2.0 2.0 7.0 1 2 37.0 1.0 3.0 130.0 250.0 0.0 0.0 187.0 0.0 3.5 3.0 0.0 3.0 0 3 41.0 0.0 2.0 130.0 204.0 0.0 2.0 172.0 0.0 1.4 1.0 0.0 3.0 0 4 56.0 1.0 2.0 120.0 236.0 0.0 0.0 178.0 0.0 0.8 1.0 0.0 3.0 0 5 62.0 0.0 4.0 140.0 268.0 0.0 2.0 160.0 0.0 3.6 3.0 2.0 3.0 1 6 57.0 0.0 4.0 120.0 354.0 0.0 0.0 163.0 1.0 0.6 1.0 0.0 3.0 0 7 63.0 1.0 4.0 130.0 254.0 0.0 2.0 147.0 0.0 1.4 2.0 1.0 7.0 1 8 53.0 1.0 4.0 140.0 203.0 1.0 2.0 155.0 1.0 3.1 3.0 0.0 7.0 1 9 57.0 1.0 4.0 140.0 192.0 0.0 0.0 148.0 0.0 0.4 2.0 0.0 6.0 0 # Last 10 print(&#39; Last 10 -&#39;) df.tail(10) Last 10 - age sex cp trestbps chol fbs restecg thalach exang oldpeak slope ca thal num 292 63.0 1.0 4.0 140.0 187.0 0.0 2.0 144.0 1.0 4.0 1.0 2.0 7.0 1 293 63.0 0.0 4.0 124.0 197.0 0.0 0.0 136.0 1.0 0.0 2.0 0.0 3.0 1 294 41.0 1.0 2.0 120.0 157.0 0.0 0.0 182.0 0.0 0.0 1.0 0.0 3.0 0 295 59.0 1.0 4.0 164.0 176.0 1.0 2.0 90.0 0.0 1.0 2.0 2.0 6.0 1 296 57.0 0.0 4.0 140.0 241.0 0.0 0.0 123.0 1.0 0.2 2.0 0.0 7.0 1 297 45.0 1.0 1.0 110.0 264.0 0.0 0.0 132.0 0.0 1.2 2.0 0.0 7.0 1 298 68.0 1.0 4.0 144.0 193.0 1.0 0.0 141.0 0.0 3.4 2.0 2.0 7.0 1 299 57.0 1.0 4.0 130.0 131.0 0.0 0.0 115.0 1.0 1.2 2.0 1.0 7.0 1 300 57.0 0.0 2.0 130.0 236.0 0.0 2.0 174.0 0.0 0.0 2.0 1.0 3.0 1 301 38.0 1.0 3.0 138.0 175.0 0.0 0.0 173.0 0.0 0.0 1.0 0.0 3.0 0 Plotting Histograms After reviewing the data in tabular form we want to visualize all of the data across the variables. We can do this easily with a histogram. # import matplotlib import matplotlib.pyplot as plt %matplotlib inline # using pandas to generate the plots df.hist() # using matplotlib to render (or show) the plot plt.show() # get the histogram of every data points fig = plt.figure(figsize = (18, 18)) ax = fig.gca() df.hist(ax=ax, bins=30) plt.show() With simple histogram of our data, we can easily observe the distribution of different attributes. One thing to note here is the fact that it is extremely easy for us to see which attributes are categorical values and which are not. We can inspect a little bit more closely and take a look at the distribution of ages and fbs (fasting blood sugar). We can see that the age distribution is closely resembling of Gaussian distribution while fbs is a categorical value. # import seaborn import seaborn as sns # a closer look at age plt.figure(figsize=(8, 8)) sns.distplot(df.age) plt.show() plt.close(&#39;all&#39;) # a closer look at fbs plt.figure(figsize=(8, 8)) sns.distplot(df.fbs) plt.show() Variance-Covariance Matrix We can calculate variance-covariance matrices in a number of ways. First we’ll use Numpy and then we’ll use the built-in Dataframe functrion. Once calculated, we can observe that most attributes do not have a strong covariance relationship. import numpy as np from numpy import dot # calculate the Variance-Covariance Matrix sample = df.values sample = sample - dot(np.ones((sample.shape[0],sample.shape[0])),sample)/(len(sample)-1) covv = dot(sample.T,sample)/(len(sample)-1) plt.figure(figsize=(8,8)) sns.heatmap(covv) plt.show() # compare with built in plt.figure(figsize=(8,8)) sns.heatmap(df.cov()) plt.show() Correlation matrix Similarly, the first image is created by manual numpy calculation and the second using the bulit-in method. Ee can observe that among the attributes there are actually strong correlation with one another. (especially heart disease and thal). # calculate correaltion matrix sample = df.values certering_mat = np.diag(np.ones((302))) - np.ones((302,302))/302 std_matrix = np.diag(np.std(sample,0)) temp = dot(certering_mat,dot(sample, np.linalg.inv(std_matrix) )) temp = dot(temp.T,temp)/len(sample) # plot plt.figure(figsize=(13, 13)) sns.heatmap(np.around(temp,2),annot=True,fmt=&quot;.2f&quot;,cmap=&quot;Blues&quot;,annot_kws={&quot;size&quot;: 15}) plt.show() # correaltion matrix sns.set(font_scale=2) plt.figure(figsize=(13,13)) sns.heatmap(df.corr().round(2),annot=True,fmt=&quot;.2f&quot;,cmap=&quot;Blues&quot;,annot_kws={&quot;size&quot;: 15}) plt.show() Interactive Histogram # plot the people who have heart vs not plt.figure(figsize=(13, 13)) sns.distplot(df.age[df.num==0], label=&#39;No Disease&#39;, color=&#39;blue&#39;) sns.distplot(df.age[df.num==1], label=&#39;Disease&#39;, color=&#39;Red&#39;) sns.distplot(df.trestbps[df.num==0],label= &#39;No Disease&#39;, color=&#39;Green&#39;) sns.distplot(df.trestbps[df.num==1], label=&#39;Disease&#39;, color=&#39;violet&#39;) plt.legend() plt.show() %matplotlib inline import pygal from IPython.display import SVG, HTML html_pygal = &quot;&quot;&quot; &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;http://kozea.github.com/pygal.js/javascripts/svg.jquery.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;http://kozea.github.com/pygal.js/javascripts/pygal-tooltips.js&quot;&gt;&lt;/script&gt; &lt;!-- ... --&gt; &lt;/head&gt; &lt;body&gt; &lt;figure&gt; {pygal_render} &lt;/figure&gt; &lt;/body&gt; &lt;/html&gt; &quot;&quot;&quot; hist = pygal.Histogram() count, division = np.histogram(df.age[df.num==0].values,bins=100) temp = [] for c,div in zip(count,division): temp.append((c,div,div+1)) count, division = np.histogram(df.age[df.num==1].values,bins=100) temp1 = [] for c,div in zip(count,division): temp1.append((c,div,div+1)) count, division = np.histogram(df.trestbps[df.num==0].values,bins=100) temp2 = [] for c,div in zip(count,division): temp2.append((c,div,div+1)) count, division = np.histogram(df.trestbps[df.num==1].values,bins=100) temp3 = [] for c,div in zip(count,division): temp3.append((c,div,div+1)) hist.add(&#39;No Disease age&#39;, temp) hist.add(&#39;Disease age&#39;, temp1) hist.add(&#39;No Disease &#39;, temp2) hist.add(&#39;Disease&#39;, temp3) hist.render() HTML(html_pygal.format(pygal_render=hist.render())) &lt;!DOCTYPE html&gt; b&#39; n",
    "url": "http://localhost:4000/lectures/Week%2004%20-%20Numpy,%20Pandas,%20Graphing%20&%20Visualization/02%20-%20Basic%20Medical%20Data%20Visualization.html",
    "relUrl": "/lectures/Week%2004%20-%20Numpy,%20Pandas,%20Graphing%20&%20Visualization/02%20-%20Basic%20Medical%20Data%20Visualization.html"
  },
  "16": {
    "id": "16",
    "title": "02 - Lists and List Comprehensions",
    "content": "Python List Comprehensions Python List Comprehension Tutorial When doing data science, you might find yourself wanting to read lists of lists, filtering column names, removing vowels from a list or flattening a matrix. You can easily use a lambda function or a for loop; As you well know, there are multiple ways to go about this. One other way to do this is by using list comprehensions. Python List Comprehension List comprehensions are used to create lists programatically. List comprehensions in Python are constructed as follows: list_variable = [x for x in iterable] List Comprehension in Python: The Mathematics Remember in maths, the common ways to describe lists (or sets, or tuples, or vectors) are: S = {x² : x in {0 ... 9}} V = (1, 2, 4, 8, ..., 2¹²) M = {x | x in S and x even} In other words, you’ll find that the above definitions actually tell you the following: The sequence S is actually a sequence that contains values between 0 and 9 included that are raised to the power of two. The sequence V, on the other hand, contains the value 2 that is raised to a certain power. For the first element in the sequence, this is 0, for the second this is 1, and so on, until you reach 12. Lastly, the sequence M contains elements from the sequence S, but only the even ones. If the above definitions give you a headache, take a look at the actual lists that these definitions would produce: S = {0, 1, 4, 9, 16, 25, 36, 49, 64, 81} V = {1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096} M = {0, 4, 16, 36, 64} # S = {x² : x in {0 ... 9}} S = [] for x in range(10): S.append(x**2) print(S) [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] # S = {x² : x in {0 ... 9}} S = [x**2 for x in range(10)] print(S) [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] The list S is built up with the square brackets that you read above in the first section. In those brackets, you see that there is an element x, which is raised to the power of 10. Now, you just need to know for how many values (and which values!) you need to raise to the power of 2. This is determined in range(10). Considering all of this, you can derive that you’ll raise all numbers, going from 0 to 9, to the power of 2. # V = (1, 2, 4, 8, ..., 2¹²) V = [] for i in range(13): V.append(2**i) print(V) [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096] # V = (1, 2, 4, 8, ..., 2¹²) V = [2**i for i in range(13)] print(V) [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096] The list V contains the base value 2, which is raised to a certain power. Just like before, now you need to know which power or i is exactly going to be used to do this. You see that i in this case is part of range(13), which means that you start from 0 and go until 12. All of this means that your list is going to have 13 values - those values will be 2 raised to the power 0, 1, 2, … all the way up to 12. # M = {x | x in S and x even} M = [] for x in S: if x % 2 == 0: M.append(x) print(M) [0, 4, 16, 36, 64] # M = {x | x in S and x even} M = [x for x in S if x % 2 == 0] print(M) [0, 4, 16, 36, 64] Lastly, the list M contains elements that are part of S if -and only if- they can be divided by 2 without having any leftovers. The modulo needs to be 0. In other words, the list M is built up with the equal values that are stored in list S. List Comprehension as an Alternative to… List comprehension is a complete substitute to for loops, lambda function as well as the functions map(), filter() and reduce(). For Loops List comprehensions are actually good alternatives to for loops, as they are more compact. For Loop Example numbers = range(0, 10) # Initialize `new_list` new_list = [] # Add values to `new_list` for n in numbers: if n % 2 == 0: new_list.append(n**2) # Print `new_list` print(new_list) [0, 4, 16, 36, 64] List Comprehension Alternative to For Loop numbers = range(0, 10) # Create `new_list` new_list = [n**2 for n in numbers if n%2==0] # Print `new_list` print(new_list) [0, 4, 16, 36, 64] Which is faster? Let’s study the difference in performance between the list comprehension and the for loop with a small test: you can set this up very quickly with the timeit library, which you can use to time small bits of Python code in a simple way. In this case, the small pieces of code that you will test are the for loop, which you will put in a function called power_two() for your convenience, and the exact list comprehension which you have formulated above. # Import `timeit` import timeit # Print the execution time print(timeit.timeit(&#39;[n**2 for n in range(10) if n%2==0]&#39;, number=10000)) 0.02252801500003443 # Define `power_two()` def power_two(numbers): for n in numbers: if n%2==0: new_list.append(n**2) return new_list print(timeit.timeit(&#39;power_two(numbers)&#39;, globals=globals(), number=10000)) 0.02238564399999632 Lambda Functions with map(), filter() and reduce() Lambda functions are also called “anonymous functions” or “functions without name”. That means that you only use this type of functions when they are created. Lambda functions borrow their name from the lambda keyword in Python, which is used to declare these functions instead of the standard def keyword. You usually use these functions together with the map(), filter(), and reduce() functions. Replace map() and Lambda Functions with List Comprehensions Map Example # Initialize the `kilometer` list kilometer = [39.2, 36.5, 37.3, 37.8] # Construct `feet` with `map()` feet = map(lambda x: float(3280.8399)*x, kilometer) # Print `feet` as a list print(type(feet), list(feet)) &lt;class &#39;map&#39;&gt; [128608.92408000001, 119750.65635, 122375.32826999998, 124015.74822] List Comprehension Alternative to Map # Convert `kilometer` to `feet` feet = [] for x in kilometer: feet.append(float(3280.8399)*x) print(feet) [128608.92408000001, 119750.65635, 122375.32826999998, 124015.74822] # Convert `kilometer` to `feet` feet = [float(3280.8399)*x for x in kilometer] # Print `feet` print(feet) [128608.92408000001, 119750.65635, 122375.32826999998, 124015.74822] Replace filter() and Lambda Functions with List Comprehensions Filter Example # Filter `feet` to only include uneven distances uneven = filter(lambda x: x % 2, feet) # Check the type of `uneven` type(uneven) # Print `uneven` as a list print(list(uneven)) [128608.92408000001, 119750.65635, 122375.32826999998, 124015.74822] List Comprehension Alternative to Filter # Constructing `feet` feet = [int(x) for x in feet] # Print `feet` print(feet) # Get all uneven distances uneven = [True if x%2 else False for x in feet] # Print `uneven` print(uneven) [128608, 119750, 122375, 124015] [False, False, True, True] Replace reduce() and Lambda Functions with List Comprehensions Reduce Example # Import `reduce` from `functools` from functools import reduce # Reduce `feet` to `reduced_feet` reduced_feet = reduce(lambda x,y: x+y, feet) # Print `reduced_feet` print(reduced_feet) 494748 List Comprehension Alternative to Reduce # Construct `reduced_feet` reduced_feet = sum([float(3280.8399)*x for x in kilometer]) # Print `reduced_feet` print(reduced_feet) 494750.65692000004 List Comprehensions with Conditionals # Define `uneven` uneven = [int(x) for x in feet if x%2] # Print `uneven` print(uneven) [122375, 124015] Multiple If Conditions Example divided = [] for x in range(100): if x%2 == 0 : if x%6 == 0: divided.append(x) print(divided) [0, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96] List Comprehension Alternative divided = [x for x in range(100) if x % 2 == 0 if x % 6 == 0] print(divided) [0, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96] if…else Conditions Example values = [] for x in feet: if x &gt;= 120000: x + 1 else: x + 5 values.append(x) print(values) [128608, 119750, 122375, 124015] List Comprehension Alternative values = [x+1 if x &gt;= 120000 else x+5 for x in feet] print(values) [128609, 119755, 122376, 124016] Nested List Comprehensions Apart from conditionals, you can also adjust your list comprehensions by nesting them within other list comprehensions. This is handy when you want to work with lists of lists: generating lists of lists, transposing lists of lists or flattening lists of lists to regular lists, for example, becomes extremely easy with nested list comprehensions. You see that most of the keywords and elements that are used in the example of the nested list comprehension are similar to the ones that you used in the simple list comprehension examples: Square brackets Two for keywords, followed by a variable that symbolizes an item of the list of lists (x) and a list item of a nested list (y); And Two in keywords, followed by a list of lists (list_of_list) and a list item (x). list_of_list = [[1,2,3],[4,5,6],[7,8]] print(list_of_list) print(list_of_list[0]) print(list_of_list[1]) print(list_of_list[1][1]) print(list_of_list[2]) [[1, 2, 3], [4, 5, 6], [7, 8]] [1, 2, 3] [4, 5, 6] 5 [7, 8] # Flatten `list_of_list` flat = [] for x in list_of_list: for y in x: flat.append(y) print(flat) [1, 2, 3, 4, 5, 6, 7, 8] # Flatten `list_of_list` flat = [y for x in list_of_list for y in x] print(flat) [1, 2, 3, 4, 5, 6, 7, 8] Let’s now consider another example, where you see that you can also use two pairs of square brackets to change the logic of your nested list comprehension: matrix = [[1,2,3], [4,5,6],[7,8,9]] [[row[i] for row in matrix] for i in range(len(matrix))] [[1, 4, 7], [2, 5, 8], [3, 6, 9]] Now practice: rewrite the code chunk above to a nested for loop. If you need some pointers on how to tackle this exercise, go to one of the previous sections of this tutorial. transposed = [] for i in range(len(matrix)): transposed_row = [] for row in matrix: transposed_row.append(row[i]) transposed.append(transposed_row) print(transposed) [[1, 4, 7], [2, 5, 8], [3, 6, 9]] You can also use nested list comprehensions when you need to create a list of lists that is actually a matrix. Check out the following example: matrix = [] for x in range(3): nested = [] matrix.append(nested) for row in range(4): nested.append(0) print(matrix) [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]] # rewritten as a list comprehension matrix = [[0 for col in range(4)] for row in range(3)] matrix [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]",
    "url": "http://localhost:4000/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/02%20-%20Lists%20and%20List%20Comprehensions.html",
    "relUrl": "/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/02%20-%20Lists%20and%20List%20Comprehensions.html"
  },
  "17": {
    "id": "17",
    "title": "02 - NumPy Data analysis",
    "content": "NumPy Tutorial: Data analysis with Python Source NumPy is a commonly used Python data analysis package. By using NumPy, you can speed up your workflow, and interface with other packages in the Python ecosystem, like scikit-learn, that use NumPy under the hood. NumPy was originally developed in the mid 2000s, and arose from an even older package called Numeric. This longevity means that almost every data analysis or machine learning package for Python leverages NumPy in some way. In this tutorial, we’ll walk through using NumPy to analyze data on wine quality. The data contains information on various attributes of wines, such as pH and fixed acidity, along with a quality score between 0 and 10 for each wine. The quality score is the average of at least 3 human taste testers. As we learn how to work with NumPy, we’ll try to figure out more about the perceived quality of wine. The wines we’ll be analyzing are from the Minho region of Portugal. The data was downloaded from the UCI Machine Learning Repository, and is available here. Here are the first few rows of the winequality-red.csv file, which we’ll be using throughout this tutorial: &quot;fixed acidity&quot;;&quot;volatile acidity&quot;;&quot;citric acid&quot;;&quot;residual sugar&quot;;&quot;chlorides&quot;;&quot;free sulfur dioxide&quot;;&quot;total sulfur dioxide&quot;;&quot;density&quot;;&quot;pH&quot;;&quot;sulphates&quot;;&quot;alcohol&quot;;&quot;quality&quot; 7.4;0.7;0;1.9;0.076;11;34;0.9978;3.51;0.56;9.4;5 7.8;0.88;0;2.6;0.098;25;67;0.9968;3.2;0.68;9.8;5 The data is in what I’m going to call ssv (semicolon separated values) format – each record is separated by a semicolon (;), and rows are separated by a new line. There are 1600 rows in the file, including a header row, and 12 columns. Before we get started, a quick version note – we’ll be using Python 3.5. Our code examples will be done using Jupyter notebook. If you want to jump right into a specific area, here are the topics: Creating an Array Reading Text Files Array Indexing N-Dimensional Arrays Data Types Array Math Array Methods Array Comparison and Filtering Reshaping and Combining Arrays Lists Of Lists for CSV Data Before using NumPy, we’ll first try to work with the data using Python and the csv package. We can read in the file using the csv.reader object, which will allow us to read in and split up all the content from the ssv file. In the below code, we: Import the csv library. Open the winequality-red.csv file. With the file open, create a new csv.reader object. Pass in the keyword argument delimiter=”;” to make sure that the records are split up on the semicolon character instead of the default comma character. Call the list type to get all the rows from the file. Assign the result to wines. import csv with open(&quot;winequality-red.csv&quot;, &#39;r&#39;) as f: wines = list(csv.reader(f, delimiter=&quot;;&quot;)) # print(wines[:3]) headers = wines[0] wines_only = wines[1:] # print the headers print(headers) [&#39;fixed acidity&#39;, &#39;volatile acidity&#39;, &#39;citric acid&#39;, &#39;residual sugar&#39;, &#39;chlorides&#39;, &#39;free sulfur dioxide&#39;, &#39;total sulfur dioxide&#39;, &#39;density&#39;, &#39;pH&#39;, &#39;sulphates&#39;, &#39;alcohol&#39;, &#39;quality&#39;] # print the 1st row of data print(wines_only[0]) [&#39;7.4&#39;, &#39;0.7&#39;, &#39;0&#39;, &#39;1.9&#39;, &#39;0.076&#39;, &#39;11&#39;, &#39;34&#39;, &#39;0.9978&#39;, &#39;3.51&#39;, &#39;0.56&#39;, &#39;9.4&#39;, &#39;5&#39;] # print the 1st three rows of data print(wines_only[:3]) [[&#39;7.4&#39;, &#39;0.7&#39;, &#39;0&#39;, &#39;1.9&#39;, &#39;0.076&#39;, &#39;11&#39;, &#39;34&#39;, &#39;0.9978&#39;, &#39;3.51&#39;, &#39;0.56&#39;, &#39;9.4&#39;, &#39;5&#39;], [&#39;7.8&#39;, &#39;0.88&#39;, &#39;0&#39;, &#39;2.6&#39;, &#39;0.098&#39;, &#39;25&#39;, &#39;67&#39;, &#39;0.9968&#39;, &#39;3.2&#39;, &#39;0.68&#39;, &#39;9.8&#39;, &#39;5&#39;], [&#39;7.8&#39;, &#39;0.76&#39;, &#39;0.04&#39;, &#39;2.3&#39;, &#39;0.092&#39;, &#39;15&#39;, &#39;54&#39;, &#39;0.997&#39;, &#39;3.26&#39;, &#39;0.65&#39;, &#39;9.8&#39;, &#39;5&#39;]] The data has been read into a list of lists. Each inner list is a row from the ssv file. As you may have noticed, each item in the entire list of lists is represented as a string, which will make it harder to do computations. As you can see from the table above, we’ve read in three rows, the first of which contains column headers. Each row after the header row represents a wine. The first element of each row is the fixed acidity, the second is the volatile acidity, and so on. Calculate Average Wine Quality We can find the average quality of the wines. The below code will: Extract the last element from each row after the header row. Convert each extracted element to a float. Assign all the extracted elements to the list qualities. Divide the sum of all the elements in qualities by the total number of elements in qualities to the get the mean. # calculate average wine quality with a loop qualities = [] for row in wines[1:]: qualities.append(float(row[-1])) sum(qualities) / len(wines[1:]) 5.6360225140712945 # calculate average wine quality with a list comprehension qualities = [float(row[-1]) for row in wines[1:]] sum(qualities) / len(wines[1:]) 5.6360225140712945 Although we were able to do the calculation we wanted, the code is fairly complex, and it won’t be fun to have to do something similar every time we want to compute a quantity. Luckily, we can use NumPy to make it easier to work with our data. Numpy 2-Dimensional Arrays With NumPy, we work with multidimensional arrays. We’ll dive into all of the possible types of multidimensional arrays later on, but for now, we’ll focus on 2-dimensional arrays. A 2-dimensional array is also known as a matrix, and is something you should be familiar with. In fact, it’s just a different way of thinking about a list of lists. A matrix has rows and columns. By specifying a row number and a column number, we’re able to extract an element from a matrix. If we picked the element at the first row and the second column, we’d get volatile acidity. If we picked the element in the third row and the second column, we’d get 0.88. In a NumPy array, the number of dimensions is called the rank, and each dimension is called an axis. So the rows are the first axis the columns are the second axis Now that you understand the basics of matrices, let’s see how we can get from our list of lists to a NumPy array. Creating A NumPy Array We can create a NumPy array using the numpy.array function. If we pass in a list of lists, it will automatically create a NumPy array with the same number of rows and columns. Because we want all of the elements in the array to be float elements for easy computation, we’ll leave off the header row, which contains strings. One of the limitations of NumPy is that all the elements in an array have to be of the same type, so if we include the header row, all the elements in the array will be read in as strings. Because we want to be able to do computations like find the average quality of the wines, we need the elements to all be floats. In the below code, we: Import the numpy package. Pass the list of lists wines into the array function, which converts it into a NumPy array. Exclude the header row with list slicing. Specify the keyword argument dtype to make sure each element is converted to a float. We’ll dive more into what the dtype is later on. import numpy as np np.set_printoptions(precision=2) # set the output print precision for readability # create the numpy array skipping the headers wines = np.array(wines[1:], dtype=np.float) # If we display wines, we&#39;ll now get a NumPy array: print(type(wines), wines) &lt;class &#39;numpy.ndarray&#39;&gt; [[ 7.4 0.7 0. ... 0.56 9.4 5. ] [ 7.8 0.88 0. ... 0.68 9.8 5. ] [ 7.8 0.76 0.04 ... 0.65 9.8 5. ] ... [ 6.3 0.51 0.13 ... 0.75 11. 6. ] [ 5.9 0.65 0.12 ... 0.71 10.2 5. ] [ 6. 0.31 0.47 ... 0.66 11. 6. ]] # We can check the number of rows and columns in our data using the shape property of NumPy arrays: wines.shape (1599, 12) Alternative NumPy Array Creation Methods There are a variety of methods that you can use to create NumPy arrays. It’s useful to create an array with all zero elements in cases when you need an array of fixed size, but don’t have any values for it yet. To start with, you can create an array where every element is zero. The below code will create an array with 3 rows and 4 columns, where every element is 0, using numpy.zeros: empty_array = np.zeros((3, 4)) empty_array array([[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]) Creating arrays full of random numbers can be useful when you want to quickly test your code with sample arrays. You can also create an array where each element is a random number using numpy.random.rand. np.random.rand(2, 3) array([[0.86, 0.94, 0.87], [0.85, 0.5 , 0.95]]) Using NumPy To Read In Files It’s possible to use NumPy to directly read csv or other files into arrays. We can do this using the numpy.genfromtxt function. We can use it to read in our initial data on red wines. In the below code, we: Use the genfromtxt function to read in the winequality-red.csv file. Specify the keyword argument delimiter=&quot;;&quot; so that the fields are parsed properly. Specify the keyword argument skip_header=1 so that the header row is skipped. wines = np.genfromtxt(&quot;winequality-red.csv&quot;, delimiter=&quot;;&quot;, skip_header=1) wines array([[ 7.4 , 0.7 , 0. , ..., 0.56, 9.4 , 5. ], [ 7.8 , 0.88, 0. , ..., 0.68, 9.8 , 5. ], [ 7.8 , 0.76, 0.04, ..., 0.65, 9.8 , 5. ], ..., [ 6.3 , 0.51, 0.13, ..., 0.75, 11. , 6. ], [ 5.9 , 0.65, 0.12, ..., 0.71, 10.2 , 5. ], [ 6. , 0.31, 0.47, ..., 0.66, 11. , 6. ]]) Wines will end up looking the same as if we read it into a list then converted it to an array of floats. NumPy will automatically pick a data type for the elements in an array based on their format. Indexing NumPy Arrays We now know how to create arrays, but unless we can retrieve results from them, there isn’t a lot we can do with NumPy. We can use array indexing to select individual elements, groups of elements, or entire rows and columns. One important thing to keep in mind is that just like Python lists, NumPy is zero-indexed, meaning that: The index of the first row is 0 The index of the first column is 0 If we want to work with the fourth row, we’d use index 3 If we want to work with the second row, we’d use index 1, and so on. We’ll again work with the wines array:                         7.4 0.70 0.00 1.9 0.076 11 34 0.9978 3.51 0.56 9.4 5 7.8 0.88 0.00 2.6 0.098 25 67 0.9968 3.20 0.68 9.8 5 7.8 0.76 0.04 2.3 0.092 15 54 0.9970 3.26 0.65 9.8 5 11.2 0.28 0.56 1.9 0.075 17 60 0.9980 3.16 0.58 9.8 6 7.4 0.70 0.00 1.9 0.076 11 34 0.9978 3.51 0.56 9.4 5 Let’s select the element at row 3 and column 4. We pass: 2 as the row index 3 as the column index. This retrieves the value from the third row and fourth column wines[2, 3] 2.3 wines[2][3] 2.3 Since we’re working with a 2-dimensional array in NumPy we specify 2 indexes to retrieve an element. The first index is the row, or axis 1, index The second index is the column, or axis 2, index Any element in wines can be retrieved using 2 indexes. # rows 1, 2, 3 and column 4 wines[0:3, 3] array([1.9, 2.6, 2.3]) # all rows and column 3 wines[:, 2] array([0. , 0. , 0.04, ..., 0.13, 0.12, 0.47]) Just like with list slicing, it’s possible to omit the 0 to just retrieve all the elements from the beginning up to element 3: # rows 1, 2, 3 and column 4 wines[:3, 3] array([1.9, 2.6, 2.3]) We can select an entire column by specifying that we want all the elements, from the first to the last. We specify this by just using the colon :, with no starting or ending indices. The below code will select the entire fourth column: # all rows and column 4 wines[:, 3] array([1.9, 2.6, 2.3, ..., 2.3, 2. , 3.6]) We selected an entire column above, but we can also extract an entire row: # row 4 and all columns wines[3, :] array([11.2 , 0.28, 0.56, 1.9 , 0.07, 17. , 60. , 1. , 3.16, 0.58, 9.8 , 6. ]) If we take our indexing to the extreme, we can select the entire array using two colons to select all the rows and columns in wines. This is a great party trick, but doesn’t have a lot of good applications: wines[:, :] array([[ 7.40, 0.70, 0.00, ..., 0.56, 9.40, 5.00], [ 7.80, 0.88, 0.00, ..., 0.68, 9.80, 5.00], [ 7.80, 0.76, 0.04, ..., 0.65, 9.80, 5.00], ..., [ 6.30, 0.51, 0.13, ..., 0.75, 11.00, 6.00], [ 5.90, 0.65, 0.12, ..., 0.71, 10.20, 5.00], [ 6.00, 0.31, 0.47, ..., 0.66, 11.00, 6.00]]) Assigning Values To NumPy Arrays We can also use indexing to assign values to certain elements in arrays. We can do this by assigning directly to the indexed value: # assign the value of 10 to the 2nd row and 6th column print(&#39;Before&#39;, wines[1, 4:7]) wines[1, 5] = 10 print(&#39;After&#39;, wines[1, 4:7]) Before [ 0.1 25. 67. ] After [ 0.1 10. 67. ] We can do the same for slices. To overwrite an entire column, we can do this: # Overwrites all the values in the eleventh column with 50. print(&#39;Before&#39;, wines[:, 9:12]) wines[:, 10] = 50 print(&#39;After&#39;, wines[:, 9:12]) Before [[ 0.56 9.4 5. ] [ 0.68 9.8 5. ] [ 0.65 9.8 5. ] ... [ 0.75 11. 6. ] [ 0.71 10.2 5. ] [ 0.66 11. 6. ]] After [[ 0.56 50. 5. ] [ 0.68 50. 5. ] [ 0.65 50. 5. ] ... [ 0.75 50. 6. ] [ 0.71 50. 5. ] [ 0.66 50. 6. ]] 1-Dimensional NumPy Arrays So far, we’ve worked with 2-dimensional arrays, such as wines. However, NumPy is a package for working with multidimensional arrays. One of the most common types of multidimensional arrays is the 1-dimensional array, or vector. As you may have noticed above, when we sliced wines, we retrieved a 1-dimensional array. A 1-dimensional array only needs a single index to retrieve an element. Each row and column in a 2-dimensional array is a 1-dimensional array. Just like a list of lists is analogous to a 2-dimensional array, a single list is analogous to a 1-dimensional array. If we slice wines and only retrieve the third row, we get a 1-dimensional array: third_wine = wines[3,:] third_wine array([11.2 , 0.28, 0.56, 1.9 , 0.07, 17. , 60. , 1. , 3.16, 0.58, 50. , 6. ]) We can retrieve individual elements from third_wine using a single index. # display the second item in third_wine third_wine[1] 0.28 Most NumPy functions that we’ve worked with, such as numpy.random.rand, can be used with multidimensional arrays. Here’s how we’d use numpy.random.rand to generate a random vector: np.random.rand(3) array([0.94, 0.41, 0.96]) Previously, when we called np.random.rand, we passed in a shape for a 2-dimensional array, so the result was a 2-dimensional array. This time, we passed in a shape for a single dimensional array. The shape specifies the number of dimensions, and the size of the array in each dimension. A shape of (10,10) will be a 2-dimensional array with 10 rows and 10 columns. A shape of (10,) will be a 1-dimensional array with 10 elements. Where NumPy gets more complex is when we start to deal with arrays that have more than 2 dimensions. N-Dimensional NumPy Arrays This doesn’t happen extremely often, but there are cases when you’ll want to deal with arrays that have greater than 3 dimensions. One way to think of this is as a list of lists of lists. Let’s say we want to store the monthly earnings of a store, but we want to be able to quickly lookup the results for a quarter, and for a year. The earnings for one year might look like this: [500, 505, 490, 810, 450, 678, 234, 897, 430, 560, 1023, 640] The store earned $500 in January, $505 in February, and so on. We can split up these earnings by quarter into a list of lists: year_one = [ [500,505,490], # 1st quarter [810,450,678], # 2nd quarter [234,897,430], # 3rd quarter [560,1023,640] # 4th quarter ] We can retrieve the earnings from January by calling year_one[0][0]. If we want the results for a whole quarter, we can call year_one[0] or year_one[1]. We now have a 2-dimensional array, or matrix. But what if we now want to add the results from another year? We have to add a third dimension: earnings = [ [ # year 1 [500,505,490], # year 1, 1st quarter [810,450,678], # year 1, 2nd quarter [234,897,430], # year 1, 3rd quarter [560,1023,640] # year 1, 4th quarter ], [ # year =2 [600,605,490], # year 2, 1st quarter [345,900,1000],# year 2, 2nd quarter [780,730,710], # year 2, 3rd quarter [670,540,324] # year 2, 4th quarter ] ] We can retrieve the earnings from January of the first year by calling earnings[0][0][0]. We now need three indexes to retrieve a single element. A three-dimensional array in NumPy is much the same. In fact, we can convert earnings to an array and then get the earnings for January of the first year: earnings = np.array(earnings) # year 1, 1st quarter, 1st month (January) earnings[0,0,0] 500 # year 2, 3rd quarter, 1st month (July) earnings[1,2,0] 780 # we can also find the shape of the array earnings.shape (2, 4, 3) Indexing and slicing work the exact same way with a 3-dimensional array, but now we have an extra axis to pass in. If we wanted to get the earnings for January of all years, we could do this: # all years, 1st quarter, 1st month (January) earnings[:,0,0] array([500, 600]) If we wanted to get first quarter earnings from both years, we could do this: # all years, 1st quarter, all months (January, February, March) earnings[:,0,:] array([[500, 505, 490], [600, 605, 490]]) Adding more dimensions can make it much easier to query your data if it’s organized in a certain way. As we go from 3-dimensional arrays to 4-dimensional and larger arrays, the same properties apply, and they can be indexed and sliced in the same ways. NumPy Data Types As we mentioned earlier, each NumPy array can store elements of a single data type. For example, wines contains only float values. NumPy stores values using its own data types, which are distinct from Python types like float and str. This is because the core of NumPy is written in a programming language called C, which stores data differently than the Python data types. NumPy data types map between Python and C, allowing us to use NumPy arrays without any conversion hitches. You can find the data type of a NumPy array by accessing the dtype property: wines.dtype dtype(&#39;float64&#39;) NumPy has several different data types, which mostly map to Python data types, like float, and str. You can find a full listing of NumPy data types here, but here are a few important ones: float – numeric floating point data. int – integer data. string – character data. object – Python objects. Data types additionally end with a suffix that indicates how many bits of memory they take up. So int32 is a 32 bit integer data type, and float64 is a 64 bit float data type. Converting Data Types You can use the numpy.ndarray.astype method to convert an array to a different type. The method will actually copy the array, and return a new array with the specified data type. For instance, we can convert wines to the int data type: # convert wines to the int data type wines.astype(int) array([[ 7, 0, 0, ..., 0, 50, 5], [ 7, 0, 0, ..., 0, 50, 5], [ 7, 0, 0, ..., 0, 50, 5], ..., [ 6, 0, 0, ..., 0, 50, 6], [ 5, 0, 0, ..., 0, 50, 5], [ 6, 0, 0, ..., 0, 50, 6]]) As you can see above, all of the items in the resulting array are integers. Note that we used the Python int type instead of a NumPy data type when converting wines. This is because several Python data types, including float, int, and string, can be used with NumPy, and are automatically converted to NumPy data types. We can check the name property of the dtype of the resulting array to see what data type NumPy mapped the resulting array to: # convert to int int_wines = wines.astype(int) # check the data type int_wines.dtype.name &#39;int64&#39; The array has been converted to a 64-bit integer data type. This allows for very long integer values, but takes up more space in memory than storing the values as 32-bit integers. If you want more control over how the array is stored in memory, you can directly create NumPy dtype objects like numpy.int32 np.int32 numpy.int32 You can use these directly to convert between types: # convert to a 64-bit integer wines.astype(np.int64) array([[ 7, 0, 0, ..., 0, 50, 5], [ 7, 0, 0, ..., 0, 50, 5], [ 7, 0, 0, ..., 0, 50, 5], ..., [ 6, 0, 0, ..., 0, 50, 6], [ 5, 0, 0, ..., 0, 50, 5], [ 6, 0, 0, ..., 0, 50, 6]]) # convert to a 32-bit integer wines.astype(np.int32) array([[ 7, 0, 0, ..., 0, 50, 5], [ 7, 0, 0, ..., 0, 50, 5], [ 7, 0, 0, ..., 0, 50, 5], ..., [ 6, 0, 0, ..., 0, 50, 6], [ 5, 0, 0, ..., 0, 50, 5], [ 6, 0, 0, ..., 0, 50, 6]], dtype=int32) # convert to a 16-bit integer wines.astype(np.int16) array([[ 7, 0, 0, ..., 0, 50, 5], [ 7, 0, 0, ..., 0, 50, 5], [ 7, 0, 0, ..., 0, 50, 5], ..., [ 6, 0, 0, ..., 0, 50, 6], [ 5, 0, 0, ..., 0, 50, 5], [ 6, 0, 0, ..., 0, 50, 6]], dtype=int16) # convert to a 8-bit integer wines.astype(np.int8) array([[ 7, 0, 0, ..., 0, 50, 5], [ 7, 0, 0, ..., 0, 50, 5], [ 7, 0, 0, ..., 0, 50, 5], ..., [ 6, 0, 0, ..., 0, 50, 6], [ 5, 0, 0, ..., 0, 50, 5], [ 6, 0, 0, ..., 0, 50, 6]], dtype=int8) NumPy Array Operations NumPy makes it simple to perform mathematical operations on arrays. This is one of the primary advantages of NumPy, and makes it quite easy to do computations. Single Array Math If you do any of the basic mathematical operations /, *, -, +, ^ with an array and a value, it will apply the operation to each of the elements in the array. Let’s say we want to add 10 points to each quality score because we’re feeling generous. Here’s how we’d do that: # add 10 points to the quality score wines[:,-1] + 10 array([15., 15., 15., ..., 16., 15., 16.]) Note: that the above operation won’t change the wines array – it will return a new 1-dimensional array where 10 has been added to each element in the quality column of wines. If we instead did +=, we’d modify the array in place: print(&#39;Before&#39;, wines[:,11]) # modify the data in place wines[:,11] += 10 print(&#39;After&#39;, wines[:,11]) Before [5. 5. 5. ... 6. 5. 6.] After [15. 15. 15. ... 16. 15. 16.] All the other operations work the same way. For example, if we want to multiply each of the quality score by 2, we could do it like this: # multiply the quality score by 2 wines[:,11] * 2 array([30., 30., 30., ..., 32., 30., 32.]) Multiple Array Math It’s also possible to do mathematical operations between arrays. This will apply the operation to pairs of elements. For example, if we add the quality column to itself, here’s what we get: # add the quality column to itself wines[:,11] + wines[:,11] array([30., 30., 30., ..., 32., 30., 32.]) Note that this is equivalent to wines[:,11] * 2 – this is because NumPy adds each pair of elements. The first element in the first array is added to the first element in the second array, the second to the second, and so on. # add the quality column to itself wines[:,11] * 2 array([30., 30., 30., ..., 32., 30., 32.]) We can also use this to multiply arrays. Let’s say we want to pick a wine that maximizes alcohol content and quality. We’d multiply alcohol by quality, and select the wine with the highest score: # multiply alcohol content by quality alcohol_by_quality = wines[:,10] * wines[:,11] print(alcohol_by_quality) [750. 750. 750. ... 800. 750. 800.] alcohol_by_quality.sort() print(alcohol_by_quality, alcohol_by_quality[-1]) [650. 650. 650. ... 900. 900. 900.] 900.0 All of the common operations /, *, -, +, ^ will work between arrays. NumPy Array Methods In addition to the common mathematical operations, NumPy also has several methods that you can use for more complex calculations on arrays. An example of this is the numpy.ndarray.sum method. This finds the sum of all the elements in an array by default: # find the sum of all rows and the quality column total = 0 for row in wines: total += row[11] print(total) 25002.0 # find the sum of all rows and the quality column wines[:,11].sum(axis=0) 25002.0 # find the sum of the rows 1, 2, and 3 across all columns totals = [] for i in range(3): total = 0 for col in wines[i,:]: total += col totals.append(total) print(totals) [125.1438, 158.2548, 149.899] # find the sum of the rows 1, 2, and 3 across all columns wines[0:3,:].sum(axis=1) array([125.14, 158.25, 149.9 ]) We can pass the axis keyword argument into the sum method to find sums over an axis. If we call sum across the wines matrix, and pass in axis=0, we’ll find the sums over the first axis of the array. This will give us the sum of all the values in every column. This may seem backwards that the sums over the first axis would give us the sum of each column, but one way to think about this is that the specified axis is the one “going away”. So if we specify axis=0, we want the rows to go away, and we want to find the sums for each of the remaining axes across each row: # sum each column for all rows totals = [0] * len(wines[0]) for i, total in enumerate(totals): for row_val in wines[:,i]: total += row_val totals[i] = total print(totals) [13303.100000000046, 843.9850000000005, 433.2899999999982, 4059.550000000003, 139.8589999999996, 25369.0, 74302.0, 1593.7979399999986, 5294.470000000001, 1052.3800000000006, 79950.0, 25002.0] # sum each column for all rows wines.sum(axis=0) array([13303.1 , 843.99, 433.29, 4059.55, 139.86, 25369. , 74302. , 1593.8 , 5294.47, 1052.38, 79950. , 25002. ]) We can verify that we did the sum correctly by checking the shape. The shape should be 12, corresponding to the number of columns: wines.sum(axis=0).shape (12,) If we pass in axis=1, we’ll find the sums over the second axis of the array. This will give us the sum of each row: # sum each row for all columns totals = [0] * len(wines) for i, total in enumerate(totals): for col_val in wines[i,:]: total += col_val totals[i] = total print(totals[0:3], &#39;...&#39;, totals[-3:]) [125.1438, 158.2548, 149.899] ... [149.48174, 155.01547, 141.49249] # sum each row for all columns wines.sum(axis=1) array([125.14, 158.25, 149.9 , ..., 149.48, 155.02, 141.49]) wines.sum(axis=1).shape (1599,) There are several other methods that behave like the sum method, including: numpy.ndarray.mean — finds the mean of an array. numpy.ndarray.std — finds the standard deviation of an array. numpy.ndarray.min — finds the minimum value in an array. numpy.ndarray.max — finds the maximum value in an array. You can find a full list of array methods here. NumPy Array Comparisons NumPy makes it possible to test to see if rows match certain values using mathematical comparison operations like &lt;, &gt;, &gt;=, &lt;=, and ==. For example, if we want to see which wines have a quality rating higher than 5, we can do this: # return True for all rows in the Quality column that are greater than 5 wines[:,11] &gt; 5 array([ True, True, True, ..., True, True, True]) We get a Boolean array that tells us which of the wines have a quality rating greater than 5. We can do something similar with the other operators. For instance, we can see if any wines have a quality rating equal to 10: # return True for all rows that have a Quality rating of 10 wines[:,11] == 10 array([False, False, False, ..., False, False, False]) Subsetting One of the powerful things we can do with a Boolean array and a NumPy array is select only certain rows or columns in the NumPy array. For example, the below code will only select rows in wines where the quality is over 7: # create a boolean array for wines with quality greater than 15 high_quality = wines[:,11] &gt; 15 print(len(high_quality), high_quality) 1599 [False False False ... True False True] # use boolean indexing to find high quality wines high_quality_wines = wines[high_quality,:] print(len(high_quality_wines), high_quality_wines) 855 [[1.12e+01 2.80e-01 5.60e-01 ... 5.80e-01 5.00e+01 1.60e+01] [7.30e+00 6.50e-01 0.00e+00 ... 4.70e-01 5.00e+01 1.70e+01] [7.80e+00 5.80e-01 2.00e-02 ... 5.70e-01 5.00e+01 1.70e+01] ... [5.90e+00 5.50e-01 1.00e-01 ... 7.60e-01 5.00e+01 1.60e+01] [6.30e+00 5.10e-01 1.30e-01 ... 7.50e-01 5.00e+01 1.60e+01] [6.00e+00 3.10e-01 4.70e-01 ... 6.60e-01 5.00e+01 1.60e+01]] We select only the rows where high_quality contains a True value, and all of the columns. This subsetting makes it simple to filter arrays for certain criteria. For example, we can look for wines with a lot of alcohol and high quality. In order to specify multiple conditions, we have to place each condition in parentheses (...), and separate conditions with an ampersand &amp;: # create a boolean array for high alcohol content and high quality high_alcohol_and_quality = (wines[:,11] &gt; 7) &amp; (wines[:,10] &gt; 10) print(high_alcohol_and_quality) # use boolean indexing to select out the wines wines[high_alcohol_and_quality,:] [ True True True ... True True True] array([[7.40e+00, 7.00e-01, 0.00e+00, ..., 5.60e-01, 5.00e+01, 1.50e+01], [7.80e+00, 8.80e-01, 0.00e+00, ..., 6.80e-01, 5.00e+01, 1.50e+01], [7.80e+00, 7.60e-01, 4.00e-02, ..., 6.50e-01, 5.00e+01, 1.50e+01], ..., [6.30e+00, 5.10e-01, 1.30e-01, ..., 7.50e-01, 5.00e+01, 1.60e+01], [5.90e+00, 6.45e-01, 1.20e-01, ..., 7.10e-01, 5.00e+01, 1.50e+01], [6.00e+00, 3.10e-01, 4.70e-01, ..., 6.60e-01, 5.00e+01, 1.60e+01]]) We can combine subsetting and assignment to overwrite certain values in an array: high_alcohol_and_quality = (wines[:,10] &gt; 10) &amp; (wines[:,11] &gt; 7) wines[high_alcohol_and_quality,10:] = 20 Reshaping NumPy Arrays We can change the shape of arrays while still preserving all of their elements. This often can make it easier to access array elements. The simplest reshaping is to flip the axes, so rows become columns, and vice versa. We can accomplish this with the numpy.transpose function: np.transpose(wines).shape (12, 1599) We can use the numpy.ravel function to turn an array into a one-dimensional representation. It will essentially flatten an array into a long sequence of values: wines.ravel() array([ 7.4 , 0.7 , 0. , ..., 0.66, 50. , 16. ]) Here’s an example where we can see the ordering of numpy.ravel: array_one = np.array( [ [1, 2, 3, 4], [5, 6, 7, 8] ] ) array_one.ravel() array([1, 2, 3, 4, 5, 6, 7, 8]) Finally, we can use the numpy.reshape function to reshape an array to a certain shape we specify. The below code will turn the second row of wines into a 2-dimensional array with 2 rows and 6 columns: # print the current shape of the 2nd row and all columns wines[1,:].shape (12,) # reshape the 2nd row to a 2 by 6 matrix wines[1,:].reshape((2,6)) array([[ 7.8 , 0.88, 0. , 2.6 , 0.1 , 10. ], [67. , 1. , 3.2 , 0.68, 50. , 15. ]]) Combining NumPy Arrays With NumPy, it’s very common to combine multiple arrays into a single unified array. We can use numpy.vstack to vertically stack multiple arrays. Think of it like the second arrays’s items being added as new rows to the first array. We can read in the winequality-white.csv dataset that contains information on the quality of white wines, then combine it with our existing dataset, wines, which contains information on red wines. In the below code, we: Read in winequality-white.csv. Display the shape of white_wines. white_wines = np.genfromtxt(&quot;winequality-white.csv&quot;, delimiter=&quot;;&quot;, skip_header=1) white_wines.shape (4898, 12) As you can see, we have attributes for 4898 wines. Now that we have the white wines data, we can combine all the wine data. In the below code, we: Use the vstack function to combine wines and white_wines. Display the shape of the result. all_wines = np.vstack((wines, white_wines)) all_wines.shape (6497, 12) As you can see, the result has 6497 rows, which is the sum of the number of rows in wines and the number of rows in red_wines. If we want to combine arrays horizontally, where the number of rows stay constant, but the columns are joined, then we can use the numpy.hstack function. The arrays we combine need to have the same number of rows for this to work. Finally, we can use numpy.concatenate as a general purpose version of hstack and vstack. If we want to concatenate two arrays, we pass them into concatenate, then specify the axis keyword argument that we want to concatenate along. Concatenating along the first axis is similar to vstack Concatenating along the second axis is similar to hstack: x = np.concatenate((wines, white_wines), axis=0) print(x.shape, x) (6497, 12) [[7.40e+00 7.00e-01 0.00e+00 ... 5.60e-01 5.00e+01 1.50e+01] [7.80e+00 8.80e-01 0.00e+00 ... 6.80e-01 5.00e+01 1.50e+01] [7.80e+00 7.60e-01 4.00e-02 ... 6.50e-01 5.00e+01 1.50e+01] ... [6.50e+00 2.40e-01 1.90e-01 ... 4.60e-01 9.40e+00 6.00e+00] [5.50e+00 2.90e-01 3.00e-01 ... 3.80e-01 1.28e+01 7.00e+00] [6.00e+00 2.10e-01 3.80e-01 ... 3.20e-01 1.18e+01 6.00e+00]] Broadcasting Unless the arrays that you’re operating on are the exact same size, it’s not possible to do elementwise operations. In cases like this, NumPy performs broadcasting to try to match up elements. Essentially, broadcasting involves a few steps: The last dimension of each array is compared. If the dimension lengths are equal, or one of the dimensions is of length 1, then we keep going. If the dimension lengths aren’t equal, and none of the dimensions have length 1, then there’s an error. Continue checking dimensions until the shortest array is out of dimensions. For example, the following two shapes are compatible: A: (50,3) B (3,) This is because the length of the trailing dimension of array A is 3, and the length of the trailing dimension of array B is 3. They’re equal, so that dimension is okay. Array B is then out of elements, so we’re okay, and the arrays are compatible for mathematical operations. The following two shapes are also compatible: A: (1,2) B (50,2) The last dimension matches, and A is of length 1 in the first dimension. These two arrays don’t match: A: (50,50) B: (49,49) The lengths of the dimensions aren’t equal, and neither array has either dimension length equal to 1. There’s a detailed explanation of broadcasting here, but we’ll go through a few examples to illustrate the principle: wines * np.array([1,2]) ValueError Traceback (most recent call last) &lt;ipython-input-98-821086ccaf65&gt; in &lt;module&gt;() -&gt; 1 wines * np.array([1,2]) ValueError: operands could not be broadcast together with shapes (1599,12) (2,) The above example didn’t work because the two arrays don’t have a matching trailing dimension. Here’s an example where the last dimension does match: array_one = np.array( [ [1,2], [3,4] ] ) array_two = np.array([4,5]) array_one + array_two array([[5, 7], [7, 9]]) As you can see, array_two has been broadcasted across each row of array_one. Here’s an example with our wines data: rand_array = np.random.rand(12) wines + rand_array array([[ 8.11, 1.46, 0.23, ..., 1.28, 50.29, 15.88], [ 8.51, 1.64, 0.23, ..., 1.4 , 50.29, 15.88], [ 8.51, 1.52, 0.27, ..., 1.37, 50.29, 15.88], ..., [ 7.01, 1.27, 0.36, ..., 1.47, 50.29, 16.88], [ 6.61, 1.4 , 0.35, ..., 1.43, 50.29, 15.88], [ 6.71, 1.07, 0.7 , ..., 1.38, 50.29, 16.88]])",
    "url": "http://localhost:4000/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth/02%20-%20NumPy%20Data%20analysis.html",
    "relUrl": "/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth/02%20-%20NumPy%20Data%20analysis.html"
  },
  "18": {
    "id": "18",
    "title": "02.a - Generating Synthetic Healthcare Data",
    "content": "Generating Synthetic Healthcare Data One of the hardest things to do in data science is get access to high quality datasets that relate to your specific questions. There’s any number of reasons why researchers and analysts get incorrect results and misread the answers they’re getting. Bad data practice may be leading to bad research. Some bad data practice themes might include: Honest Statistical/Computing Error Honest Misunderstanding of Data Honest Misapplication of Methods Honest Failure to Normalize and Malicious Manipulation (made worse through the) Poor citation practices of Copy-Paste Google Scholar-ship. In this class we’re going to learn how to process and analyze data using python. Since I work in healthcare we’ll be using a tool called Synthea which will help us create consistent meaningful datasets at scale in a vareity of formats (Text, CSV, C-CDA, and FHIR). We’ll use these datasets to: Learn about basic and advanced python concepts Learn about handling data in python Answer simple and complex questions about the data Generate interesting visualizations What is Synthea? Synthea Getting Started SyntheaTM is a synthetic patient generator that models the medical history of synthetic patients. Our mission is to output high-quality synthetic, realistic but not real, patient data and associated health records covering every aspect of healthcare. The resulting data is free from cost, privacy, and security restrictions. It can be used without restriction for a variety of secondary uses in academia, research, industry, and government (although a citation would be appreciated). SyntheaTM generates synthetic patient records using an agent-based approach. Each synthetic patient is generated independently, as they progress from birth to death through modular representations of various diseases and conditions. Each patient runs through every module in the system. Once a patient dies or the simulation reaches the current day, that patient record can be exported in a number of different formats. Synthea Data Formats Synthea generates these datasets in a variety of commonly used healthcare data formats including (Text, CSV, C-CDA, and FHIR) Text Text format is a quick human readable format. This format doesn’t adhere to any particular standard. Text formats are most commonly consumed by humans who may be clinicians or other application end users. The other data formats (CSV, C-CDA, and FHIR) can be easily converted to a Text format. However, converting a Text format to any of the other data formats is extremely challenging. Often times we use Natuarl Language Processing (NLP) and Regular Expressions (RegEx) as we attempt the Text to (CSV, C-CDA, FHIR) conversion. Sample: Mekhi724 Kemmer911 ================== Race: White Ethnicity: Non-Hispanic Gender: F Age: 33 Birth Date: 1983-11-04 Marital Status: M -- ALLERGIES: N/A -- MEDICATIONS: 2013-08-22 [CURRENT] : Acetaminophen 160 MG for Acute bronchitis (disorder) 1996-05-12 [CURRENT] : Acetaminophen 160 MG for Acute bronchitis (disorder) 1995-04-13 [CURRENT] : Acetaminophen 160 MG for Acute bronchitis (disorder) 1984-01-14 [CURRENT] : Penicillin V Potassium 250 MG for Streptococcal sore throat (disorder) -- CONDITIONS: 2015-10-30 - 2015-11-07 : Fetus with chromosomal abnormality 2015-10-30 - 2015-11-07 : Miscarriage in first trimester 2015-10-30 - 2015-11-07 : Normal pregnancy 2013-08-22 - 2013-09-08 : Acute bronchitis (disorder) 1985-08-07 - : Food Allergy: Fish -- CARE PLANS: 2013-08-22 [STOPPED] : Respiratory therapy Reason: Acute bronchitis (disorder) Activity: Recommendation to avoid exercise Activity: Deep breathing and coughing exercises -- OBSERVATIONS: 2014-01-14 : Body Weight 73.9 kg 2014-01-14 : Body Height 163.7 cm 2014-01-14 : Body Mass Index 27.6 kg/m2 2014-01-14 : Systolic Blood Pressure 133.0 mmHg 2014-01-14 : Diastolic Blood Pressure 76.0 mmHg 2014-01-14 : Blood Pressure 2.0 -- PROCEDURES: 2015-10-30 : Standard pregnancy test for Normal pregnancy 2014-01-14 : Documentation of current medications -- ENCOUNTERS: 2015-11-07 : Encounter for Fetus with chromosomal abnormality 2015-10-30 : Encounter for Normal pregnancy 2014-01-14 : Outpatient Encounter 2013-08-22 : Encounter for Acute bronchitis (disorder) -- CSV Comma Separated Value (CSV) files are common in healthcare and one could argue one of the 3 most common data formats with the others being HL7v2 and C-CDA. Unlike the Text format generated by Synthea, which only contains a single patient per file, the CSV format contains many patients per file. However, the files themselves are “resource” based. The resources generated include: Patients - patients.csv Encounters - encounters.csv Allergies - allergies.csv Medications - medications.csv Conditions - conditions.csv Care Plans - careplans.csv Observations - observations.csv Procedures - Procedures.csv Immunizations - immunizations.csv Sample: patients.csv ID,BIRTHDATE,DEATHDATE,SSN,DRIVERS,PASSPORT,PREFIX,FIRST,LAST,SUFFIX,MAIDEN,MARITAL,RACE,ETHNICITY,GENDER,BIRTHPLACE,ADDRESS 5e0d195e-1cd9-494d-8f9a-757c15da2aed,1946-12-14,2015-10-03,999-12-2377,S99962866,false,Mrs.,Miracle267,Ledner332,,Raynor597,M,white,irish,F,Millbury MA,2502 Fisher Manor Boston MA 02132 52082709-06ce-4fde-9c93-cfb4e6542ae1,1968-05-23,,999-17-1808,S99941406,X41451685X,Mrs.,Alda869,Gorczany848,,Funk527,M,white,italian,F,Gardner MA,46973 Velda Gateway Franklin Town MA 02038 8b4c62c8-b116-4b58-9259-466485b0345c,1967-06-22,1985-07-04,999-11-1173,S99955795,,Ms.,Moshe832,Zulauf396,,,,white,english,F,Boston MA,250 Reba Park Carver MA 02330 965c5539-598b-4a9b-a670-e0259667deb8,1934-11-04,2015-06-19,999-63-2195,S99931866,X71888970X,Mr.,Verla554,Roberts329,,,S,white,irish,M,Fall River MA,321 Abdullah Bridge Needham MA 02492 2b28d6c3-9e0c-48d4-99f9-292488133101,1964-08-13,,999-55-5054,S99990374,X68574707X,Ms.,Henderson277,Labadie810,,,S,black,dominican,F,North Attleborough MA,55825 Barrows Prairie Suite 144 Boston MA 02134 conditions.csv START,STOP,PATIENT,ENCOUNTER,CODE,DESCRIPTION 1965-10-10,,5e0d195e-1cd9-494d-8f9a-757c15da2aed,918b17f4-e815-44ef-9eeb-41953bbcf7e9,38341003,Hypertension 1966-09-09,,5e0d195e-1cd9-494d-8f9a-757c15da2aed,918b17f4-e815-44ef-9eeb-41953bbcf7e9,15777000,Prediabetes 1988-09-25,,5e0d195e-1cd9-494d-8f9a-757c15da2aed,918b17f4-e815-44ef-9eeb-41953bbcf7e9,239872002,Osteoarthritis of hip 1990-09-01,,5e0d195e-1cd9-494d-8f9a-757c15da2aed,918b17f4-e815-44ef-9eeb-41953bbcf7e9,410429000,Cardiac Arrest 1990-09-01,,5e0d195e-1cd9-494d-8f9a-757c15da2aed,918b17f4-e815-44ef-9eeb-41953bbcf7e9,429007001,History of cardiac arrest (situation) We’ll talk more about each of these resources below when we discuss the FHIR data format. C-CDA Consolidated Clinical Document Architecture (C-CDA) format is an XML-based standard defined by HL7, that uses templates from a standard library to represent clinical concepts. For more information on C-CDA, see http://www.hl7.org/implement/standards/product_brief.cfm?product_id=258. Sample: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;ClinicalDocument xmlns=&quot;urn:hl7-org:v3&quot; xmlns:sdtc=&quot;urn:hl7-org:sdtc&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;urn:hl7-org:v3 http://xreg2.nist.gov:8080/hitspValidation/schema/cdar2c32/infrastructure/cda/C32_CDA.xsd&quot;&gt; &lt;realmCode code=&quot;US&quot;/&gt; &lt;typeId root=&quot;2.16.840.1.113883.1.3&quot; extension=&quot;POCD_HD000040&quot;/&gt; &lt;templateId root=&quot;2.16.840.1.113883.10.20.22.1.1&quot; extension=&quot;2015-08-01&quot;/&gt; &lt;templateId root=&quot;2.16.840.1.113883.10.20.22.1.2&quot; extension=&quot;2015-08-01&quot;/&gt; &lt;id root=&quot;2.16.840.1.113883.19.5&quot; extension=&quot;47b10305-eb1b-4a47-a27c-24b7e96ee1da&quot; assigningAuthorityName=&quot;https://github.com/synthetichealth/synthea&quot;/&gt; &lt;code code=&quot;34133-9&quot; displayName=&quot;Summarization of episode note&quot; codeSystem=&quot;2.16.840.1.113883.6.1&quot; codeSystemName=&quot;LOINC&quot;/&gt; &lt;title&gt;C-CDA R2.1 Patient Record: Augustine565 Cummings51&lt;/title&gt; &lt;effectiveTime value=&quot;20190308211454&quot;/&gt; &lt;confidentialityCode code=&quot;N&quot;/&gt; &lt;languageCode code=&quot;en-US&quot;/&gt; &lt;recordTarget&gt; &lt;patientRole&gt; &lt;id root=&quot;2.16.840.1.113883.19.5&quot; extension=&quot;47b10305-eb1b-4a47-a27c-24b7e96ee1da&quot; assigningAuthorityName=&quot;https://github.com/synthetichealth/synthea&quot;/&gt; &lt;addr use=&quot;HP&quot;&gt; &lt;streetAddressLine&gt;931 Watsica Lock&lt;/streetAddressLine&gt; &lt;city&gt;Pittsburgh&lt;/city&gt; &lt;state&gt;Pennsylvania&lt;/state&gt; &lt;postalCode&gt;15106&lt;/postalCode&gt; &lt;/addr&gt; &lt;telecom nullFlavor=&quot;NI&quot;/&gt; &lt;patient&gt; &lt;name&gt; &lt;given&gt;Augustine565&lt;/given&gt; &lt;family&gt;Cummings51&lt;/family&gt; &lt;/name&gt; &lt;administrativeGenderCode code=&quot;F&quot; codeSystem=&quot;2.16.840.1.113883.5.1&quot; codeSystemName=&quot;HL7 AdministrativeGender&quot;/&gt; &lt;birthTime value=&quot;19690509221454&quot;/&gt; &lt;raceCode code=&quot;2028-9&quot; displayName=&quot;asian&quot; codeSystemName=&quot;CDC Race and Ethnicity&quot; codeSystem=&quot;2.16.840.1.113883.6.238&quot;/&gt; &lt;ethnicGroupCode code=&quot;2186-5&quot; displayName=&quot;non-hispanic&quot; codeSystemName=&quot;CDC Race and Ethnicity&quot; codeSystem=&quot;2.16.840.1.113883.6.238&quot;/&gt; &lt;languageCommunication&gt; &lt;languageCode code=&quot;en-US&quot;/&gt; &lt;/languageCommunication&gt; &lt;/patient&gt; &lt;/patientRole&gt; &lt;/recordTarget&gt; &lt;!-- ... --&gt; &lt;/ClinicalDocument&gt; FHIR HL7 FHIR is possibly the most exciting and interesting data format to deal with. Many of the formats discussed above were created in a time where the vast majority of Health IT systems ran on-premise. These data format and transport protocol standards are extremely reliable, but not so friendly to the web developer. HL7 FHIR started as a community response to the legacy and hard to deal with Health IT standards. In just a few years the community has grown dramatically and most (if not all) EMR vendors have some support for the standard which is unheard of in the Health IT space. The primary drive for this rapid pace has been the US governement who has released a number of regulations and mandates for open data access. FHIR® – Fast Healtcare Interoperability Resources (hl7.org/fhir) – is a next generation standards framework created by HL7. FHIR combines the best features of HL7’s Version 2, Version 3 and CDA® product lines while leveraging the latest web standards and applying a tight focus on implementability. SyntheaTM currently supports exporting patients as Fast Healthcare Interoperability Resources (FHIR), versions 3.5.0 (R4), 3.0.1 (STU3) and 1.0.2 (DSTU2). FHIR is a standard created by HL7 for exchanging healthcare information electronically. While FHIR supports both XML and JSON, Synthea exports FHIR as JSON only. Sample: { &quot;resourceType&quot;: &quot;Bundle&quot;, &quot;type&quot;: &quot;transaction&quot;, &quot;entry&quot;: [ { &quot;fullUrl&quot;: &quot;urn:uuid:4bd23de9-7d28-48a5-8093-1ac7ff1c64b7&quot;, &quot;resource&quot;: { &quot;resourceType&quot;: &quot;Patient&quot;, &quot;id&quot;: &quot;4bd23de9-7d28-48a5-8093-1ac7ff1c64b7&quot;, &quot;text&quot;: { &quot;status&quot;: &quot;generated&quot;, &quot;div&quot;: &quot;&lt;div xmlns= &quot;http://www.w3.org/1999/xhtml &quot;&gt;Generated by &lt;a href= &quot;https://github.com/synthetichealth/synthea &quot;&gt;Synthea&lt;/a&gt;.Version identifier: v2.4.0-44-g6dbf88c6 n . Person seed: -1236052134575208584 Population seed: 12345&lt;/div&gt;&quot; }, &quot;name&quot;: [ { &quot;use&quot;: &quot;official&quot;, &quot;family&quot;: &quot;Cummings51&quot;, &quot;given&quot;: [ &quot;Augustine565&quot; ], &quot;prefix&quot;: [ &quot;Mrs.&quot; ] }, { &quot;use&quot;: &quot;maiden&quot;, &quot;family&quot;: &quot;Cremin516&quot;, &quot;given&quot;: [ &quot;Augustine565&quot; ], &quot;prefix&quot;: [ &quot;Mrs.&quot; ] } ] }] }",
    "url": "http://localhost:4000/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/02.a%20-%20Generating%20Synthetic%20Healthcare%20Data.html",
    "relUrl": "/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/02.a%20-%20Generating%20Synthetic%20Healthcare%20Data.html"
  },
  "19": {
    "id": "19",
    "title": "02.a - Python Classes",
    "content": "Python Classes Object-Oriented Programming (OOP) in Python Classes in Python Focusing first on the data, each thing or object is an instance of some class. Classes are used to create new user-defined data structures that contain arbitrary information about something. In the case of an person, we could create a Person() class to track properties about the Person like the name and age. It’s important to note that a class just provides structure—it’s a blueprint for how something should be defined, but it doesn’t actually provide any real content itself. The Person() class may specify that the name and age are necessary for defining an person, but it will not actually state what a specific person’s name or age is. It may help to think of a class as an idea for how something should be defined. Python Objects (Instances) While the class is the blueprint, an instance is a copy of the class with actual values, literally an object belonging to a specific class. It’s not an idea anymore; it’s an actual person, like a person named Bill who’s twenty years old. Put another way, a class is like a form or questionnaire. It defines the needed information. After you fill out the form, your specific copy is an instance of the class; it contains actual information relevant to you. You can fill out multiple copies to create many different instances, but without the form as a guide, you would be lost, not knowing what information is required. Thus, before you can create individual instances of an object, we must first specify what is needed by defining a class. How To Define a Class in Python class Person: pass Instance Attributes All classes create objects, and all objects contain characteristics called attributes (referred to as properties in the opening paragraph). Use the __init__() method to initialize (e.g., specify) an object’s initial attributes by giving them their default value (or state). This method must have at least one argument as well as the self variable, which refers to the object itself (e.g., Person). class Person: # Initializer / Instance Attributes def __init__(self, name, age): self.name = name self.age = age In the case of our Person() class: each person has a specific name and age, which is obviously important to know for when you start actually creating different persons. Remember: the class is just for defining the Person, not actually creating instances of individual persons with specific names and ages; we’ll get to that shortly. Similarly, the self variable is also an instance of the class. Since instances of a class have varying values we could state Person.name = name rather than self.name = name. But since not all persons share the same name, we need to be able to assign different values to different instances. Hence the need for the special self variable, which will help to keep track of individual instances of each class. Note: You will never have to call the __init__() method; it gets called automatically when you create a new ‘Person’ instance. Class Attributes While instance attributes are specific to each object, class attributes are the same for all instances—which in this case is all persons. So while each person has a unique name and age, every person is a homo sapien. class Person: # Class Attribute species = &#39;homo sapien&#39; # Initializer / Instance Attributes def __init__(self, name, age): self.name = name self.age = age Instantiating Objects Instantiating is a fancy term for creating a new, unique instance of a class. class Animal: pass a = Animal() print(&#39;a is type&#39;, type(a), &#39;value&#39;, a) b = Animal() print(&#39;b is type&#39;, type(b), &#39;value&#39;, b) c = b a is type &lt;class &#39;__main__.Animal&#39;&gt; value &lt;__main__.Animal object at 0x112f886a0&gt; b is type &lt;class &#39;__main__.Animal&#39;&gt; value &lt;__main__.Animal object at 0x112f886d8&gt; a == b False print(a == c) print(b == c) False True # Instantiate the Person object ben = Person(&quot;Ben&quot;, 37) geno = Person(&quot;Geno&quot;, 32) # Access the instance attributes print(f&quot;{ben.name} is {ben.age} and {geno.name} is {geno.age}.&quot;) # Is Ben a mammal? if ben.species == &quot;homo sapien&quot;: print(f&quot;{ben.name} is a {ben.species}!&quot;) Ben is 37 and Geno is 32. Ben is a homo sapien! Instance Methods Instance methods are defined inside a class and are used to get the contents of an instance. They can also be used to perform operations with the attributes of our objects. Like the __init__ method, the first argument is always self: class Dog: # Class Attribute species = &#39;mammal&#39; # Initializer / Instance Attributes def __init__(self, name, age): self.name = name self.age = age # instance method def description(self): return &quot;{} is {} years old&quot;.format(self.name, self.age) # instance method def speak(self, sound): return &quot;{} says {}&quot;.format(self.name, sound) # Instantiate the Dog object mikey = Dog(&quot;Mikey&quot;, 6) # call our instance methods print(mikey.description()) print(mikey.speak(&quot;Gruff Gruff&quot;)) Mikey is 6 years old Mikey says Gruff Gruff Modifying Attributes You can change the value of attributes based on some behavior: class Email: def __init__(self): self.is_sent = False def send_email(self): self.is_sent = True my_email = Email() my_email.is_sent False my_email.send_email() my_email.is_sent True Python Object Inheritance Inheritance is the process by which one class takes on the attributes and methods of another. Newly formed classes are called child classes, and the classes that child classes are derived from are called parent classes. It’s important to note that child classes override or extend the functionality (e.g., attributes and behaviors) of parent classes. In other words, child classes inherit all of the parent’s attributes and behaviors but can also specify different behavior to follow. The most basic type of class is an object, which generally all other classes inherit as their parent. Dog Park Example Let’s pretend that we’re at a dog park. There are multiple Dog objects engaging in Dog behaviors, each with different attributes. In regular-speak that means some dogs are running, while some are stretching and some are just watching other dogs. Furthermore, each dog has been named by its owner and, since each dog is living and breathing, each ages. class Dog: def __init__(self, breed): self.breed = breed spencer = Dog(&quot;German Shepard&quot;) spencer.breed &#39;German Shepard&#39; sara = Dog(&quot;Boston Terrier&quot;) sara.breed &#39;Boston Terrier&#39; Extending the Functionality of a Parent Class # Parent class class Dog: # Class attribute species = &#39;mammal&#39; # Initializer / Instance attributes def __init__(self, name, age): self.name = name self.age = age # instance method def description(self): return &quot;{} is {} years old&quot;.format(self.name, self.age) # instance method def speak(self, sound): return &quot;{} says {}&quot;.format(self.name, sound) # Child class (inherits from Dog class) class RussellTerrier(Dog): def run(self, speed): return &quot;{} runs {}&quot;.format(self.name, speed) # Child class (inherits from Dog class) class Bulldog(Dog): def run(self, speed): return &quot;{} runs {}&quot;.format(self.name, speed) # Child classes inherit attributes and # behaviors from the parent class jim = Bulldog(&quot;Jim&quot;, 12) print(jim.description()) Jim is 12 years old # Child classes have specific attributes # and behaviors as well print(jim.run(&quot;slowly&quot;)) Jim runs slowly Parent vs. Child Classes The isinstance() function is used to determine if an instance is also an instance of a certain parent class. # Child classes inherit attributes and # behaviors from the parent class jim = Bulldog(&quot;Jim&quot;, 12) # Is jim an instance of Dog()? print(isinstance(jim, Dog)) True print(isinstance(jim, Bulldog)) True print(isinstance(jim, RussellTerrier)) False Overriding the Functionality of a Parent Class Remember that child classes can also override attributes and behaviors from the parent class. For examples: class FrenchBulldog(Bulldog): species = &#39;french bulldog&#39; sleepy = FrenchBulldog(&#39;sleepy&#39;, 2) print(sleepy.species) french bulldog print(isinstance(sleepy, Bulldog)) True print(isinstance(sleepy, FrenchBulldog)) True",
    "url": "http://localhost:4000/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/02.a%20-%20Python%20Classes.html",
    "relUrl": "/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/02.a%20-%20Python%20Classes.html"
  },
  "20": {
    "id": "20",
    "title": "02.b - Generating Other Synthetic Data",
    "content": "Generating Other Synthetic Data Source What kind of data may be needed for a rich learning experience? Imagine you are tinkering with a cool machine learning algorithm like SVM or a deep neural net. What kind of dataset you should practice them on? If you are learning from scratch, the advice is to start with simple, small-scale datasets which you can plot in two dimensions to understand the patterns visually and see for yourself the working of the ML algorithm in an intuitive fashion. For example, here is an excellent article on various datasets you can try at various level of learning. What is a synthetic dataset? As the name suggests, quite obviously, a synthetic dataset is a repository of data that is generated programmatically. So, it is not collected by any real-life survey or experiment. Its main purpose, therefore, is to be flexible and rich enough to help an ML practitioner conduct fascinating experiments with various classification, regression, and clustering algorithms. Desired properties are, It can be numerical, binary, or categorical (ordinal or non-ordinal), The number of features and length of the dataset should be arbitrary It should preferably be random and the user should be able to choose a wide variety of statistical distribution to base this data upon i.e. the underlying random process can be precisely controlled and tuned, If it is used for classification algorithms, then the degree of class separation should be controllable to make the learning problem easy or hard, Random noise can be interjected in a controllable manner For a regression problem, a complex, non-linear generative process can be used for sourcing the data What about privacy concerns? Although in this article, we keep our discussions limited to synthetic data for better ML algorithms, its purpose can be far reaching in cases where it helps get around security and privacy concerns with real datasets, that cannot be used or acquired for learning purpose. For example, think about medical or military data. Here is an excellent summary article about such methods. import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns Regression problem generation Regression problem generation: Scikit-learn’s dataset.make_regression function can create random regression problem with arbitrary number of input features, output targets, and controllable degree of informative coupling between them. It can also mix Gaussian noise. from sklearn.datasets import make_regression data1 = make_regression(n_samples=20, n_features=4, n_informative=2, n_targets=1, bias=0.0, effective_rank=None,tail_strength=0.5, noise=0.0, shuffle=True, coef=False, random_state=None) df1 = pd.DataFrame(data1[0],columns=[&#39;x&#39;+str(i) for i in range(1,5)]) df1[&#39;y&#39;] = data1[1] df1.head() x1 x2 x3 x4 y 0 -0.726064 -0.330319 1.028857 1.060585 95.436070 1 -0.552313 0.313671 -0.073183 0.285335 22.901152 2 0.822014 -0.241618 1.849015 -0.900789 -79.460904 3 0.834856 -0.268336 0.242290 0.272725 32.480840 4 -0.019002 -1.650089 -0.206772 0.564262 53.629369 Plot plt.figure(figsize=(15,10)) for i in range(1,5): fit = np.polyfit(df1[df1.columns[i-1]],df1[&#39;y&#39;],1) fit_fn = np.poly1d(fit) plt.subplot(2,2,i) plt.scatter(df1[df1.columns[i-1]],df1[&#39;y&#39;],s=200,c=&#39;orange&#39;,edgecolor=&#39;k&#39;) plt.plot(df1[df1.columns[i-1]],fit_fn(df1[df1.columns[i-1]]),&#39;b-&#39;,lw=3) plt.grid(True) Data with Gaussian noise data2 = make_regression(n_samples=20, n_features=4, n_informative=2, n_targets=1, bias=0.0, effective_rank=None,tail_strength=0.5, noise=2.0, shuffle=True, coef=False, random_state=None) df2 = pd.DataFrame(data2[0],columns=[&#39;x&#39;+str(i) for i in range(1,5)]) df2[&#39;y&#39;] = data2[1] Plot plt.figure(figsize=(15,10)) for i in range(1,5): fit = np.polyfit(df2[df2.columns[i-1]],df2[&#39;y&#39;],1) fit_fn = np.poly1d(fit) plt.subplot(2,2,i) plt.scatter(df2[df2.columns[i-1]],df2[&#39;y&#39;],s=200,c=&#39;orange&#39;,edgecolor=&#39;k&#39;) plt.plot(df2[df2.columns[i-1]],fit_fn(df2[df2.columns[i-1]]),&#39;b-&#39;,lw=3) plt.grid(True) Plot datasets with varying degree of noise plt.figure(figsize=(15,6)) df2 = pd.DataFrame(data=np.zeros((20,1))) for i in range(3): data2 = make_regression(n_samples=20, n_features=1, n_informative=1, n_targets=1, bias=0.0, effective_rank=None,tail_strength=0.5, noise=i*10, shuffle=True, coef=False, random_state=None) df2[&#39;x&#39;+str(i+1)]=data2[0] df2[&#39;y&#39;+str(i+1)] = data2[1] for i in range(3): fit = np.polyfit(df2[&#39;x&#39;+str(i+1)],df2[&#39;y&#39;+str(i+1)],1) fit_fn = np.poly1d(fit) plt.subplot(1,3,i+1) plt.scatter(df2[&#39;x&#39;+str(i+1)],df2[&#39;y&#39;+str(i+1)],s=200,c=&#39;orange&#39;,edgecolor=&#39;k&#39;) plt.plot(df2[&#39;x&#39;+str(i+1)],fit_fn(df2[&#39;x&#39;+str(i+1)]),&#39;b-&#39;,lw=3) plt.grid(True) Classification problem generation Classification problem generation: Similar to the regression function above, dataset.make_classification generates a random multi-class classification problem (dataset) with controllable class separation and added noise. You can also randomly flip any percentage of output signs to create a harder classification dataset if you want. from sklearn.datasets import make_classification data3 = make_classification(n_samples=20, n_features=4, n_informative=4, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=1, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None) df3 = pd.DataFrame(data3[0],columns=[&#39;x&#39;+str(i) for i in range(1,5)]) df3[&#39;y&#39;] = data3[1] df3.head() x1 x2 x3 x4 y 0 1.061883 0.055163 -1.267258 -2.902750 0 1 -1.201849 0.003287 -1.653525 -2.585140 0 2 -1.577193 -0.663333 -1.042551 -0.954686 0 3 -1.389437 -2.269763 -0.686865 0.309748 0 4 -1.665307 -1.256313 -0.603768 0.207372 0 Plot from itertools import combinations from math import ceil lst_var=list(combinations(df3.columns[:-1],2)) len_var = len(lst_var) plt.figure(figsize=(18,10)) for i in range(1,len_var+1): plt.subplot(2,ceil(len_var/2),i) var1 = lst_var[i-1][0] var2 = lst_var[i-1][1] plt.scatter(df3[var1],df3[var2],s=200,c=df3[&#39;y&#39;],edgecolor=&#39;k&#39;) plt.xlabel(var1,fontsize=14) plt.ylabel(var2,fontsize=14) plt.grid(True) Making class separation easy by tweaking class_sep data3 = make_classification(n_samples=20, n_features=4, n_informative=4, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=1, weights=None, flip_y=0.01, class_sep=3.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None) df3 = pd.DataFrame(data3[0],columns=[&#39;x&#39;+str(i) for i in range(1,5)]) df3[&#39;y&#39;] = data3[1] from itertools import combinations from math import ceil lst_var=list(combinations(df3.columns[:-1],2)) len_var = len(lst_var) plt.figure(figsize=(18,10)) for i in range(1,len_var+1): plt.subplot(2,ceil(len_var/2),i) var1 = lst_var[i-1][0] var2 = lst_var[i-1][1] plt.scatter(df3[var1],df3[var2],s=200,c=df3[&#39;y&#39;],edgecolor=&#39;k&#39;) plt.xlabel(var1,fontsize=14) plt.ylabel(var2,fontsize=14) plt.grid(True) Making class separation hard by tweaking class_sep data3 = make_classification(n_samples=20, n_features=4, n_informative=4, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=1, weights=None, flip_y=0.01, class_sep=0.5, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None) df3 = pd.DataFrame(data3[0],columns=[&#39;x&#39;+str(i) for i in range(1,5)]) df3[&#39;y&#39;] = data3[1] from itertools import combinations from math import ceil lst_var=list(combinations(df3.columns[:-1],2)) len_var = len(lst_var) plt.figure(figsize=(18,10)) for i in range(1,len_var+1): plt.subplot(2,ceil(len_var/2),i) var1 = lst_var[i-1][0] var2 = lst_var[i-1][1] plt.scatter(df3[var1],df3[var2],s=200,c=df3[&#39;y&#39;],edgecolor=&#39;k&#39;) plt.xlabel(var1,fontsize=14) plt.ylabel(var2,fontsize=14) plt.grid(True) Making data noisy by increasing flip_y plt.figure(figsize=(18,10)) for i in range(6): data3 = make_classification(n_samples=20, n_features=4, n_informative=4, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=1, weights=None, flip_y=0.1*i, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=False, random_state=101) df3 = pd.DataFrame(data3[0],columns=[&#39;x&#39;+str(i) for i in range(1,5)]) df3[&#39;y&#39;] = data3[1] plt.subplot(2,3,i+1) plt.title(f&quot;Plot for flip_y={round(0.1*i,2)}&quot;) plt.scatter(df3[&#39;x1&#39;],df3[&#39;x2&#39;],s=200,c=df3[&#39;y&#39;],edgecolor=&#39;k&#39;) plt.xlabel(&#39;x1&#39;,fontsize=14) plt.ylabel(&#39;x2&#39;,fontsize=14) plt.grid(True) Plot datasets with varying degree of class separation plt.figure(figsize=(18,5)) df2 = pd.DataFrame(data=np.zeros((20,1))) for i in range(3): data2 = make_classification(n_samples=20, n_features=2, n_informative=2, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=1, weights=None, flip_y=0, class_sep=i+0.5, hypercube=True, shift=0.0, scale=1.0, shuffle=False, random_state=101) df2[&#39;x&#39;+str(i+1)+&#39;1&#39;]=data2[0][:,0] df2[&#39;x&#39;+str(i+1)+&#39;2&#39;]=data2[0][:,1] df2[&#39;y&#39;+str(i+1)] = data2[1] for i in range(3): plt.subplot(1,3,i+1) plt.scatter(df2[&#39;x&#39;+str(i+1)+&#39;1&#39;],df2[&#39;x&#39;+str(i+1)+&#39;2&#39;],s=200,c=df2[&#39;y&#39;+str(i+1)],edgecolor=&#39;k&#39;) plt.grid(True) Clustering problem generation Clustering problem generation: There are quite a few functions for generating interesting clusters. The most straightforward one is datasets.make_blobs, which generates arbitrary number of clusters with controllable distance parameters. from sklearn.datasets import make_blobs data4 = make_blobs(n_samples=60, n_features=4, centers=3, cluster_std=1.0, center_box=(-5.0, 5.0), shuffle=True, random_state=None) df4 = pd.DataFrame(data4[0],columns=[&#39;x&#39;+str(i) for i in range(1,5)]) df4[&#39;y&#39;] = data4[1] from itertools import combinations from math import ceil lst_var=list(combinations(df4.columns[:-1],2)) len_var = len(lst_var) plt.figure(figsize=(18,10)) for i in range(1,len_var+1): plt.subplot(2,ceil(len_var/2),i) var1 = lst_var[i-1][0] var2 = lst_var[i-1][1] plt.scatter(df4[var1],df4[var2],s=200,c=df4[&#39;y&#39;],edgecolor=&#39;k&#39;) plt.xlabel(var1,fontsize=14) plt.ylabel(var2,fontsize=14) plt.grid(True) Making clusters compact and easily separable by tweaking cluster_std data4 = make_blobs(n_samples=60, n_features=4, centers=3, cluster_std=0.3, center_box=(-5.0, 5.0), shuffle=True, random_state=None) df4 = pd.DataFrame(data4[0],columns=[&#39;x&#39;+str(i) for i in range(1,5)]) df4[&#39;y&#39;] = data4[1] from itertools import combinations from math import ceil lst_var=list(combinations(df4.columns[:-1],2)) len_var = len(lst_var) plt.figure(figsize=(18,10)) for i in range(1,len_var+1): plt.subplot(2,ceil(len_var/2),i) var1 = lst_var[i-1][0] var2 = lst_var[i-1][1] plt.scatter(df4[var1],df4[var2],s=200,c=df4[&#39;y&#39;],edgecolor=&#39;k&#39;) plt.xlabel(var1,fontsize=14) plt.ylabel(var2,fontsize=14) plt.grid(True) Making clusters spread out and difficult to separate by tweaking cluster_std data4 = make_blobs(n_samples=60, n_features=4, centers=3, cluster_std=2.5, center_box=(-5.0, 5.0), shuffle=True, random_state=None) df4 = pd.DataFrame(data4[0],columns=[&#39;x&#39;+str(i) for i in range(1,5)]) df4[&#39;y&#39;] = data4[1] from itertools import combinations from math import ceil lst_var=list(combinations(df4.columns[:-1],2)) len_var = len(lst_var) plt.figure(figsize=(18,10)) for i in range(1,len_var+1): plt.subplot(2,ceil(len_var/2),i) var1 = lst_var[i-1][0] var2 = lst_var[i-1][1] plt.scatter(df4[var1],df4[var2],s=200,c=df4[&#39;y&#39;],edgecolor=&#39;k&#39;) plt.xlabel(var1,fontsize=14) plt.ylabel(var2,fontsize=14) plt.grid(True) Making anisotropically distributed clustering problem Anisotropic cluster generation: With a simple transformation using matrix multiplication, you can generate clusters which is aligned along certain axis or anisotropically distributed. data5 = make_blobs(n_samples=50, n_features=2, centers=3,cluster_std=1.5) transformation = [[0.5, -0.5], [-0.4, 0.8]] data5_0=np.dot(data5[0],transformation) df5 = pd.DataFrame(data5_0,columns=[&#39;x&#39;+str(i) for i in range(1,3)]) df5[&#39;y&#39;] = data5[1] plt.figure(figsize=(8,5)) plt.scatter(df5[&#39;x1&#39;],df5[&#39;x2&#39;],c=df5[&#39;y&#39;],s=200,edgecolors=&#39;k&#39;) plt.xlabel(&#39;x1&#39;,fontsize=14) plt.ylabel(&#39;x2&#39;,fontsize=14) plt.grid(True) plt.show() Making concentric circle clusters Concentric ring cluster data generation: For testing affinity based clustering algorithm or Gaussian mixture models, it is useful to have clusters generated in a special shape. We can use datasets.make_circles function to accomplish that. from sklearn.datasets import make_circles data6 = make_circles(n_samples=50, shuffle=True, noise=None, random_state=None, factor=0.6) df6 = pd.DataFrame(data6[0],columns=[&#39;x&#39;+str(i) for i in range(1,3)]) df6[&#39;y&#39;] = data6[1] plt.figure(figsize=(8,5)) plt.scatter(df6[&#39;x1&#39;],df6[&#39;x2&#39;],c=df6[&#39;y&#39;],s=200,edgecolors=&#39;k&#39;) plt.xlabel(&#39;x1&#39;,fontsize=14) plt.ylabel(&#39;x2&#39;,fontsize=14) plt.grid(True) plt.show() Introdue noise in the circle clusters data6 = make_circles(n_samples=50, shuffle=True, noise=0.15, random_state=None, factor=0.6) df6 = pd.DataFrame(data6[0],columns=[&#39;x&#39;+str(i) for i in range(1,3)]) df6[&#39;y&#39;] = data6[1] plt.figure(figsize=(8,5)) plt.scatter(df6[&#39;x1&#39;],df6[&#39;x2&#39;],c=df6[&#39;y&#39;],s=200,edgecolors=&#39;k&#39;) plt.xlabel(&#39;x1&#39;,fontsize=14) plt.ylabel(&#39;x2&#39;,fontsize=14) plt.grid(True) plt.show() Make moon shape clusters Moon-shaped cluster data generation: We can also generate moon-shaped cluster data for testing algorithms, with controllable noise using datasets.make_moons function. from sklearn.datasets import make_moons data7 = make_moons(n_samples=50, shuffle=True, noise=None, random_state=None) df7 = pd.DataFrame(data7[0],columns=[&#39;x&#39;+str(i) for i in range(1,3)]) df7[&#39;y&#39;] = data7[1] plt.figure(figsize=(8,5)) plt.scatter(df7[&#39;x1&#39;],df7[&#39;x2&#39;],c=df7[&#39;y&#39;],s=200,edgecolors=&#39;k&#39;) plt.xlabel(&#39;x1&#39;,fontsize=14) plt.ylabel(&#39;x2&#39;,fontsize=14) plt.grid(True) plt.show() Introduce noise in the moon-shaped clusters data7 = make_moons(n_samples=50, shuffle=True, noise=0.1, random_state=None) df7 = pd.DataFrame(data7[0],columns=[&#39;x&#39;+str(i) for i in range(1,3)]) df7[&#39;y&#39;] = data7[1] plt.figure(figsize=(8,5)) plt.scatter(df7[&#39;x1&#39;],df7[&#39;x2&#39;],c=df7[&#39;y&#39;],s=200,edgecolors=&#39;k&#39;) plt.xlabel(&#39;x1&#39;,fontsize=14) plt.ylabel(&#39;x2&#39;,fontsize=14) plt.grid(True) plt.show() Random regression/classification problem generation using symbolic function from Symbolic_regression_classification_generator import gen_regression_symbolic, gen_classification_symbolic Generate regression data with a symbolic expression of: data8 = gen_regression_symbolic(m=&#39;((x1^2)/2-3*x2)+20*sin(x3)&#39;,n_samples=50,noise=0.01) df8=pd.DataFrame(data8, columns=[&#39;x&#39;+str(i) for i in range(1,4)]+[&#39;y&#39;]) df8.head() x1 x2 x3 y 0 2.81256 2.44171 0.164293 -0.0854328434586468 1 -0.142291 1.23618 -6.7039 -11.8655190618648 2 -3.12003 4.51081 -1.62335 -28.6475904071715 3 3.17514 5.96053 1.35922 6.72283347069333 4 -0.714066 3.2681 -1.56271 -29.5495765823713 plt.figure(figsize=(18,5)) for i in range(1,4): plt.subplot(1,3,i) plt.scatter(df8[df8.columns[i-1]],df8[&#39;y&#39;],s=200,c=&#39;orange&#39;,edgecolor=&#39;k&#39;) plt.grid(True) Generate regression data with a symbolic expression of: data8 = 0.1*gen_regression_symbolic(m=&#39;x1^2*sin(x1)&#39;,n_samples=200,noise=0.05) df8=pd.DataFrame(data8, columns=[&#39;x&#39;+str(i) for i in range(1,2)]+[&#39;y&#39;]) plt.figure(figsize=(8,5)) plt.scatter(df8[&#39;x1&#39;],df8[&#39;y&#39;],s=100,c=&#39;orange&#39;,edgecolor=&#39;k&#39;) plt.grid(True) Generate classification data with a symbolic expression of: data9 = gen_classification_symbolic(m=&#39;((x1^2)/3-(x2^2)/15)&#39;,n_samples=500,flip_y=0.01) df9=pd.DataFrame(data9, columns=[&#39;x&#39;+str(i) for i in range(1,3)]+[&#39;y&#39;]) df9.head() x1 x2 y 0 -1.484834 -1.036240 1.0 1 -3.448183 0.979776 1.0 2 -7.778664 4.174078 1.0 3 1.976225 5.150482 0.0 4 0.653557 7.083188 0.0 plt.figure(figsize=(8,5)) plt.scatter(df9[&#39;x1&#39;],df9[&#39;x2&#39;],c=df9[&#39;y&#39;],s=100,edgecolors=&#39;k&#39;) plt.xlabel(&#39;x1&#39;,fontsize=14) plt.ylabel(&#39;x2&#39;,fontsize=14) plt.grid(True) plt.show() Generate classification data with a symbolic expression of: data9 = gen_classification_symbolic(m=&#39;x1-3*sin(x2/2)&#39;,n_samples=500,flip_y=0.01) df9=pd.DataFrame(data9, columns=[&#39;x&#39;+str(i) for i in range(1,3)]+[&#39;y&#39;]) plt.figure(figsize=(8,5)) plt.scatter(df9[&#39;x1&#39;],df9[&#39;x2&#39;],c=df9[&#39;y&#39;],s=100,edgecolors=&#39;k&#39;) plt.xlabel(&#39;x1&#39;,fontsize=14) plt.ylabel(&#39;x2&#39;,fontsize=14) plt.grid(True) plt.show() Categorical data generation using “pydbgen” library While many high-quality real-life datasets are available on the web for trying out cool machine learning techniques, from my personal experience, I found that the same is not true when it comes to learning SQL. For data science expertise, having a basic familiarity of SQL is almost as important as knowing how to write code in Python or R. But access to a large enough database with real categorical data (such as name, age, credit card, SSN, address, birthday, etc.) is not nearly as common as access to toy datasets on Kaggle, specifically designed or curated for machine learning task. Apart from the beginners in data science, even seasoned software testers may find it useful to have a simple tool where with a few lines of code they can generate arbitrarily large data sets with random (fake) yet meaningful entries. Enter pydbgen. Read the docs here. It is a lightweight, pure-python library to generate random useful entries (e.g. name, address, credit card number, date, time, company name, job title, license plate number, etc.) and save them in either Pandas dataframe object, or as a SQLite table in a database file, or in a MS Excel file. Generate name, address, phone number, email etc. using pydbgen package This is a package you need to install first with pip install pydbgen. from pydbgen import pydbgen generator = pydbgen.pydb() Generate a license-plate (US style) generator.license_plate() &#39;DEE-328&#39; Generate few random names generator.gen_data_series(num=10,data_type=&#39;name&#39;) 0 Kristin Cortez 1 Kerry Singh 2 Timothy Blanchard 3 Jaclyn Powers 4 Danielle Jones 5 David Perez 6 Jason Stewart 7 Justin Kelly 8 Joseph Moses 9 Jeanette Lopez dtype: object Generate random phone numbers generator.simple_ph_num() &#39;209-922-0398&#39; generator.gen_data_series(num=10,data_type=&#39;phone_number_full&#39;) 0 1-195-730-3152x151 1 827.024.2732x1761 2 977-282-0138x3868 3 655-724-0652x010 4 088-458-4360x7793 5 1-526-302-3859 6 315-650-7567 7 493.804.2412x6951 8 1-770-960-5933x867 9 664.585.2472 dtype: object Generate a full data frame with random name, street address, SSN, email, date df10 = generator.gen_dataframe(fields=[&#39;name&#39;,&#39;street_address&#39;,&#39;ssn&#39;,&#39;email&#39;,&#39;date&#39;]) df10 name street_address ssn email date 0 David Washington 893 Deborah Spur Apt. 341 863-23-8636 David.W34@gmail.com 2004-06-29 1 Daniel Bush 942 Gabriel Brooks 406-17-7350 DBush@protonmail.com 1991-05-11 2 Anna Roberson 3209 Todd Views Apt. 410 256-68-9954 ARoberson@protonmail.com 1982-07-23 3 Jacob Parker 132 Bailey Overpass Suite 627 771-91-9716 Parker_Jacob@aol.com 1970-01-22 4 Mr. Jeffrey Zimmerman 85005 Weeks Prairie 090-57-2158 Mr.Zimmerman@att.com 1975-12-27 5 Lisa Reyes 6675 Jack Orchard 019-20-2315 Lisa_R@yandex.com 2016-09-09 6 Anna Gonzales 4169 Edwards Island Suite 974 441-94-8985 Gonzales.Anna@yandex.com 1999-06-24 7 Melanie Frazier 752 Dawn Neck 392-39-6581 Melanie.F@protonmail.com 2001-05-07 8 Lindsey King 862 Donald Trace 457-83-0301 King.Lindsey@zoho.com 1985-01-03 9 David Hawkins 204 Weiss Mall Apt. 256 072-33-6619 DavidHawkins@att.com 1982-04-13",
    "url": "http://localhost:4000/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/02.b%20-%20Generating%20Other%20Synthetic%20Data.html",
    "relUrl": "/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/02.b%20-%20Generating%20Other%20Synthetic%20Data.html"
  },
  "21": {
    "id": "21",
    "title": "02.b - Python Modules and Packages",
    "content": "Python Modules Python Modules A module allows you to logically organize your Python code. Grouping related code into a module makes the code easier to understand and use. A module is a Python object with arbitrarily named attributes that you can bind and reference. Simply, a module is a file consisting of Python code. A module can define functions, classes and variables. A module can also include runnable code. The import Statement You can use any Python source file as a module by executing an import statement in some other Python source file. The import has the following syntax import module1[, module2[,... moduleN] When the interpreter encounters an import statement, it imports the module if the module is present in the search path. A search path is a list of directories that the interpreter searches before importing a module. For example, to import the module support.py, you need to put the following command at the top of the script # Import module support import support # Now you can call defined function that module as follows support.print_func(&quot;drk&quot;) Hello : drk A module is loaded only once, regardless of the number of times it is imported. This prevents the module execution from happening over and over again if multiple imports occur. The from…import Statement Python’s from statement lets you import specific attributes from a module into the current namespace. The from…import has the following syntax from modname import name1[, name2[, ... nameN]] For example, to import the function fibonacci from the module fib, use the following statement − from fib import fibonacci This statement does not import the entire module fib into the current namespace; it just introduces the item fibonacci from the module fib into the global symbol table of the importing module. The from…import * Statement It is also possible to import all names from a module into the current namespace by using the following import statement from modname import * This provides an easy way to import all the items from a module into the current namespace; however, this statement should be used sparingly. Locating Modules When you import a module, the Python interpreter searches for the module in the following sequences − The current directory. If the module isn’t found, Python then searches each directory in the shell variable PYTHONPATH. If all else fails, Python checks the default path. On UNIX, this default path is normally /usr/local/lib/python/. The module search path is stored in the system module sys as the sys.path variable. The sys.path variable contains the current directory, PYTHONPATH, and the installation-dependent default. Python Packages A package is a hierarchical file directory structure that defines a single Python application environment that consists of modules and subpackages and sub-subpackages, and so on. Consider a file Pots.py available in Phone directory. This file has following line of source code − def Pots(): print &quot;I&#39;m Pots Phone&quot; Similar way, we have another two files having different functions with the same name as above − Phone/Isdn.py file having function Isdn() Phone/G3.py file having function G3() Now, create one more file init.py in Phone directory To make all of your functions available when you’ve imported Phone, you need to put explicit import statements in init.py as follows from Pots import Pots from Isdn import Isdn from G3 import G3 After you add these lines to init.py, you have all of these classes available when you import the Phone package. # Now import your Phone Package. import Phone as p p.Pots() I&#39;m a Pots Phone. p.Isdn() I&#39;m an Isdn phone. p.G3() I&#39;m a G3 phone.",
    "url": "http://localhost:4000/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/02.b%20-%20Python%20Modules%20and%20Packages.html",
    "relUrl": "/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/02.b%20-%20Python%20Modules%20and%20Packages.html"
  },
  "22": {
    "id": "22",
    "title": "02.c - Using Synthea",
    "content": "Synthea Home Synthea Introduction Basic Setup and Running In a termainal, change the directory to where synthea is installed and execute the run_synthea script OSX cd ~/Documents/Source/synthea ./run_synthea Windows cd c: users kolowitz synthea run_synthea.bat Note: if running on Windows, use . run_synthea.bat instead of ./run_synthea – this guide uses ./run_synthea for brevity import os import pathlib os.chdir(os.path.join(pathlib.Path.home(), &#39;Documents/Source/synthea&#39;)) # generate a population of 5 patients !./run_synthea -p 5 # generate a population of 5 patients in Pittsburgh Pennsylvania !./run_synthea -p 5 Pennsylvania Pittsburgh # generate a population of 5 patients with a seed of 12345 !./run_synthea -p 5 -s 12345 Common Configuration Source Setting Name Valid Values Default Description exporter.ccda.export true/false false Change this setting to true to enable exporting patients in CCDA format. exporter.fhir.export true/false true Change this setting to false to disable exporting patients in FHIR R4 format. exporter.text.export true/false false Change this setting to true to enable exporting patients in a simple text-based format. exporter.csv.export true/false false Change this setting to true to enable exporting patient data in a comma-separated value format. See the CSV File Data Dictionary. exporter.years_of_history Whole number 10 The number of years of patient history to include in patient records. For example, if set to 5, then all patient history older than 5 years old (from the time you execute the program) will not be included in the exported records. Note that conditions and medications that are currently active will still be exported, regardless of this setting. Set this to 0 to keep all history in the patient record. !cat ./src/main/resources/synthea.properties cat: ./src/main/resources/synthea.properties: No such file or directory",
    "url": "http://localhost:4000/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/02.c%20-%20Using%20Synthea.html",
    "relUrl": "/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/02.c%20-%20Using%20Synthea.html"
  },
  "23": {
    "id": "23",
    "title": "03 - Getting Data from a Database",
    "content": "SQLAlchemy — Python Tutorial Source Other References What are Object Relational Mappers (ORMs) SQLAlchemy Basics We often encounter data as Relational Databases. To work with them we generally would need to write raw SQL queries, pass them to the database engine and parse the returned results as a normal array of records. SQLAlchemy provides a nice “Pythonic” way of interacting with databases. So rather than dealing with the differences between specific dialects of traditional SQL such as MySQL or PostgreSQL or Oracle, you can leverage the Pythonic framework of SQLAlchemy to streamline your workflow and more efficiently query your data. # Installing The Package !pip install sqlalchemy Connecting to a database To start interacting with the database we first we need to establish a connection. import sqlalchemy as db engine = db.create_engine(&#39;dialect+driver://user:pass@host:port/db&#39;) Database connection examples Source PostgreSQL # default engine = create_engine(&#39;postgresql://scott:tiger@localhost/mydatabase&#39;) # psycopg2 engine = create_engine(&#39;postgresql+psycopg2://scott:tiger@localhost/mydatabase&#39;) # pg8000 engine = create_engine(&#39;postgresql+pg8000://scott:tiger@localhost/mydatabase&#39;) MySQL # default engine = create_engine(&#39;mysql://scott:tiger@localhost/foo&#39;) # mysqlclient (a maintained fork of MySQL-Python) engine = create_engine(&#39;mysql+mysqldb://scott:tiger@localhost/foo&#39;) # PyMySQL engine = create_engine(&#39;mysql+pymysql://scott:tiger@localhost/foo&#39;) Oracle engine = create_engine(&#39;oracle://scott:tiger@127.0.0.1:1521/sidname&#39;) engine = create_engine(&#39;oracle+cx_oracle://scott:tiger@tnsname&#39;) Microsoft SQL Server # pyodbc engine = create_engine(&#39;mssql+pyodbc://scott:tiger@mydsn&#39;) # pymssql engine = create_engine(&#39;mssql+pymssql://scott:tiger@hostname:port/dbname&#39;) SQLite # sqlite://&lt;nohostname&gt;/&lt;path&gt; # where &lt;path&gt; is relative: engine = create_engine(&#39;sqlite:///foo.db&#39;) # Unix/Mac - 4 initial slashes in total engine = create_engine(&#39;sqlite:////absolute/path/to/foo.db&#39;) # Windows engine = create_engine(&#39;sqlite:///C: path to foo.db&#39;) # Windows alternative using raw string engine = create_engine(r&#39;sqlite:///C: path to foo.db&#39;) # To use a SQLite :memory: database, specify an empty URL: engine = create_engine(&#39;sqlite://&#39;) Viewing Table Details SQLAlchemy can be used to automatically load tables from a database using something called reflection. Reflection is the process of reading the database and building the metadata based on that information. import sqlalchemy as db engine = db.create_engine(&#39;sqlite:///census.sqlite&#39;) connection = engine.connect() metadata = db.MetaData() census = db.Table(&#39;census&#39;, metadata, autoload=True, autoload_with=engine) # Print the column names print(census.columns.keys()) # Print full table metadata print(repr(metadata.tables[&#39;census&#39;])) Querying Table and MetaData have already been imported. The metadata is available as metadata. import sqlalchemy as db engine = db.create_engine(&#39;sqlite:///census.sqlite&#39;) connection = engine.connect() metadata = db.MetaData() census = db.Table(&#39;census&#39;, metadata, autoload=True, autoload_with=engine) #Equivalent to &#39;SELECT * FROM census&#39; query = db.select([census]) ResultProxy: The object returned by the .execute() method. It can be used in a variety of ways to get the data returned by the query. ResultProxy = connection.execute(query) ResultSet: The actual data asked for in the query when using a fetch method such as .fetchall() on a ResultProxy. ResultSet = ResultProxy.fetchall() ResultSet[:3] Dealing with Large ResultSet We use .fetchmany() to load optimal no of rows and overcome memory issues in case of large datasets. ResultProxy = connection.execute(query) # ResultSet = ResultProxy.fetchall() flag = True while flag: print(&#39;*** new fetch&#39;) partial_results = ResultProxy.fetchmany(5) if(partial_results == []): flag = False for result in partial_results: print(&#39; t&#39;, result) # print(partial_results) ResultProxy.close() Convert to DataFrame import pandas as pd df = pd.DataFrame(ResultSet) df.columns = ResultSet[0].keys() df.head() Filtering data Lets see some examples of raw SQLite Queries and queries using SQLAlchemy. where SQL SELECT * FROM census WHERE sex = F # SQLAlchemy db.select([census]).where(census.columns.sex == &#39;F&#39;) in SQL SELECT state, sex FROM census WHERE state IN (Texas, New York) # SQLAlchemy db.select([census.columns.state, census.columns.sex]) .where(census.columns.state.in_([&#39;Texas&#39;, &#39;New York&#39;])) and, or, not SQL SELECT * FROM census WHERE state = &#39;California&#39; AND NOT sex = &#39;M&#39; # SQLAlchemy db.select([census]) .where(db.and_(census.columns.state == &#39;California&#39;, census.columns.sex != &#39;M&#39;)) order by SQL SELECT * FROM census ORDER BY State DESC, pop2000 # SQLAlchemy db.select([census]).order_by( db.desc(census.columns.state), census.columns.pop2000) functions other functions include avg, count, min, max SQL SELECT SUM(pop2008) FROM census # SQLAlchemy query = db.select([db.func.sum(census.columns.pop2008)]) ResultSet = connection.execute(query).fetchall() pd.DataFrame(ResultSet) group by SQL SELECT SUM(pop2008) as pop2008, sex FROM census GROUP BY sex # SQLAlchemy query = db.select([db.func.sum(census.columns.pop2008).label(&#39;pop2008&#39;), census.columns.sex]).group_by(census.columns.sex) ResultSet = connection.execute(query).fetchall() pd.DataFrame(ResultSet) distinct SQL SELECT DISTINCT state FROM census # SQLAlchemy query = db.select([census.columns.state.distinct()]) ResultSet = connection.execute(query).fetchall() pd.DataFrame(ResultSet) case &amp; cast The case() expression accepts a list of conditions to match and the column to return if the condition matches, followed by an else_ if none of the conditions match. cast() function to convert an expression to a particular type engine = db.create_engine(&#39;sqlite:///census.sqlite&#39;) connection = engine.connect() metadata = db.MetaData() census = db.Table(&#39;census&#39;, metadata, autoload=True, autoload_with=engine) female_pop = db.func.sum( db.case([(census.columns.sex == &#39;F&#39;, census.columns.pop2000)], else_=0)) ResultSet = connection.execute(female_pop).fetchall() pd.DataFrame(ResultSet) total_pop = db.cast(db.func.sum(census.columns.pop2000), db.Float) query = db.select([female_pop/total_pop * 100]) ResultSet = connection.execute(query).fetchall() pd.DataFrame(ResultSet) result = connection.execute(query).scalar() print(result) We use .scalar to the result when the result contains only single value joins If you have two tables that already have an established relationship, you can automatically use that relationship by just adding the columns we want from each table to the select statement. select([census.columns.pop2008, state_fact.columns.abbreviation]) engine = db.create_engine(&#39;sqlite:///census.sqlite&#39;) connection = engine.connect() metadata = db.MetaData() census = db.Table(&#39;census&#39;, metadata, autoload=True, autoload_with=engine) state_fact = db.Table(&#39;state_fact&#39;, metadata, autoload=True, autoload_with=engine) # Automatic Join query = db.select([census.columns.pop2008, state_fact.columns.abbreviation]) results = connection.execute(query).fetchall() df = pd.DataFrame(results) df.columns = results[0].keys() df.head(5) # Manual Join query = db.select([census, state_fact]) query = query.select_from(census.join(state_fact, census.columns.state == state_fact.columns.name)) results = connection.execute(query).fetchall() df = pd.DataFrame(results) df.columns = results[0].keys() df.head(5) Creating and Inserting Data into Tables By passing the database which is not present, to the engine then sqlalchemy automatically creates a new database. Creating Database and Table # delete the test database import os test_db_name = &#39;test.sqlite&#39; if os.path.exists(test_db_name): os.remove(test_db_name) engine = db.create_engine(f&#39;sqlite:///{test_db_name}&#39;) #Create test.sqlite automatically connection = engine.connect() metadata = db.MetaData() emp = db.Table(&#39;emp&#39;, metadata, db.Column(&#39;Id&#39;, db.Integer()), db.Column(&#39;name&#39;, db.String(255), nullable=False), db.Column(&#39;salary&#39;, db.Float(), default=100.0), db.Column(&#39;active&#39;, db.Boolean(), default=True) ) metadata.create_all(engine) #Creates the table Inserting Data #Inserting record one by one query = db.insert(emp).values(Id=1, name=&#39;naveen&#39;, salary=60000.00, active=True) ResultProxy = connection.execute(query) #Inserting many records at ones query = db.insert(emp) values_list = [{&#39;Id&#39;:&#39;2&#39;, &#39;name&#39;:&#39;ram&#39;, &#39;salary&#39;:80000, &#39;active&#39;:False}, {&#39;Id&#39;:&#39;3&#39;, &#39;name&#39;:&#39;ramesh&#39;, &#39;salary&#39;:70000, &#39;active&#39;:True}] ResultProxy = connection.execute(query, values_list) results = connection.execute(db.select([emp])).fetchall() df = pd.DataFrame(results) df.columns = results[0].keys() df.head(4) Updating data in Databases db.update(table_name).values(attribute = new_value).where(condition) engine = db.create_engine(f&#39;sqlite:///{test_db_name}&#39;) metadata = db.MetaData() connection = engine.connect() emp = db.Table(&#39;emp&#39;, metadata, autoload=True, autoload_with=engine) results = connection.execute(db.select([emp])).fetchall() df = pd.DataFrame(results) df.columns = results[0].keys() df.head(4) # Build a statement to update the salary to 100000 query = db.update(emp).values(salary = 100000) query = query.where(emp.columns.Id == 1) results = connection.execute(query) results = connection.execute(db.select([emp])).fetchall() df = pd.DataFrame(results) df.columns = results[0].keys() df.head(4) Delete Table db.delete(table_name).where(condition) engine = db.create_engine(f&#39;sqlite:///{test_db_name}&#39;) metadata = db.MetaData() connection = engine.connect() emp = db.Table(&#39;emp&#39;, metadata, autoload=True, autoload_with=engine) results = connection.execute(db.select([emp])).fetchall() df = pd.DataFrame(results) df.columns = results[0].keys() df.head(4) # Build a statement to delete where salary &lt; 100000 query = db.delete(emp) query = query.where(emp.columns.salary &lt; 100000) results = connection.execute(query) results = connection.execute(db.select([emp])).fetchall() df = pd.DataFrame(results) df.columns = results[0].keys() df.head(4) Dropping a Table table_name.drop(engine) #drops a single table metadata.drop_all(engine) #drops all the tables in the database engine = db.create_engine(f&#39;sqlite:///{test_db_name}&#39;) metadata = db.MetaData() connection = engine.connect() # drop a table emp = db.Table(&#39;emp&#39;, metadata, autoload=True, autoload_with=engine) emp.drop(engine) # drop all tables metadata.drop_all(engine)",
    "url": "http://localhost:4000/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/03%20-%20Getting%20Data%20from%20a%20Database.html",
    "relUrl": "/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/03%20-%20Getting%20Data%20from%20a%20Database.html"
  },
  "24": {
    "id": "24",
    "title": "03 - Matplotlib Tutorial Python Plotting",
    "content": "Matplotlib Tutorial Python Plotting Source This Matplotlib tutorial takes you through the basics Python data visualization: the anatomy of a plot, pyplot and pylab, and much more. Humans are very visual creatures: we understand things better when we see things visualized. However, the step to presenting analyses, results or insights can be a bottleneck: you might not even know where to start or you might have already a right format in mind, but then questions like “Is this the right way to visualize the insights that I want to bring to my audience?” will have definitely come across your mind. When you’re working with the Python plotting library Matplotlib, the first step to answering the above questions is by building up knowledge on topics like: The anatomy of a Matplotlib plot: what is a subplot? What are the Axes? What exactly is a figure? Plot creation, which could raise questions about what module you exactly need to import (pylab or pyplot?), how you exactly should go about initializing the figure and the Axes of your plot, how to use matplotlib in Jupyter notebooks, etc. Plotting routines, from simple ways to plot your data to more advanced ways of visualizing your data. Basic plot customizations, with a focus on plot legends and text, titles, axes labels and plot layout. Saving, showing, clearing, … your plots: show the plot, save one or more figures to, for example, pdf files, clear the axes, clear the figure or close the plot, etc. Lastly, you’ll briefly cover two ways in which you can customize Matplotlib: with style sheets and the rc settings. What Does A Matplotlib Python Plot Look Like? At first sight, it will seem that there are quite some components to consider when you start plotting with this Python data visualization library. You’ll probably agree with me that it’s confusing and sometimes even discouraging seeing the amount of code that is necessary for some plots, not knowing where to start yourself and which components you should use. Luckily, this library is very flexible and has a lot of handy, built-in defaults that will help you out tremendously. As such, you don’t need much to get started: you need to make the necessary imports, prepare some data, and you can start plotting with the help of the plot() function! When you’re ready, don’t forget to show your plot using the show() function. # Import the necessary packages and modules import matplotlib.pyplot as plt import numpy as np # Prepare the data x = np.linspace(0, 10, 100) # Plot the data plt.plot(x, x, label=&#39;linear&#39;) # Add a legend plt.legend() # Show the plot plt.show() Note that you import the pyplot module of the matplotlib library under the alias plt. Congrats, you have now successfully created your first plot! Now let’s take a look at the resulting plot in a little bit more detail. What you can’t see on the surface is that you have maybe unconsciously made use of the built-in defaults that take care of the creation of the underlying components, such as the Figure and the Axes. You’ll read more about these defaults in the section that deals with the differences between pylab and pyplot. For now, you’ll understand that working with matplotlib will already become a lot easier when you understand how the underlying components are instantiated. Or, in other words, what the anatomy of a matplotlib plot looks like: Source In essence, there are two big components that you need to take into account: The Figure is the overall window or page that everything is drawn on. It’s the top-level component of all the ones that you will consider in the following points. You can create multiple independent Figures. A Figure can have several other things in it, such as a suptitle, which is a centered title to the figure. You’ll also find that you can add a legend and color bar, for example, to your Figure. To the figure you add Axes. The Axes is the area on which the data is plotted with functions such as plot() and scatter() and that can have ticks, labels, etc. associated with it. This explains why Figures can contain multiple Axes. Tip: when you see, for example, plt.xlim, you’ll call ax.set_xlim() behind the covers. All methods of an Axes object exist as a function in the pyplot module and vice versa. Note that mostly, you’ll use the functions of the pyplot module because they’re much cleaner, at least for simple plots! You’ll see what “clean” means when you take a look at the following pieces of code. Compare, for example, this piece of code: fig = plt.figure() ax = fig.add_subplot(111) ax.plot([1, 2, 3, 4], [10, 20, 25, 30], color=&#39;lightblue&#39;, linewidth=3) ax.scatter([0.3, 3.8, 1.2, 2.5], [11, 25, 9, 26], color=&#39;darkgreen&#39;, marker=&#39;^&#39;) ax.set_xlim(0.5, 4.5) plt.show() With the piece of code below: plt.plot([1, 2, 3, 4], [10, 20, 25, 30], color=&#39;lightblue&#39;, linewidth=3) plt.scatter([0.3, 3.8, 1.2, 2.5], [11, 25, 9, 26], color=&#39;darkgreen&#39;, marker=&#39;^&#39;) plt.xlim(0.5, 4.5) plt.show() The second code chunk is definitely cleaner, isn’it it? Note: that the above code examples come from the Anatomy of Matplotlib Tutorial by Benjamin Root. However, if you have multiple axes, it’s still better to make use of the first code chunk because it’s always better to prefer explicit above implicit code! In such cases, you want to make use of the Axes object ax. Next to these two components, there are a couple more that you can keep in mind: Each Axes has an x-axis and a y-axis, which contain ticks, which have major and minor ticklines and ticklabels. There’s also the axis labels, title, and legend to consider when you want to customize your axes, but also taking into account the axis scales and gridlines might come in handy. Spines are lines that connect the axis tick marks and that designate the boundaries of the data area. In other words, they are the simple black square that you get to see when you don’t plot any data at all but when you have initialized the Axes, like in the picture below: Source You see that the right and top spines are set to invisible. Note that you’ll sometimes also read about Artist objects, which are virtually all objects that the package has to offers to users like yourself. Everything drawn using Matplotlib is part of the Artist module. The containers that you will use to plot your data, such as Axis, Axes and Figure, and other graphical objects such as text, patches, etc. are types of Artists. For those who have already got some coding experience, it might be good to check out and study the code examples that you find in the Matplotlib gallery. Matplotlib, pyplot and pylab: how are they related? First off, you’ll already know Matplotlib by now. When you talk about “Matplotlib”, you talk about the whole Python data visualization package. This should not come to you as a big surprise :) Secondly, pyplot is a module in the matplotlib package. That’s why you often see matplotlib.pyplot in code. The module provides an interface that allows you to implicitly and automatically create figures and axes to achieve the desired plot. This is especially handy when you want to quickly plot something without instantiating any Figures or Axes, as you saw in the example in the first section of this tutorial. You see, you haven’t explicitly specified these components, yet you manage to output a plot that you have even customized! The defaults are initialized and any customizations that you do, will be done with the current Figure and Axes in mind. Lastly, pylab is another module, but it gets installed alongside the matplotlib package. It bulk imports pyplot and the numpy library and was generally recommended when you were working with arrays, doing mathematics interactively and wanted access to plotting features. You might still see this popping up in older tutorials and examples of matplotlib, but its use is no longer recommended, especially not when you’re using the IPython kernel in your Jupyter notebook. You can read more about this here. As a solution, you can best use %matplotlib magic in combination with the right backend, such as inline, qt, etc. Most of the times, you will want to use inline, as this will make sure that the plots are embedded inside the notebook. Read more about that in DataCamp’s Definitive Guide to Jupyter Notebook. Note that also when you’re not working in a Jupyter notebook, you’ll still need to choose a different backend, depending on your use case. In other words, if you don’t want to embed plots inside a notebook, but you rather want to embed them into graphical user interfaces, in batch scripts or web application servers, etc., you will need to specify the backend that you want to use. However, this topic is outside the scope of this tutorial; Instead, the tutorial assumes that you will be using Matplotlib to save your images to your local file system. Data For Matplotlib Plots As you have read in one of the previous sections, Matplotlib is often used to visualize analyses or calcuations. That’s why the first step that you have to take in order to start plotting in Python yourself is to consider revising NumPy, the Python library for scientific computing. Scientific computing might not really seem of much interest, but when you’re doing data science you’ll find yourself working a lot with data that is stored in arrays. You’ll need to perform operations on them, inspect your arrays and manipulate them so that you’re working with the (subset of the) data that is interesting for your analysis and that is in the right format, etc. In short, you’ll find NumPy extremely handy when you’re working with this data visualization library. If you’re interested in taking a NumPy tutorial to start well-prepared, go and take DataCamp’s tutorial and make sure to have your copy of their NumPy cheat sheet close! Of course, arrays are not the only thing that you pass to your plotting functions; There’s also the possibility to, for example, pass Python lists. If you would like to know more about Python lists, consider checking out their Python list tutorial or the free Intro to Python for Data Science course. Create Your Plot Alright, you’re off to create your first plot yourself with Python! As you have read in one of the previous sections, the Figure is the first step and the key to unlocking the power of this package. Next, you see that you initialize the axes of the Figure in the code chunk above with fig.add_axes(): # Initialize a Figure fig = plt.figure() # Add Axes to the Figure fig.add_axes([0,0,1,1]) plt.show() What Is A Subplot? You have seen all components of a plot and you have initialized your first figure and Axes, but to make things a bit more complicated, you’ll sometimes see subplots pop up in code. You use subplots to set up and place your Axes on a regular grid. So that means that in most cases, Axes and subplot are synonymous, they will designate the same thing. When you do call subplot to add Axes to your figure, do so with the add_subplots() function. There is, however, a difference between the add_axes() and the add_subplots() function, but you’ll learn more about this later on in the tutorial. Consider the following example: import numpy as np # Create a Figure fig = plt.figure() # Set up Axes ax = fig.add_subplot(111) # Scatter the data ax.scatter(np.linspace(0, 1, 5), np.linspace(0, 5, 5)) # Show the plot plt.show() You see that the add_subplot() function in itsef also poses you with a challenge, because you see add_subplots(111) in the above code chunk. What does 111 mean? Well, 111 is equal to 1,1,1, which means that you actually give three arguments to add_subplot(). The three arguments designate the: the number of rows (1), the number of columns (1) the plot number (1). So you actually make one subplot. Note: that you can really go bananas with this function when you are using this function, especially when you’re just starting out with this library and you keep on forgetting for what the three numbers stand. Consider the following commands and try to envision what the plot will look like and how many Axes your Figure will have: ax = fig.add_subplot(2,2,1). Your Figure will have four axes in total, arranged in a structure that has two rows and two columns. With the line of code that you have considered, you say that the variable ax is the first of the four axes to which you want to start plotting. The “first” in this case means that it will be the first axes on the left of the 2x2 structure that you have initialized. What Is The Difference Between add_axes() and add_subplot()? The difference between fig.add_axes() and fig.add_subplot() doesn’t lie in the result: they both return an Axes object. However, they do differ in the mechanism that is used to add the axes: you pass a list to add_axes() which is the lower left point, the width and the height. This means that the axes object is positioned in absolute coordinates. In contrast, the add_subplot() function doesn’t provide the option to put the axes at a certain position: it does, however, allow the axes to be situated according to a subplot grid, as you have seen in the section above. In most cases, you’ll use add_subplot() to create axes; Only in cases where the positioning matters, you’ll resort to add_axes(). Alternatively, you can also use subplots() if you want to get one or more subplots at the same time. You’ll see an example of how this works in the next section. How To Change The Size of Figures Now that you have seen how to initialize a Figure and Axes from scratch, you will also want to know how you can change certain small details that the package sets up for you, such as the figure size. Let’s say you don’t have the luxury to follow along with the defaults and you want to change this. How do you set the size of your figures manually? Like everything with this package, it’s pretty easy, but you need to know first what to change. Add an argument figsize to your plt.figure() function of the pyplot module; You just have to specify a tuple with the width and hight of your figure in inches, just like this plt.figure(figsize=(3,4)), for it to work. Note that you can also pass figsize to the the plt.subplots() function of the same module; The inner workings are the same as the figure() function that you’ve just seen. See an example of how this would work here: # Initialize the plot fig = plt.figure(figsize=(20,10)) ax1 = fig.add_subplot(121) ax2 = fig.add_subplot(122) # Plot the data ax1.bar([1,2,3],[3,4,5]) ax2.barh([0.5,1,2.5],[0,1,2]) # Show the plot plt.show() # alternatively fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,10)) # or replace the three lines of code above by the following line: #fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,10)) # Plot the data ax1.bar([1,2,3],[3,4,5]) ax2.barh([0.5,1,2.5],[0,1,2]) # Show the plot plt.show() Working With Pyplot: Plotting Routines Now that all is set for you to start plotting your data, it’s time to take a closer look at some plotting routines. You’ll often come across functions like plot() and scatter(), which either draw points with lines or markers connecting them, or draw unconnected points, which are scaled or colored. But, as you have already seen in the example of the first section, you shouldn’t forget to pass the data that you want these functions to use! These functions are only the bare basics. You will need some other functions to make sure your plots look awesome: Method Description ax.bar() Vertical rectangles ax.barh() Horizontal rectangles ax.axhline() Horizontal line across axes ax.vline() Vertical line across axes ax.fill() Filled polygons ax.fill_between() Fill between y-values and 0 ax.stackplot() Stack plot If you’re curious how you can use these functions to plot your data, consider the following example. data = [ {&#39;x&#39;: [1,2,3], &#39;y&#39;:[3,4,5], &#39;horizontal&#39;: False}, {&#39;x&#39;: [0.5,1,2.5], &#39;y&#39;:[0,1,2], &#39;horizontal&#39;: True} ] # alternatively fig, axes = plt.subplots(len(data), 1, figsize=(10,20)) # or replace the three lines of code above by the following line: #fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,10)) for index, ax in enumerate(axes): if data[index][&#39;horizontal&#39;]: ax.barh(data[index][&#39;x&#39;], data[index][&#39;y&#39;]) else: ax.bar(data[index][&#39;x&#39;], data[index][&#39;y&#39;]) # Show the plot plt.show() x = np.array([ 0., 0.25, 0.5, 0.75, 1. ], dtype=np.float64) y = np.array([ 0., 1.25, 2.5, 3.75, 5. ], dtype=np.float64) # Initialize the plot # fig = plt.figure(figsize=(15,10)) fig = plt.figure() ax1 = fig.add_subplot(131) ax2 = fig.add_subplot(132) ax3 = fig.add_subplot(133) # Plot the data ax1.bar([1,2,3],[3,4,5]) ax2.barh([0.5,1,2.5],[0,1,2]) ax2.axhline(0.45) ax1.axvline(0.65) ax3.scatter(x,y) # Show the plot plt.show() Most functions speak for themselves because the names are quite clear. But that doesn’t mean that you need to limit yourself: for example, the fill_between() function is perfect for those who want to create area plots, but they can also be used to create a stacked line graph; Just use the plotting function a couple of times to make sure that the areas overlap and give the illusion of being stacked. Note that, of course, simply passing the data is not enough to create great plots. Make sure to manipulate your data in such a way that the visualization makes sense: don’t be afraid to change your array shape, combine arrays, etc. When you move on and you start to work with vector fields or data distributions, you might want to check out the following functions: Method Description ax.arrow() Arrow ax.quiver() 2D field of arrows ax.streamplot() 2D vector fields ax.hist() Histogram ax.boxplot() Boxplot ax.violinplot() Violinplot Note of course that you probably won’t use all of the functions listed in these tables; It really depends on your data and your use case. If you’re totally new to data science, you might want to check out the statistical plotting routines first! On the other hand, when you work with 2-D or n-D data, you might also find yourself in need of some more advanced plotting routines, like these ones: Method Description ax.pcolor() Pseudocolor plot ax.pcolormesh() Pseudocolor plot ax.contour() Contour plot ax.contourf() Filled contour plot ax.clabel() Labeled contour plot Note that contour plots are used to explore the potential relationship between three variables. Just like contour plots, also pseudocolor plots can be used for this purpose, since they are surface plot seen from above. Of course, this are not nearly all the functions that you can use to plot your data. If you’re working with images or 2D data, for example, you might also want to check out imshow() to show images in your subplots. For a practical example of how to use the imshow() function, go to DataCamp’s scikit-learn tutorial. The examples in the tutorial also make clear that this data visualization library is really the cherry on the pie in the data science workflow: you have to be quite well-versed in general Python concepts, such as lists and control flow, which can come especially handy if you want to automate the plotting for a great number of subplots. If you feel like revising these concepts, consider taking the free introduction to Python for data science course. Customizing Your PyPlot A lot of questions about this package come from the fact that there are a lot of things that you can do to personalize your plots and make sure that they are unique: besides adjusting the colors, you also have the option to change markers, linestyles and linewidths, add text, legend and annotations, and change the limits and layout of your plots. It’s exactly the fact that there is an endless range of possibilities when it comes to these plots that makes it difficult to set out some things that you need to know when you start working on this topic. Great tips that you should keep in the back of your mind are not only the gallery, which contains many real-life examples that are already coded for you and which you can use, but also the documentation, which can tell you more about the arguments that you can pass to certain functions to adjust visual features. Also keep in mind that there are multiple solutions for one problem and that you learn most of this stuff when you’re getting your hands dirty with the package itself and when you run into troubles. You’ll see some of the most common questions and solutions in this section. Deleting an Axis If you ever want to remove an axes form your plot, you can use delaxes() to remove and update the current axes. Note: you can restore a deleted axes by adding fig.add_axes(ax) right after fig.delaxes(ax3). # Initialize the plot fig = plt.figure() ax1 = fig.add_subplot(131) ax2 = fig.add_subplot(132) ax3 = fig.add_subplot(133) # Plot the data ax1.bar([1,2,3],[3,4,5]) ax2.barh([0.5,1,2.5],[0,1,2]) ax2.axhline(0.45) ax1.axvline(0.65) ax3.scatter(np.linspace(0, 1, 5), np.linspace(0, 5, 5)) # Delete `ax3` fig.delaxes(ax3) # Show the plot plt.show() How To Put The Legend Out of the Plot There are a number of ways to address this question, but mostly all come back to the arguments that you can provide to legend(): You can specify the loc or location argument to something like center left or upper right, which ensures that your legend does not fall in the Axes or subplot area. Alternatively, you can also add the bbox_to_anchor argument to your function and pass a tuple with the coordinates in which you want to put the legend. In this case, the box is put in the upper right corner of the plotting area: ax.legend(bbox_to_anchor=(1.1, 1.05)). How To Set Plot Title And Axes Labels To change your plot title and axes labels, you can follow one of the following approaches, depending of which container of which you want to make use: The easiest way to set these things right is by using ax.set(title=&quot;A title&quot;, xlabel=&quot;x&quot;, ylabel=&quot;y&quot;) or ax.set_xlim(), ax.set_ylim() or ax.set_title(). If you want to work with the figure, you might also resort to fig.suptitle() to add a title to your plot. If you’re making use of the default settings that the package has to offer, you might want to use plt.title(), plt.xlabel(), plt.ylabel(). Define your own style sheet or change the default matplotlibrc settings. Read more about this here. How To Fix The Plot Layout A thing to consider when you’re using subplots to build up your plot is the tight_layout function, which will help you to make sure that the plots fit nicely in your figure. You ideally call it after you have plotted your data and customized your plot; So that’s right before you call plt.show() that you should use plt.tight_layout(). Additionally, you might also be interested to use subplots_adjust(), which allows you to manually set the width and height reserved for blank space between subplots, and also fix the left and right sides, and the top and bottom of the subplots. Showing, Saving And Closing Your Plot After you have done all the necessary customizations, you will want to show your plot because, as you will have noticed from working in the terminal, you just get to see that an object is made, but you never see the nice plot every time you make adjustments. In the first example of this tutorial, this was implicitly done; Do you remember? It’s this piece of code: # Prepare the data x = np.linspace(0, 10, 100) # Plot the data plt.plot(x, x, label=&#39;linear&#39;) # Add a legend plt.legend() # Show the plot plt.show() The line plt.show() says indeed that you want to see the plot. If you execute this line, you’ll see a window popping up. And you’ll see if it looks like what you had in your mind! But this is where your questions start. How can I save this image and if it’s not to your liking, can you clear the image so that you can start anew? The following short sections will cover these questions. How To Save A Plot To An Image File You can easily save a figure to, for example, a png file by making use of plt.savefig(). The only argument you need to pass to this function is the file name, just like in this example: # Prepare the data x = np.linspace(0, 10, 100) # Plot the data plt.plot(x, x, label=&#39;linear&#39;) # Add a legend plt.legend() # Save Figure plt.savefig(&quot;foo.png&quot;) # Prepare the data x = np.linspace(0, 10, 100) # Plot the data plt.plot(x, x, label=&#39;linear&#39;) # Add a legend plt.legend() # Save Transparent Figure plt.savefig(&quot;foo_transparent.png&quot;, transparent=True) How To Save A Plot To A Pdf File If you want to save multiple plots to a pdf file, you want to make use of the pdf backend, which you can easily import: # Import PdfPages from matplotlib.backends.backend_pdf import PdfPages # Prepare the data x = np.linspace(0, 10, 100) # Plot the data plt.plot(x, x, label=&#39;linear&#39;) # Add a legend plt.legend() # Initialize the pdf file pp = PdfPages(&#39;multipage.pdf&#39;) # Save the figure to the file pp.savefig() # Close the file pp.close() When To Use cla(), clf() or close()? When you’re finally ready with the inspection of your plot, it’s time to move on with something else (maybe with another plot!). When you’re working with this data visualization library for the first time, it might be weird at start because you can, of course, shut down the GUI window that appears, but that’s usually not the way you want to handle things, because it doesn’t always work as well when you’re working on several things at a time. You have to explicitly tell Matplotlib to close down the plot that you’ve been working on so that you can move on. There are three functions that will come in handy once you’re at this point: Use: plt.cla() to clear an axis plt.clf() to clear the entire figure plt.close() to close a window that has popped up to show you your plot Customizing Matplotlib By now, you’re already familiar with some basic options to customize your plots. But what if the customizations that you want to make situate more on a library level instead of a plot level? In such cases, also, you don’t need to panic: Matplotlib offers you several options to adjust some of the internal workings. This section will just cover two options, namely style sheets and rc settings. If you want to know more, definitely check out this page. How To Use A ggplot2 Style For the R enthusiasts among you, Matplotlib also offers you the option to set the style of the plots to ggplot. You can easily do this by running the following piece of code: # Set the style to `ggplot` plt.style.use(&quot;ggplot&quot;) rc Settings “rc” is common for configuration files: they usually end in rc. It comes from the practice of having configs as executables: they are automatically run and configure settings, for example. You can read more about it here. Matplotlib has such an rc file to which you can make adjustments dynamically and statically. To dynamically change default rc settings, you can use the rcParams variable: # without rc Settings # Prepare the data x = np.linspace(0, 10, 100) # Plot the data plt.plot(x, x, label=&#39;linear&#39;) # Add a legend plt.legend() # Show the plot plt.show() # with rc Settings import matplotlib as mpl mpl.rcParams[&#39;lines.linewidth&#39;] = 5 # Prepare the data x = np.linspace(0, 10, 100) # Plot the data plt.plot(x, x, label=&#39;linear&#39;) # Add a legend plt.legend() # Show the plot plt.show() You just adjusted the line width in the example above, but you can also change figure size and dpi, line width, color and style, axes, axis and grid properties, text and font properties, … If you want to work more statically, you should probably also know that you have a matplotlibrc configuration file, which you can use to customize all kinds of properties (just like you did above with the line width parameter). If you want to find this specific file, you can just run the following: import matplotlib matplotlib.matplotlib_fname() &#39;/Users/kolobj/.matplotlib/matplotlibrc&#39; Continue Learning Congratulations! You have gone through today’s Matplotlib tutorial successfully! There is still much to learn, but you’re definitely ready to go out on your own and create your own amazing plots. Don’t miss out on DataCamp’s Matplotlib cheat sheet that can help you to make plots in no time, step by step. If you’re eager to discover more from Matplotlib, consider checking out DataCamp’s Viewing 3D Volumetric Data With Matplotlib tutorial to learn how to work with matplotlib’s event handler API or this tutorial, in which you’ll learn all about animating your plots.",
    "url": "http://localhost:4000/lectures/Week%2004%20-%20Numpy,%20Pandas,%20Graphing%20&%20Visualization/03%20-%20Matplotlib%20Tutorial%20Python%20Plotting.html",
    "relUrl": "/lectures/Week%2004%20-%20Numpy,%20Pandas,%20Graphing%20&%20Visualization/03%20-%20Matplotlib%20Tutorial%20Python%20Plotting.html"
  },
  "25": {
    "id": "25",
    "title": "03 - Pandas Introduction",
    "content": "Pandas Tutorial: DataFrames in Python Source Explore data analysis with Python. Pandas DataFrames make manipulating your data easy, from selecting or replacing columns and indices to reshaping your data. Pandas is a popular Python package for data science, and with good reason: it offers powerful, expressive and flexible data structures that make data manipulation and analysis easy, among many other things. The DataFrame is one of these structures. This tutorial covers Pandas DataFrames, from basic manipulations to advanced operations, by tackling 11 of the most popular questions so that you understand -and avoid- the doubts of the Pythonistas who have gone before you. Content How To Create a Pandas DataFrame How To Select an Index or Column From a DataFrame How To Add an Index, Row or Column to a DataFrame How To Delete Indices, Rows or Columns From a DataFrame How To Rename the Columns or Indices of a DataFrame How To Format the Data in Your DataFrame How To Create an Empty DataFrame Does Pandas Recognize Dates When Importing Data? When, Why and How You Should Reshape Your DataFrame How To Iterate Over a DataFrame How To Write a DataFrame to a File What Are Pandas Data Frames? Before you start, let’s have a brief recap of what DataFrames are. Those who are familiar with R know the data frame as a way to store data in rectangular grids that can easily be overviewed. Each row of these grids corresponds to measurements or values of an instance, while each column is a vector containing data for a specific variable. This means that a data frame’s rows do not need to contain, but can contain, the same type of values: they can be numeric, character, logical, etc. Now, DataFrames in Python are very similar: they come with the Pandas library, and they are defined as a two-dimensional labeled data structures with columns of potentially different types. In general, you could say that the Pandas DataFrame consists of three main components: the data, the index, and the columns. Firstly, the DataFrame can contain data that is: a Pandas DataFrame a Pandas Series: a one-dimensional labeled array capable of holding any data type with axis labels or index. An example of a Series object is one column from a DataFrame. a NumPy ndarray, which can be a record or structured a two-dimensional ndarray dictionaries of one-dimensional ndarray’s, list’s, dictionarie’s or Series. Note the difference between np.ndarray and np.array(). The former is an actual data type, while the latter is a function to make arrays from other data structures. Structured arrays allow users to manipulate the data by named fields: in the example below, a structured array of three tuples is created. The first element of each tuple will be called foo and will be of type int, while the second element will be named bar and will be a float. import numpy as np import pandas as pd # A structured array my_array = np.ones(3, dtype=([(&#39;foo&#39;, int), (&#39;bar&#39;, float)])) # Print the structured array print(type(my_array[&#39;foo&#39;]), my_array[&#39;foo&#39;]) &lt;class &#39;numpy.ndarray&#39;&gt; [1 1 1] Record arrays, on the other hand, expand the properties of structured arrays. They allow users to access fields of structured arrays by attribute rather than by index. You see below that the foo values are accessed in the r2 record array. # A record array my_array2 = my_array.view(np.recarray) # Print the record array print(type(my_array2.foo), my_array2.foo) &lt;class &#39;numpy.ndarray&#39;&gt; [1 1 1] Besides data, you can also specify the index and column names for your DataFrame. The index, on the one hand, indicates the difference in rows, while the column names indicate the difference in columns. You will see later that these two components of the DataFrame will come in handy when you’re manipulating your data. Note that in this post, most of the times, the libraries that you need have already been loaded in. The Pandas library is usually imported under the alias pd, while the NumPy library is loaded as np. Remember that when you code in your own data science environment, you shouldn’t forget this import step, which you write just like this: import numpy as np import pandas as pd 1. How To Create a Pandas DataFrame Obviously, making your DataFrames is your first step in almost anything that you want to do when it comes to data munging in Python. Sometimes, you will want to start from scratch, but you can also convert other data structures, such as lists or NumPy arrays, to Pandas DataFrames. In this section, you’ll will only cover the latter. Among the many things that can serve as input to make a DataFrame, a NumPy ndarray is one of them. To make a data frame from a NumPy array, you can just pass it to the DataFrame() function in the data argument. columns = [&#39;Col1&#39;, &#39;Col2&#39;] index = [&#39;Row1&#39;, &#39;Row2&#39;] data = [[1, 2], [3, 4]] df = pd.DataFrame(data=data, index=index, columns=columns) df Col1 Col2 Row1 1 2 Row2 3 4 data = np.array([[&#39;&#39;,&#39;Col1&#39;,&#39;Col2&#39;], [&#39;Row1&#39;,1,2], [&#39;Row2&#39;,3,4]]) df = pd.DataFrame(data=data[1:,1:], index=data[1:,0], columns=data[0,1:]) df Col1 Col2 Row1 1 2 Row2 3 4 Pay attention to how the code chunks above select elements from the NumPy array to construct the DataFrame: you first select the values that are contained in the lists that start with Row1 and Row2 then you select the index or row numbers Row1 and Row2 and then the column names Col1 and Col2 Next, you also see that, in the chunk above, you printed out a small selection of the data. This works the same as subsetting 2D NumPy arrays: you first indicate the row that you want to look in for your data, then the column. Don’t forget that the indices start at 0! For data in the example above, you go and look in the rows at index 1 to end and you select all elements that come after index 1. As a result, you end up selecting 1, 2, 3 and 4. This approach to making DataFrames will be the same for all the structures that DataFrame() can take on as input. # Take a 2D array as input to your DataFrame my_2darray = np.array([[1, 2, 3], [4, 5, 6]]) print(my_2darray) [[1 2 3] [4 5 6]] # Take a dictionary as input to your DataFrame my_dict = { 1: [&#39;1&#39;, &#39;3&#39;], 2: [&#39;1&#39;, &#39;2&#39;], 3: [&#39;2&#39;, &#39;4&#39;]} my_df = pd.DataFrame(my_dict) my_df 1 2 3 0 1 1 2 1 3 2 4 # Take a DataFrame as input to your DataFrame my_df = pd.DataFrame( data=[4,5,6,7], index=range(0,4), columns=[&#39;A&#39;]) my_df A 0 4 1 5 2 6 3 7 # Take a Series as input to your DataFrame my_series = pd.Series({ &quot;Belgium&quot;:&quot;Brussels&quot;, &quot;India&quot;:&quot;New Delhi&quot;, &quot;United Kingdom&quot;:&quot;London&quot;, &quot;United States&quot;:&quot;Washington&quot;}) my_series Belgium Brussels India New Delhi United Kingdom London United States Washington dtype: object Note that the index of your Series (and DataFrame) contains the keys of the original dictionary, but that they are sorted: Belgium will be the index at 0, while United States will be the index at 3. After you have created your DataFrame, you might want to know a little bit more about it. You can use the shape property or the len() function in combination with the .index property: df = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6]])) # Use the `shape` property print(df.shape) (2, 3) # Or use the `len()` function with the `index` property print(len(df.index)) 2 These two options give you slightly different information on your DataFrame: the shape property will give you the dimensions of your DataFrame. That means that you will get to know the width and the height of your DataFrame. the len() function, in combination with the index property, will only give you information on the height of your DataFrame. This all is totally not extraordinary, though, as you explicitly give in the index property. You could also use df[0].count() to get to know more about the height of your DataFrame, but this will exclude the NaN values (if there are any). That is why calling .count()`` on your DataFrame is not always the better option. If you want more information on your DataFrame columns, you can always execute list(df.columns.values). list(df.columns.values) [0, 1, 2] 2. How To Select an Index or Column From a Pandas DataFrame Before you start with adding, deleting and renaming the components of your DataFrame, you first need to know how you can select these elements. So, how do you do this? Even though you might still remember how to do it from the previous section: selecting an index, column or value from your DataFrame isn’t that hard, quite the contrary. It’s similar to what you see in other languages (or packages!) that are used for data analysis. If you aren’t convinced, consider the following: In R, you use the [,] notation to access the data frame’s values. Now, let’s say you have a DataFrame like this one def create_df(): vals = [[1, 4, 7], [2, 5, 8], [3, 6, 9]] d = { k:v for (k, v) in zip(&#39;ABC&#39;, vals)} df = pd.DataFrame(d) return df df = create_df() df A B C 0 1 2 3 1 4 5 6 2 7 8 9 And you want to access the value that is at index 0, in column ‘A’. There are various options that exist to get your value 1 back: # Using `iloc[]` print(df.iloc[0][0]) # Using `loc[]` print(df.loc[0][&#39;A&#39;]) # Using `at[]` print(df.at[0,&#39;A&#39;]) # Using `iat[]` print(df.iat[0,0]) 1 1 1 1 The most important ones to remember are, without a doubt, .loc[] and .iloc[]. The subtle differences between these two will be discussed in the next sections. Enough for now about selecting values from your DataFrame. What about selecting rows and columns? In that case, you would use: # Use `iloc[]` to select row `0` print(df.iloc[0]) A 1 B 2 C 3 Name: 0, dtype: int64 # Use `loc[]` to select column `&#39;A&#39;` print(df.loc[:,&#39;A&#39;]) 0 1 1 4 2 7 Name: A, dtype: int64 For now, it’s enough to know that you can either access the values by calling them by their label or by their position in the index or column. If you don’t see this, look again at the slight differences in the commands: one time, you see [0][0], the other time, you see [0,&#39;A&#39;] to retrieve your value 1. 3. How To Add an Index, Row or Column to a Pandas DataFrame Now that you have learned how to select a value from a DataFrame, it’s time to get to the real work and add an index, row or column to it! Adding an Index to a DataFrame When you create a DataFrame, you have the option to add input to the index argument to make sure that you have the index that you desire. When you don’t specify this, your DataFrame will have, by default, a numerically valued index that starts with 0 and continues until the last row of your DataFrame. However, even when your index is specified for you automatically, you still have the power to re-use one of your columns and make it your index. You can easily do this by calling set_index() on your DataFrame. # Print out your DataFrame `df` to check it out df A B C 0 1 2 3 1 4 5 6 2 7 8 9 # Set &#39;C&#39; as the index of your DataFrame df.set_index(&#39;C&#39;) A B C 3 1 2 6 4 5 9 7 8 Adding Rows to a DataFrame Before you can get to the solution, it’s first a good idea to grasp the concept of loc and how it differs from other indexing attributes such as .iloc[] and .ix[]: .loc[] works on labels of your index. This means that if you give in loc[2], you look for the values of your DataFrame that have an index labeled 2. .iloc[] works on the positions in your index. This means that if you give in iloc[2], you look for the values of your DataFrame that are at index ’2`. .ix[] is a more complex case: when the index is integer-based, you pass a label to .ix[] .ix[2] then means that you’re looking in your DataFrame for values that have an index labeled 2. This is just like .loc[]! However, if your index is not solely integer-based, ix will work with positions, just like .iloc[]. This all might seem very complicated. Let’s illustrate all of this with a small example: df = pd.DataFrame(data=np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), index=[2, &#39;A&#39;, 4], columns=[48, 49, 50]) df 48 49 50 2 1 2 3 A 4 5 6 4 7 8 9 # Pass `2` to `loc` df.loc[2] 48 1 49 2 50 3 Name: 2, dtype: int64 # Pass `2` to `iloc` print(df.iloc[2]) 48 7 49 8 50 9 Name: 4, dtype: int64 # Pass `2` to `ix` print(df.ix[2]) 48 7 49 8 50 9 Name: 4, dtype: int64 /Users/kolobj/anaconda/envs/cmu3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: .ix is deprecated. Please use .loc for label based indexing or .iloc for positional indexing See the documentation here: http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated Note that in this case you used an example of a DataFrame that is not solely integer-based as to make it easier for you to understand the differences. You clearly see that passing 2 to .loc[] or .iloc[]/.ix[] does not give back the same result! You know that .loc[] will go and look at the values that are at label 2. The result that you get back, will be 48 1 49 2 50 3 You also know that .iloc[] will go and look at the positions in the index. When you pass 2, you will get back: 48 7 49 8 50 9 Since the index doesn’t only contain integers, .ix[] will have the same behavior as iloc and look at the positions in the index. You will get back the same result as .iloc[]. Now that the difference between .iloc[], .loc[] and .ix[] is clear, you are ready to give adding rows to your DataFrame a go! Tip: as a consequence of what you have just read, you understand now also that the general recommendation is that you use .loc to insert rows in your DataFrame. That is because if you would use df.ix[], you might try to reference a numerically valued index with the index value and accidentally overwrite an existing row of your DataFrame. You better avoid this! Check out the difference once more in the DataFrame below: df = pd.DataFrame(data=np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), index= [2.5, 12.6, 4.8], columns=[48, 49, 50]) # There&#39;s no index labeled `2`, so you will change the index at position `2` df.ix[2] = [60, 50, 40] print(df) 48 49 50 2.5 1 2 3 12.6 4 5 6 4.8 60 50 40 /Users/kolobj/anaconda/envs/cmu3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: .ix is deprecated. Please use .loc for label based indexing or .iloc for positional indexing See the documentation here: http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated # This will make an index labeled `2` and add the new values df.loc[2] = [11, 12, 13] print(df) 48 49 50 2.5 1 2 3 12.6 4 5 6 4.8 60 50 40 2.0 11 12 13 Adding a Column to Your DataFrame In some cases, you want to make your index part of your DataFrame. You can easily do this by taking a column from your DataFrame or by referring to a column that you haven’t made yet and assigning it to the .index property, just like this: df = pd.DataFrame(data=np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;]) df A B C 0 1 2 3 1 4 5 6 2 7 8 9 # Use `.index` df[&#39;D&#39;] = df.index # Print `df` print(df) A B C D 0 1 2 3 0 1 4 5 6 1 2 7 8 9 2 In other words, you tell your DataFrame that it should take column A as its index. However, if you want to append columns to your DataFrame, you could also follow the same approach as when you would add an index to your DataFrame: you use .loc[] or .iloc[]. In this case, you add a Series to an existing DataFrame with the help of .loc[]: # Study the DataFrame `df` df A B C D 0 1 2 3 0 1 4 5 6 1 2 7 8 9 2 # Append a column to `df` df.loc[:, &#39;E&#39;] = pd.Series([&#39;5&#39;, &#39;6&#39;, &#39;7&#39;], index=df.index) # Print out `df` again to see the changes df A B C D E 0 1 2 3 0 5 1 4 5 6 1 6 2 7 8 9 2 7 Remember a Series object is much like a column of a DataFrame; That explains why you can easily add a Series to an existing DataFrame. Note also that the observation that was made earlier about .loc[] still stays valid, also when you’re adding columns to your DataFrame! Resetting the Index of Your DataFrame When your index doesn’t look entirely the way you want it to, you can opt to reset it. You can easily do this with .reset_index(). However, you should still watch out, as you can pass several arguments that can make or break the success of your reset: # Check out the weird index of your dataframe df = df.set_index(&#39;C&#39;) df A B D E C 3 1 2 0 5 6 4 5 1 6 9 7 8 2 7 # Use `reset_index()` to reset the values. df = df.reset_index(level=0, drop=True) df A B D E 0 1 2 0 5 1 4 5 1 6 2 7 8 2 7 4. How to Delete Indices, Rows or Columns From a Pandas Data Frame Now that you have seen how to select and add indices, rows, and columns to your DataFrame, it’s time to consider another use case: removing these three from your data structure. Deleting an Index from Your DataFrame If you want to remove the index from your DataFrame, you should reconsider because DataFrames and Series always have an index. However, what you can do is, for example: resetting the index of your DataFrame (go back to the previous section to see how it is done) remove the index name, if there is any, by executing del df.index.name remove duplicate index values by resetting the index, dropping the duplicates of the index column that has been added to your DataFrame and reinstating that duplicateless column again as the index: df = pd.DataFrame(data=np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [40, 50, 60], [23, 35, 37]]), index= [2.5, 12.6, 4.8, 4.8, 2.5], columns=[48, 49, 50]) print(df) 48 49 50 2.5 1 2 3 12.6 4 5 6 4.8 7 8 9 4.8 40 50 60 2.5 23 35 37 x = df.reset_index().drop_duplicates(subset=&#39;index&#39;, keep=&#39;last&#39;).set_index(&#39;index&#39;) print(x) 48 49 50 index 12.6 4 5 6 4.8 40 50 60 2.5 23 35 37 Deleting a Column from Your DataFrame To get rid of (a selection of) columns from your DataFrame, you can use the drop() method: # Check out the DataFrame `df` df = create_df() print(df) A B C 0 1 2 3 1 4 5 6 2 7 8 9 # Drop the column with label &#39;A&#39; df.drop(&#39;A&#39;, axis=1, inplace=True) print(df) B C 0 2 3 1 5 6 2 8 9 # Drop the column at position 1 df.drop(df.columns[[1]], axis=1) print(df) B C 0 2 3 1 5 6 2 8 9 You might think now: well, this is not so straightforward; There are some extra arguments that are passed to the drop() method! The axis argument is either 0 when it indicates rows and 1 when it is used to drop columns. You can set inplace to True to delete the column without having to reassign the DataFrame. Removing a Row from Your DataFrame You can remove duplicate rows from your DataFrame by executing df.drop_duplicates(). You can also remove rows from your DataFrame, taking into account only the duplicate values that exist in one column. # Check out your DataFrame `df` df = create_df() df = df.append({ &#39;A&#39;: 1, &#39;B&#39;: 2, &#39;C&#39;: 3}, ignore_index=True) print(df) A B C 0 1 2 3 1 4 5 6 2 7 8 9 3 1 2 3 # Drop the duplicates in `df` x = df.drop_duplicates(subset=&#39;A&#39;, keep=&#39;last&#39;) print(x) A B C 1 4 5 6 2 7 8 9 3 1 2 3",
    "url": "http://localhost:4000/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth/03%20-%20Pandas%20Introduction.html",
    "relUrl": "/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth/03%20-%20Pandas%20Introduction.html"
  },
  "26": {
    "id": "26",
    "title": "03 - Sets and Set Comprehensions",
    "content": "Sets and Set Comprehensions Python Sets Set Comprehensions Perhaps you recall learning about sets and set theory at some point in your mathematical education. Maybe you even remember Venn diagrams: In mathematics, a rigorous definition of a set can be abstract and difficult to grasp. Practically though, a set can be thought of simply as a well-defined collection of distinct objects, typically called elements or members. Grouping objects into a set can be useful in programming as well, and Python provides a built-in set type to do so. Sets are distinguished from other object types by the unique operations that can be performed on them. Here’s what you’ll learn in this tutorial: You’ll see how to define set objects in Python and discover the operations that they support. You’ll also learn about frozen sets, which are similar to sets except for one important detail. Defining a Set Python’s built-in set type has the following characteristics: Sets are unordered. Set elements are unique. Duplicate elements are not allowed. A set itself may be modified, but the elements contained in the set must be of an immutable type. A set can be created in two ways. First, you can define a set with the built-in set() function: x = set(&lt;iter&gt;) x = set([&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;, &#39;qux&#39;]) print(x) {&#39;foo&#39;, &#39;baz&#39;, &#39;qux&#39;, &#39;bar&#39;} y = set((&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;, &#39;qux&#39;)) print(y) {&#39;foo&#39;, &#39;baz&#39;, &#39;qux&#39;, &#39;bar&#39;} z = set() print(type(z), z) &lt;class &#39;set&#39;&gt; set() Strings are also iterable, so a string can be passed to set() as well. You have already seen that list(s) generates a list of the characters in the string s. Similarly, set(s) generates a set of the characters in s: s = &#39;data focused python&#39; print(s) data focused python print(list(s)) [&#39;d&#39;, &#39;a&#39;, &#39;t&#39;, &#39;a&#39;, &#39; &#39;, &#39;f&#39;, &#39;o&#39;, &#39;c&#39;, &#39;u&#39;, &#39;s&#39;, &#39;e&#39;, &#39;d&#39;, &#39; &#39;, &#39;p&#39;, &#39;y&#39;, &#39;t&#39;, &#39;h&#39;, &#39;o&#39;, &#39;n&#39;] print(set(s)) {&#39;o&#39;, &#39;p&#39;, &#39;u&#39;, &#39;e&#39;, &#39;h&#39;, &#39;f&#39;, &#39;d&#39;, &#39;n&#39;, &#39;y&#39;, &#39;c&#39;, &#39;t&#39;, &#39;s&#39;, &#39;a&#39;, &#39; &#39;} s = &#39;data focused python is cool because we learn python and work with data&#39; words = s.split(&#39; &#39;) print(words) print(set(words)) [&#39;data&#39;, &#39;focused&#39;, &#39;python&#39;, &#39;is&#39;, &#39;cool&#39;, &#39;because&#39;, &#39;we&#39;, &#39;learn&#39;, &#39;python&#39;, &#39;and&#39;, &#39;work&#39;, &#39;with&#39;, &#39;data&#39;] {&#39;we&#39;, &#39;is&#39;, &#39;with&#39;, &#39;and&#39;, &#39;learn&#39;, &#39;cool&#39;, &#39;python&#39;, &#39;because&#39;, &#39;work&#39;, &#39;data&#39;, &#39;focused&#39;} You can see that the resulting sets are unordered: the original order, as specified in the definition, is not necessarily preserved. Additionally, duplicate values are only represented in the set once, as with the string ‘foo’ in the first two examples and the letter ‘u’ in the third. Alternately, a set can be defined with curly braces ({}): x = {&lt;obj&gt;, &lt;obj&gt;, ..., &lt;obj&gt;} When a set is defined this way, each becomes a distinct element of the set, even if it is an iterable. This behavior is similar to that of the .append() list method. Thus, the sets shown above can also be defined like this: x = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;, &#39;qux&#39;} print(type(x), x) &lt;class &#39;set&#39;&gt; {&#39;foo&#39;, &#39;baz&#39;, &#39;qux&#39;, &#39;bar&#39;} y = {&#39;q&#39;, &#39;u&#39;, &#39;u&#39;, &#39;x&#39;} print(type(y), y) &lt;class &#39;set&#39;&gt; {&#39;x&#39;, &#39;u&#39;, &#39;q&#39;} To recap: The argument to set() is an iterable. It generates a list of elements to be placed into the set. The objects in curly braces are placed into the set intact, even if they are iterable. Observe the difference between these two set definitions: x = {&#39;foo&#39;} print(type(x), x) &lt;class &#39;set&#39;&gt; {&#39;foo&#39;} y = set(&#39;foo&#39;) print(type(y), y) &lt;class &#39;set&#39;&gt; {&#39;o&#39;, &#39;f&#39;} A set can be empty. However, recall that Python interprets empty curly braces ({}) as an empty dictionary, so the only way to define an empty set is with the set() function: x = {} print(type(x)) &lt;class &#39;dict&#39;&gt; y = set() print(type(y)) &lt;class &#39;set&#39;&gt; An empty set is falsy in Boolean context: x = set() bool(x) False x or 1 1 x and 1 set() You might think the most intuitive sets would contain similar objects—for example, even numbers or surnames: s1 = {2, 4, 6, 8, 10} s2 = {&#39;Smith&#39;, &#39;McArthur&#39;, &#39;Wilson&#39;, &#39;Johansson&#39;} Python does not require this, though. The elements in a set can be objects of different types: x = {42, &#39;foo&#39;, 3.14159, None} print(x) {&#39;foo&#39;, 42, 3.14159, None} Don’t forget that set elements must be immutable. For example, a tuple may be included in a set: x = {42, &#39;foo&#39;, (1, 2, 3), 3.14159} print(x) {&#39;foo&#39;, 42, 3.14159, (1, 2, 3)} But lists and dictionaries are mutable, so they can’t be set elements: a = [1, 2, 3] x = {a} TypeError Traceback (most recent call last) &lt;ipython-input-34-0c2e2fff221a&gt; in &lt;module&gt; 1 a = [1, 2, 3] -&gt; 2 x = {a} TypeError: unhashable type: &#39;list&#39; Set Size and Membership x = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} len(x) 3 &#39;bar&#39; in x True &#39;qux&#39; in x False Operating on a Set Many of the operations that can be used for Python’s other composite data types don’t make sense for sets. For example, sets can’t be indexed or sliced. However, Python provides a whole host of operations on set objects that generally mimic the operations that are defined for mathematical sets. Operators vs. Methods Most, though not quite all, set operations in Python can be performed in two different ways: by operator or by method. Let’s take a look at how these operators and methods work, using set union as an example. Given two sets, x1 and x2, the union of x1 and x2 is a set consisting of all elements in either set. Consider these two sets: x1 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} x2 = {&#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;} The union of x1 and x2 is {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;}. In Python, set union can be performed with the | operator: union_x = x1 | x2 print(union_x) {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;} # note : there aren&#39;t any duplicates print(len(union_x), len(x1), len(x2)) 5 3 3 Set union can also be obtained with the .union() method. The method is invoked on one of the sets, and the other is passed as an argument: x1.union(x2) {&#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;, &#39;quux&#39;, &#39;qux&#39;} The way they are used in the examples above, the operator and method behave identically. But there is a subtle difference between them. When you use the operator, both operands must be sets. The .union() method, on the other hand, will take any iterable as an argument, convert it to a set, and then perform the union. Observe the difference between these two statements: x1 | (&#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;) TypeError Traceback (most recent call last) &lt;ipython-input-44-d83d33f7fbad&gt; in &lt;module&gt; -&gt; 1 x1 | (&#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;) TypeError: unsupported operand type(s) for |: &#39;set&#39; and &#39;tuple&#39; x1.union((&#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;)) {&#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;, &#39;quux&#39;, &#39;qux&#39;} Available Operators and Methods Below is a list of the set operations available in Python. Some are performed by operator, some by method, and some by both. The principle outlined above generally applies: where a set is expected, methods will typically accept any iterable as an argument, but operators require actual sets as operands. Union x1 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} x2 = {&#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;} print(x1.union(x2)) print(x1 | x2) {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;} {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;} More than two sets may be specified with either the operator or the method: a = {1, 2, 3, 4} b = {2, 3, 4, 5} c = {3, 4, 5, 6} d = {4, 5, 6, 7} print(a.union(b, c, d)) print(a | b | c | d) {1, 2, 3, 4, 5, 6, 7} {1, 2, 3, 4, 5, 6, 7} Intersection x1 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} x2 = {&#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;} print(x1.intersection(x2)) print(x1 &amp; x2) {&#39;baz&#39;} {&#39;baz&#39;} You can specify multiple sets with the intersection method and operator, just like you can with set union: a = {1, 2, 3, 4} b = {2, 3, 4, 5} c = {3, 4, 5, 6} d = {4, 5, 6, 7} print(a.intersection(b, c, d)) print(a &amp; b &amp; c &amp; d) {4} {4} Difference x1 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} x2 = {&#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;} print(x1.difference(x2)) print(x1 - x2) {&#39;foo&#39;, &#39;bar&#39;} {&#39;foo&#39;, &#39;bar&#39;} Once again, you can specify more than two sets: a = {1, 2, 3, 30, 300} b = {10, 20, 30, 40} c = {100, 200, 300, 400} print(a.difference(b, c)) print(a - b - c) {1, 2, 3} {1, 2, 3} When multiple sets are specified, the operation is performed from left to right. In the example above, a - b is computed first, resulting in {1, 2, 3, 300}. Then c is subtracted from that set, leaving {1, 2, 3}: Symmetric Difference x1 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} x2 = {&#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;} print(x1.symmetric_difference(x2)) print(x1 ^ x2) {&#39;foo&#39;, &#39;bar&#39;, &#39;qux&#39;, &#39;quux&#39;} {&#39;foo&#39;, &#39;bar&#39;, &#39;qux&#39;, &#39;quux&#39;} The ^ operator also allows more than two sets: a = {1, 2, 3, 4, 5} b = {10, 2, 3, 4, 50} c = {1, 50, 100} print(a ^ b ^ c) {10, 100, 5} Disjoint Determines whether or not two sets have any elements in common. x1.isdisjoint(x2) returns True if x1 and x2 have no elements in common: x1 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} x2 = {&#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;} print(x1.isdisjoint(x2)) False x3 = x2 - {&#39;baz&#39;} print(x1.isdisjoint(x3)) True If x1.isdisjoint(x2) is True, then x1 &amp; x2 is the empty set: x1 = {1, 3, 5} x2 = {2, 4, 6} print(x1.isdisjoint(x2)) True print(x1 &amp; x2) set() Is Subset Determine whether one set is a subset of the other. In set theory, a set x1 is considered a subset of another set x2 if every element of x1 is in x2. x1.issubset(x2) and x1 &lt;= x2 return True if x1 is a subset of x2: x1 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} print(x1.issubset({&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;})) True x2 = {&#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;} print(x1 &lt;= x2) False Is Proper Subset A proper subset is the same as a subset, except that the sets can’t be identical. A set x1 is considered a proper subset of another set x2 if every element of x1 is in x2, and x1 and x2 are not equal. x1 = {&#39;foo&#39;, &#39;bar&#39;} x2 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} print(x1 &lt; x2) True x1 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} x2 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} print(x1 &lt; x2) False Is Superset A superset is the reverse of a subset. A set x1 is considered a superset of another set x2 if x1 contains every element of x2. x1.issuperset(x2) and x1 &gt;= x2 return True if x1 is a superset of x2: x1 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} print(x1.issuperset({&#39;foo&#39;, &#39;bar&#39;})) True x2 = {&#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;} print(x1 &gt;= x2) False Is Proper Superset A proper superset is the same as a superset, except that the sets can’t be identical. A set x1 is considered a proper superset of another set x2 if x1 contains every element of x2, and x1 and x2 are not equal. x1 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} x2 = {&#39;foo&#39;, &#39;bar&#39;} print(x1 &gt; x2) True x1 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} x2 = {&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;} print(x1 &gt; x2) False Frozen Sets Python provides another built-in type called a frozenset, which is in all respects exactly like a set, except that a frozenset is immutable. You can perform non-modifying operations on a frozenset: x = frozenset([&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;]) print(x) frozenset({&#39;foo&#39;, &#39;baz&#39;, &#39;bar&#39;}) print(len(x)) 3 print(x &amp; {&#39;baz&#39;, &#39;qux&#39;, &#39;quux&#39;}) frozenset({&#39;baz&#39;}) But methods that attempt to modify a frozenset fail: x.add(&#39;quux&#39;) AttributeError Traceback (most recent call last) &lt;ipython-input-70-b02648b33e59&gt; in &lt;module&gt; -&gt; 1 x.add(&#39;quux&#39;) AttributeError: &#39;frozenset&#39; object has no attribute &#39;add&#39; Set Comprehension import random from random import randint seed = 1234 random.seed(seed) x = 0 y = 5 a = [randint(x, y) for i in range(0, 10)] print(a) [3, 0, 0, 0, 4, 0, 5, 5, 0, 0] random.seed(seed) x = 0 y = 5 b = {randint(x, y) for i in range(0, 10)} print(b) {0, 3, 4, 5} random.seed(seed) a = [&#39;Even&#39; if i % 2 else &#39;Odd&#39; for i in range(10)] print(a) [&#39;Odd&#39;, &#39;Even&#39;, &#39;Odd&#39;, &#39;Even&#39;, &#39;Odd&#39;, &#39;Even&#39;, &#39;Odd&#39;, &#39;Even&#39;, &#39;Odd&#39;, &#39;Even&#39;] random.seed(seed) b = {&#39;Even&#39; if i % 2 else &#39;Odd&#39; for i in range(10)} print(b) {&#39;Odd&#39;, &#39;Even&#39;}",
    "url": "http://localhost:4000/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/03%20-%20Sets%20and%20Set%20Comprehensions.html",
    "relUrl": "/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/03%20-%20Sets%20and%20Set%20Comprehensions.html"
  },
  "27": {
    "id": "27",
    "title": "03 - Using fhirclient to parse Healthcare Data",
    "content": "fhirclient Note: this example uses FHIR DSTU3 whereas synthea now supports FHIR R4 so you’ll need a different version of the fhirclient library to deal with each dataset The fhirclient, a flexible Python client for FHIR servers supporting the SMART on FHIR protocol. fhirclient versioning is not identical to FHIR versioning, see the full table for reference. Version FHIR   4.0.0 4.0.0 (R4) 3.0.0 3.0.0 (STU-3) 1.0.3 1.0.2 (DSTU 2) 1.0 1.0.1 (DSTU 2) Installation pip install fhirclient or pip install git+https://github.com/smart-on-fhir/client-py.git NOTE: We’ll use FHIR R4 here so you need to install from GitHub Documentation Technical documentation is available at docs. Client Use To connect to a SMART on FHIR server (or any open FHIR server), you can use the FHIRClient class. It will initialize and handle a FHIRServer instance, your actual handle to the FHIR server you’d like to access. Read Data from Server To read a given patient from an open FHIR server, you can use: from pprint import pprint from fhirclient import client settings = { &#39;app_id&#39;: &#39;my_web_app&#39;, &#39;api_base&#39;: &#39;http://hapi.fhir.org/baseR4&#39; } smart = client.FHIRClient(settings=settings) import fhirclient.models.patient as p patient = p.Patient.read(&#39;38&#39;, smart.server) print(patient.birthDate.isostring) print(smart.human_name(patient.name[0])) 1980-01-01 Luc Sky If this is a protected server, you will first have to send your user to the authorize endpoint to log in. Call smart.authorize_url to obtain the correct URL. You can use smart.prepare(), which will return False if the server is protected and you need to authorize. The smart.ready property has the same purpose, it will however not retrieve the server’s CapabilityStatement resource and hence is only useful as a quick check whether the server instance is ready. smart = client.FHIRClient(settings=settings) smart.ready # prints False print(smart.prepare()) # prints True after fetching CapabilityStatement print(smart.ready) # prints True print(smart.prepare()) # prints True immediately print(smart.authorize_url) True True True None You can work with the FHIRServer class directly, without using FHIRClient, but this is not recommended: import fhirclient.server smart = fhirclient.server.FHIRServer(None, &#39;http://hapi.fhir.org/baseR4&#39;) import fhirclient.models.patient as p patient = p.Patient.read(&#39;38&#39;, smart) patient.name[0].given [&#39;Luc&#39;] Search Records on Server You can also search for resources matching a particular set of criteria: smart = client.FHIRClient(settings=settings) import fhirclient.models.observation as o search = o.Observation.where(struct={&#39;subject&#39;: &#39;Patient/38&#39;}) observations = search.perform_resources(smart.server) # print(observations) for observation in observations: pprint(observation.as_json()) {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;CRE(1)&#39;, &#39;display&#39;: &#39;CREATININE&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52391&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:28:34.475+00:00&#39;, &#39;source&#39;: &#39;#SWMQuDDsY0r4Ndbn&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 8}, &#39;low&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 6}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;K(1)&#39;, &#39;display&#39;: &#39;POTASSIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52390&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:28:34.187+00:00&#39;, &#39;source&#39;: &#39;#ZkPXDmdj9WQhpcPC&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 5.5}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 3.5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 4.1}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;NA(1)&#39;, &#39;display&#39;: &#39;SODIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52389&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:28:33.889+00:00&#39;, &#39;source&#39;: &#39;#SoUHor0kX69jDHko&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 146}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 132}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 139}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;N(1)&#39;, &#39;display&#39;: &#39;LEUCOCYTES&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52388&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:28:33.592+00:00&#39;, &#39;source&#39;: &#39;#fk9d4FaQW1DqbhDX&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 10}, &#39;low&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 4}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 5.65}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;CRE(1)&#39;, &#39;display&#39;: &#39;CREATININE&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52386&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:21:42.928+00:00&#39;, &#39;source&#39;: &#39;#9id3EEsARrddLcYd&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 8}, &#39;low&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 6}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;K(1)&#39;, &#39;display&#39;: &#39;POTASSIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52385&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:21:42.620+00:00&#39;, &#39;source&#39;: &#39;#bJudecLm5RyJJFLr&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 5.5}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 3.5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 4.1}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;NA(1)&#39;, &#39;display&#39;: &#39;SODIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52384&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:21:42.312+00:00&#39;, &#39;source&#39;: &#39;#1MsZwjff0Cn9GO1K&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 146}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 132}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 139}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;N(1)&#39;, &#39;display&#39;: &#39;LEUCOCYTES&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52383&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:21:42.017+00:00&#39;, &#39;source&#39;: &#39;#AOVr9w5iXmgJm5o2&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 10}, &#39;low&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 4}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 5.65}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;CRE(1)&#39;, &#39;display&#39;: &#39;CREATININE&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52381&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:17:01.440+00:00&#39;, &#39;source&#39;: &#39;#9rQCaKBqqCktrFWx&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 8}, &#39;low&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 6}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;K(1)&#39;, &#39;display&#39;: &#39;POTASSIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52380&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:17:01.128+00:00&#39;, &#39;source&#39;: &#39;#cRfk4V7g0yhVZ0pe&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 5.5}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 3.5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 4.1}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;NA(1)&#39;, &#39;display&#39;: &#39;SODIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52379&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:17:00.815+00:00&#39;, &#39;source&#39;: &#39;#R9fOeuj088bnsod9&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 146}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 132}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 139}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;N(1)&#39;, &#39;display&#39;: &#39;LEUCOCYTES&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52378&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:17:00.419+00:00&#39;, &#39;source&#39;: &#39;#UWnHDbhZAXLD0qEI&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 10}, &#39;low&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 4}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 5.65}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;K(1)&#39;, &#39;display&#39;: &#39;POTASSIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51286&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T14:31:19.040+00:00&#39;, &#39;source&#39;: &#39;#N4NvLWK09cvWPw7a&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 5.5}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 3.5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 4.1}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;NA(1)&#39;, &#39;display&#39;: &#39;SODIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51285&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T14:31:18.727+00:00&#39;, &#39;source&#39;: &#39;#oCkviKNqchwDSfP5&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 146}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 132}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 139}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;N(1)&#39;, &#39;display&#39;: &#39;LEUCOCYTES&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51284&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T14:31:18.398+00:00&#39;, &#39;source&#39;: &#39;#HNragNqo20ohjwIp&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 10}, &#39;low&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 4}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 5.65}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;CRE(1)&#39;, &#39;display&#39;: &#39;CREATININE&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51283&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T13:59:28.090+00:00&#39;, &#39;source&#39;: &#39;#Ga4BkHLzxi7Yykz6&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 8}, &#39;low&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 6}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;K(1)&#39;, &#39;display&#39;: &#39;POTASSIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51282&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T13:59:27.771+00:00&#39;, &#39;source&#39;: &#39;#qxl66ph5Ty5RJn4Q&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 5.5}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 3.5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 4.1}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;NA(1)&#39;, &#39;display&#39;: &#39;SODIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51281&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T13:59:27.463+00:00&#39;, &#39;source&#39;: &#39;#jZ9LFx51pXWzMIC9&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 146}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 132}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 139}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;N(1)&#39;, &#39;display&#39;: &#39;LEUCOCYTES&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51280&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T13:59:27.122+00:00&#39;, &#39;source&#39;: &#39;#doSGbTbIhYfSrE4d&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 10}, &#39;low&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 4}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 5.65}} {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;CRE(1)&#39;, &#39;display&#39;: &#39;CREATININE&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51279&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T13:57:12.698+00:00&#39;, &#39;source&#39;: &#39;#EErteiOsAusb5QXn&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 8}, &#39;low&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 6}} # to get the raw Bundle instead of resources only, you can use: bundle = search.perform(smart.server) pprint(bundle.as_json()) {&#39;entry&#39;: [{&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/52391&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;CRE(1)&#39;, &#39;display&#39;: &#39;CREATININE&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52391&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:28:34.475+00:00&#39;, &#39;source&#39;: &#39;#SWMQuDDsY0r4Ndbn&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 8}, &#39;low&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 6}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/52390&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;K(1)&#39;, &#39;display&#39;: &#39;POTASSIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52390&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:28:34.187+00:00&#39;, &#39;source&#39;: &#39;#ZkPXDmdj9WQhpcPC&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 5.5}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 3.5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 4.1}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/52389&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;NA(1)&#39;, &#39;display&#39;: &#39;SODIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52389&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:28:33.889+00:00&#39;, &#39;source&#39;: &#39;#SoUHor0kX69jDHko&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 146}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 132}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 139}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/52388&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;N(1)&#39;, &#39;display&#39;: &#39;LEUCOCYTES&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52388&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:28:33.592+00:00&#39;, &#39;source&#39;: &#39;#fk9d4FaQW1DqbhDX&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 10}, &#39;low&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 4}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 5.65}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/52386&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;CRE(1)&#39;, &#39;display&#39;: &#39;CREATININE&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52386&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:21:42.928+00:00&#39;, &#39;source&#39;: &#39;#9id3EEsARrddLcYd&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 8}, &#39;low&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 6}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/52385&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;K(1)&#39;, &#39;display&#39;: &#39;POTASSIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52385&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:21:42.620+00:00&#39;, &#39;source&#39;: &#39;#bJudecLm5RyJJFLr&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 5.5}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 3.5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 4.1}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/52384&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;NA(1)&#39;, &#39;display&#39;: &#39;SODIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52384&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:21:42.312+00:00&#39;, &#39;source&#39;: &#39;#1MsZwjff0Cn9GO1K&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 146}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 132}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 139}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/52383&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;N(1)&#39;, &#39;display&#39;: &#39;LEUCOCYTES&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52383&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:21:42.017+00:00&#39;, &#39;source&#39;: &#39;#AOVr9w5iXmgJm5o2&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 10}, &#39;low&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 4}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 5.65}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/52381&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;CRE(1)&#39;, &#39;display&#39;: &#39;CREATININE&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52381&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:17:01.440+00:00&#39;, &#39;source&#39;: &#39;#9rQCaKBqqCktrFWx&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 8}, &#39;low&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 6}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/52380&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;K(1)&#39;, &#39;display&#39;: &#39;POTASSIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52380&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:17:01.128+00:00&#39;, &#39;source&#39;: &#39;#cRfk4V7g0yhVZ0pe&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 5.5}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 3.5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 4.1}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/52379&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;NA(1)&#39;, &#39;display&#39;: &#39;SODIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52379&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:17:00.815+00:00&#39;, &#39;source&#39;: &#39;#R9fOeuj088bnsod9&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 146}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 132}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 139}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/52378&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;N(1)&#39;, &#39;display&#39;: &#39;LEUCOCYTES&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;52378&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-30T14:17:00.419+00:00&#39;, &#39;source&#39;: &#39;#UWnHDbhZAXLD0qEI&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/1141&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 10}, &#39;low&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 4}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 5.65}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/51286&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;K(1)&#39;, &#39;display&#39;: &#39;POTASSIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51286&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T14:31:19.040+00:00&#39;, &#39;source&#39;: &#39;#N4NvLWK09cvWPw7a&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 5.5}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 3.5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 4.1}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/51285&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;NA(1)&#39;, &#39;display&#39;: &#39;SODIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51285&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T14:31:18.727+00:00&#39;, &#39;source&#39;: &#39;#oCkviKNqchwDSfP5&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 146}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 132}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 139}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/51284&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;N(1)&#39;, &#39;display&#39;: &#39;LEUCOCYTES&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51284&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T14:31:18.398+00:00&#39;, &#39;source&#39;: &#39;#HNragNqo20ohjwIp&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 10}, &#39;low&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 4}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 5.65}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/51283&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;CRE(1)&#39;, &#39;display&#39;: &#39;CREATININE&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51283&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T13:59:28.090+00:00&#39;, &#39;source&#39;: &#39;#Ga4BkHLzxi7Yykz6&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 8}, &#39;low&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 6}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/51282&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;K(1)&#39;, &#39;display&#39;: &#39;POTASSIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51282&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T13:59:27.771+00:00&#39;, &#39;source&#39;: &#39;#qxl66ph5Ty5RJn4Q&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 5.5}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 3.5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 4.1}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/51281&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;NA(1)&#39;, &#39;display&#39;: &#39;SODIUM&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51281&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T13:59:27.463+00:00&#39;, &#39;source&#39;: &#39;#jZ9LFx51pXWzMIC9&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 146}, &#39;low&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 132}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mEq/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mEq/l&#39;, &#39;value&#39;: 139}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/51280&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;N(1)&#39;, &#39;display&#39;: &#39;LEUCOCYTES&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51280&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T13:59:27.122+00:00&#39;, &#39;source&#39;: &#39;#doSGbTbIhYfSrE4d&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 10}, &#39;low&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 4}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;G/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;G/l&#39;, &#39;value&#39;: 5.65}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}, {&#39;fullUrl&#39;: &#39;http://hapi.fhir.org/baseR4/Observation/51279&#39;, &#39;resource&#39;: {&#39;code&#39;: {&#39;coding&#39;: [{&#39;code&#39;: &#39;CRE(1)&#39;, &#39;display&#39;: &#39;CREATININE&#39;, &#39;system&#39;: &#39;http://loinc.org&#39;}]}, &#39;id&#39;: &#39;51279&#39;, &#39;interpretation&#39;: [{&#39;coding&#39;: [{&#39;code&#39;: &#39;N&#39;, &#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-ObservationInterpretation&#39;}]}], &#39;issued&#39;: &#39;2019-10-14&#39;, &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-10-27T13:57:12.698+00:00&#39;, &#39;source&#39;: &#39;#EErteiOsAusb5QXn&#39;, &#39;versionId&#39;: &#39;1&#39;}, &#39;performer&#39;: [{&#39;display&#39;: &#39;LESTEST ECLANCHER&#39;, &#39;reference&#39;: &#39;Practitioner/clinFhirbqsp1zJ4G6NmckaQKAWDeLpKRF73&#39;}], &#39;referenceRange&#39;: [{&#39;high&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 8}, &#39;low&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 5}}], &#39;resourceType&#39;: &#39;Observation&#39;, &#39;status&#39;: &#39;final&#39;, &#39;subject&#39;: {&#39;display&#39;: &#39;Sky Luc&#39;, &#39;reference&#39;: &#39;Patient/38&#39;}, &#39;valueQuantity&#39;: {&#39;code&#39;: &#39;mg/l&#39;, &#39;system&#39;: &#39;http://unitsofmeasure.org&#39;, &#39;unit&#39;: &#39;mg/l&#39;, &#39;value&#39;: 6}}, &#39;search&#39;: {&#39;mode&#39;: &#39;match&#39;}}], &#39;id&#39;: &#39;327cddc7-d99d-4219-b8f4-3dd782db66dd&#39;, &#39;link&#39;: [{&#39;relation&#39;: &#39;self&#39;, &#39;url&#39;: &#39;http://hapi.fhir.org/baseR4/Observation?subject=Patient%2F38&#39;}, {&#39;relation&#39;: &#39;next&#39;, &#39;url&#39;: &#39;http://hapi.fhir.org/baseR4?_getpages=327cddc7-d99d-4219-b8f4-3dd782db66dd&amp;_getpagesoffset=20&amp;_count=20&amp;_pretty=true&amp;_bundletype=searchset&#39;}], &#39;meta&#39;: {&#39;lastUpdated&#39;: &#39;2019-11-01T00:01:34.662+00:00&#39;}, &#39;resourceType&#39;: &#39;Bundle&#39;, &#39;total&#39;: 204, &#39;type&#39;: &#39;searchset&#39;} Data Model Use The client contains data model classes, built using fhir-parser, that handle (de)serialization and allow to work with FHIR data in a Pythonic way. Initialize Data Model import fhirclient.models.patient import fhirclient.models.humanname data = {&#39;id&#39;: &#39;patient-1&#39;} patient = fhirclient.models.patient.Patient(data) print(patient.id) patient-1 name = fhirclient.models.humanname.HumanName() name.given = [&#39;Peter&#39;] name.family = &#39;Parker&#39; patient.name = [name] pprint(patient.as_json()) {&#39;id&#39;: &#39;patient-1&#39;, &#39;name&#39;: [{&#39;family&#39;: &#39;Parker&#39;, &#39;given&#39;: [&#39;Peter&#39;]}], &#39;resourceType&#39;: &#39;Patient&#39;} name.given = &#39;Peter&#39; patient.as_json() # throws FHIRValidationError: because we incorrectly set the name to a string FHIRValidationError Traceback (most recent call last) &lt;ipython-input-19-814c163e63cc&gt; in &lt;module&gt; 1 name.given = &#39;Peter&#39; -&gt; 2 patient.as_json() # throws FHIRValidationError: because we incorrectly set the name to a string ~/anaconda/envs/cmu3/lib/python3.6/site-packages/fhirclient/models/fhirabstractresource.py in as_json(self) 40 41 def as_json(self): &gt; 42 js = super(FHIRAbstractResource, self).as_json() 43 js[&#39;resourceType&#39;] = self.resource_type 44 return js ~/anaconda/envs/cmu3/lib/python3.6/site-packages/fhirclient/models/fhirabstractbase.py in as_json(self) 295 296 if len(errs) &gt; 0: --&gt; 297 raise FHIRValidationError(errs) 298 return js 299 FHIRValidationError: {root}: name.0: given: Expecting property &quot;given&quot; on &lt;class &#39;fhirclient.models.humanname.HumanName&#39;&gt; to be list, but is &lt;class &#39;str&#39;&gt; Initialize from JSON file import json import fhirclient.models.patient with open(&#39;patient.json&#39;, &#39;r&#39;) as h: pjs = json.load(h) patient = fhirclient.models.patient.Patient(pjs) print(patient.name[0].family) print(patient.name[0].given[0]) print(patient.gender) print(patient.birthDate.isostring) Sky Luc male 1980-01-01 Using Requests only import requests response = requests.get(&quot;http://hapi.fhir.org/baseR4/Patient/38&quot;) response.status_code 200 data = json.loads(response.content.decode(&#39;utf-8&#39;)) data[&#39;name&#39;] [{&#39;family&#39;: &#39;Sky&#39;, &#39;given&#39;: [&#39;Luc&#39;]}] data[&#39;name&#39;][0][&#39;family&#39;] &#39;Sky&#39; data[&#39;name&#39;][0][&#39;given&#39;] [&#39;Luc&#39;] data[&#39;name&#39;][0][&#39;given&#39;][0] &#39;Luc&#39; response.text &#39;{ n &quot;resourceType&quot;: &quot;Patient&quot;, n &quot;id&quot;: &quot;38&quot;, n &quot;meta&quot;: { n &quot;versionId&quot;: &quot;32&quot;, n &quot;lastUpdated&quot;: &quot;2019-10-30T14:16:54.484+00:00&quot;, n &quot;source&quot;: &quot;#e0mm6ofqyX94cLL9&quot; n }, n &quot;text&quot;: { n &quot;status&quot;: &quot;generated&quot;, n &quot;div&quot;: &quot;&lt;div xmlns= &quot;http://www.w3.org/1999/xhtml &quot;&gt; &lt;div class= &quot;hapiHeaderText &quot;&gt;Hi &lt;b&gt;HELLO &lt;/b&gt; &lt;/div&gt; &lt;table class= &quot;hapiPropertyTable &quot;&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Identifier&lt;/td&gt; &lt;td&gt;NCC-7676&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Address&lt;/td&gt; &lt;td&gt; &lt;span&gt;Nowhere 42 &lt;/span&gt; &lt;br/&gt; &lt;span&gt;Spöck &lt;/span&gt; &lt;span&gt;Germany &lt;/span&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Date of birth&lt;/td&gt; &lt;td&gt; &lt;span&gt;24 October 1990&lt;/span&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt;&quot; n }, n &quot;identifier&quot;: [ n { n &quot;use&quot;: &quot;usual&quot;, n &quot;type&quot;: { n &quot;coding&quot;: [ n { n &quot;system&quot;: &quot;http://interopsante.org/fhir/valueset/fr-patient-identifier-type&quot;, n &quot;version&quot;: &quot;1.0&quot;, n &quot;code&quot;: &quot;INS-NIR&quot;, n &quot;display&quot;: &quot;NIR définitif&quot; n } n ] n }, n &quot;system&quot;: &quot;urn:oid:1.2.250.1.213.1.4.10&quot;, n &quot;value&quot;: &quot;1426354675483&quot; n }, n { n &quot;system&quot;: &quot;http://starfleet-hospital.ufp/NamingSystem/patient-identifier&quot;, n &quot;value&quot;: &quot;NCC-7676&quot; n }, n { n &quot;system&quot;: &quot;http://starfleet-hospital.ufp/fhir/&quot;, n &quot;value&quot;: &quot;6768&quot; n } n ], n &quot;name&quot;: [ n { n &quot;family&quot;: &quot;Sky&quot;, n &quot;given&quot;: [ n &quot;Luc&quot; n ] n } n ], n &quot;telecom&quot;: [ n { n &quot;system&quot;: &quot;phone&quot;, n &quot;value&quot;: &quot;+49 (0)12345 - 123456&quot; n } n ], n &quot;gender&quot;: &quot;male&quot;, n &quot;birthDate&quot;: &quot;1980-01-01&quot;, n &quot;address&quot;: [ n { n &quot;line&quot;: [ n &quot;Nowhere 42&quot; n ], n &quot;city&quot;: &quot;Spöck&quot;, n &quot;postalCode&quot;: &quot;76297&quot;, n &quot;country&quot;: &quot;Germany&quot; n } n ], n &quot;maritalStatus&quot;: { n &quot;coding&quot;: [ n { n &quot;system&quot;: &quot;http://terminology.hl7.org/CodeSystem/v3-MaritalStatus&quot;, n &quot;code&quot;: &quot;U&quot;, n &quot;display&quot;: &quot;unmarried&quot; n } n ] n } n}&#39; response.json() {&#39;resourceType&#39;: &#39;Patient&#39;, &#39;id&#39;: &#39;38&#39;, &#39;meta&#39;: {&#39;versionId&#39;: &#39;32&#39;, &#39;lastUpdated&#39;: &#39;2019-10-30T14:16:54.484+00:00&#39;, &#39;source&#39;: &#39;#e0mm6ofqyX94cLL9&#39;}, &#39;text&#39;: {&#39;status&#39;: &#39;generated&#39;, &#39;div&#39;: &#39;&lt;div xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt; &lt;div class=&quot;hapiHeaderText&quot;&gt;Hi &lt;b&gt;HELLO &lt;/b&gt; &lt;/div&gt; &lt;table class=&quot;hapiPropertyTable&quot;&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Identifier&lt;/td&gt; &lt;td&gt;NCC-7676&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Address&lt;/td&gt; &lt;td&gt; &lt;span&gt;Nowhere 42 &lt;/span&gt; &lt;br/&gt; &lt;span&gt;Spöck &lt;/span&gt; &lt;span&gt;Germany &lt;/span&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Date of birth&lt;/td&gt; &lt;td&gt; &lt;span&gt;24 October 1990&lt;/span&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt;&#39;}, &#39;identifier&#39;: [{&#39;use&#39;: &#39;usual&#39;, &#39;type&#39;: {&#39;coding&#39;: [{&#39;system&#39;: &#39;http://interopsante.org/fhir/valueset/fr-patient-identifier-type&#39;, &#39;version&#39;: &#39;1.0&#39;, &#39;code&#39;: &#39;INS-NIR&#39;, &#39;display&#39;: &#39;NIR définitif&#39;}]}, &#39;system&#39;: &#39;urn:oid:1.2.250.1.213.1.4.10&#39;, &#39;value&#39;: &#39;1426354675483&#39;}, {&#39;system&#39;: &#39;http://starfleet-hospital.ufp/NamingSystem/patient-identifier&#39;, &#39;value&#39;: &#39;NCC-7676&#39;}, {&#39;system&#39;: &#39;http://starfleet-hospital.ufp/fhir/&#39;, &#39;value&#39;: &#39;6768&#39;}], &#39;name&#39;: [{&#39;family&#39;: &#39;Sky&#39;, &#39;given&#39;: [&#39;Luc&#39;]}], &#39;telecom&#39;: [{&#39;system&#39;: &#39;phone&#39;, &#39;value&#39;: &#39;+49 (0)12345 - 123456&#39;}], &#39;gender&#39;: &#39;male&#39;, &#39;birthDate&#39;: &#39;1980-01-01&#39;, &#39;address&#39;: [{&#39;line&#39;: [&#39;Nowhere 42&#39;], &#39;city&#39;: &#39;Spöck&#39;, &#39;postalCode&#39;: &#39;76297&#39;, &#39;country&#39;: &#39;Germany&#39;}], &#39;maritalStatus&#39;: {&#39;coding&#39;: [{&#39;system&#39;: &#39;http://terminology.hl7.org/CodeSystem/v3-MaritalStatus&#39;, &#39;code&#39;: &#39;U&#39;, &#39;display&#39;: &#39;unmarried&#39;}]}}",
    "url": "http://localhost:4000/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/03%20-%20Using%20fhirclient%20to%20parse%20Healthcare%20Data.html",
    "relUrl": "/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/03%20-%20Using%20fhirclient%20to%20parse%20Healthcare%20Data.html"
  },
  "28": {
    "id": "28",
    "title": "04 - FHIR SQL",
    "content": "import json from dateutil.parser import parse import pprint f = open(&#39;../data/fhir/Abe604_Veum823_e841a5e8-9ace-437b-be32-b37d006aef87.json&#39;, &#39;r&#39;) text = f.read() f.close() print(type(text)) &lt;class &#39;str&#39;&gt; with open(&#39;../data/fhir/Abe604_Veum823_e841a5e8-9ace-437b-be32-b37d006aef87.json&#39;) as f: bundle = json.load(f) print(type(bundle)) &lt;class &#39;dict&#39;&gt; for entry in bundle[&#39;entry&#39;]: resource = entry[&#39;resource&#39;] resource_type = resource[&#39;resourceType&#39;] if resource_type == &#39;Claim&#39;: id = resource[&#39;id&#39;] patient = resource[&#39;patient&#39;][&#39;reference&#39;] status = resource[&#39;status&#39;] total = resource[&#39;total&#39;][&#39;value&#39;] currency = resource[&#39;total&#39;][&#39;currency&#39;] start = resource[&#39;billablePeriod&#39;][&#39;start&#39;] end = resource[&#39;billablePeriod&#39;][&#39;end&#39;] print(patient, status, total, currency, start, end) break urn:uuid:df5f01e0-810b-4379-be90-bf53a6b3563d active 125.0 USD 1968-04-11T18:37:35-05:00 1968-04-11T18:52:35-05:00 for entry in bundle[&#39;entry&#39;]: resource = entry[&#39;resource&#39;] resource_type = resource[&#39;resourceType&#39;] if resource_type == &#39;Claim&#39;: id = resource[&#39;id&#39;] patient = resource[&#39;patient&#39;][&#39;reference&#39;] status = resource[&#39;status&#39;] total = resource[&#39;total&#39;][&#39;value&#39;] currency = resource[&#39;total&#39;][&#39;currency&#39;] start = parse(resource[&#39;billablePeriod&#39;][&#39;start&#39;]) end = parse(resource[&#39;billablePeriod&#39;][&#39;end&#39;]) print(patient, status, total, currency, start, end) break urn:uuid:df5f01e0-810b-4379-be90-bf53a6b3563d active 125.0 USD 1968-04-11 18:37:35-05:00 1968-04-11 18:52:35-05:00 import sqlalchemy as db engine = db.create_engine(&#39;sqlite:///fhir.sqlite&#39;) connection = engine.connect() metadata = db.MetaData() claims = db.Table(&#39;claims&#39;, metadata, db.Column(&#39;id&#39;, db.Integer()), db.Column(&#39;patient&#39;, db.String(255)), db.Column(&#39;status&#39;, db.String(255)), db.Column(&#39;total&#39;, db.Float()), db.Column(&#39;currency&#39;, db.String(255)), db.Column(&#39;start&#39;, db.DateTime()), db.Column(&#39;end&#39;, db.DateTime())) metadata.create_all(engine) #Creates the table print(claims.columns.keys()) [&#39;id&#39;, &#39;patient&#39;, &#39;status&#39;, &#39;total&#39;, &#39;currency&#39;, &#39;start&#39;, &#39;end&#39;] for entry in bundle[&#39;entry&#39;]: resource = entry[&#39;resource&#39;] resource_type = resource[&#39;resourceType&#39;] if resource_type == &#39;Claim&#39;: id = resource[&#39;id&#39;] patient = resource[&#39;patient&#39;][&#39;reference&#39;] status = resource[&#39;status&#39;] total = resource[&#39;total&#39;][&#39;value&#39;] currency = resource[&#39;total&#39;][&#39;currency&#39;] start = parse(resource[&#39;billablePeriod&#39;][&#39;start&#39;]) end = parse(resource[&#39;billablePeriod&#39;][&#39;end&#39;]) query = db.insert(claims).values(id=id, patient=patient, status=status, total=total, currency=currency, start=start, end=end) result_proxy = connection.execute(query) stmt = db.select([claims]) results = connection.execute(stmt).fetchall() import pandas as pd df = pd.DataFrame(results) df.columns = results[0].keys() df.head() id patient status total currency start end 0 b16bf2ad-9084-4764-b029-83aa5e40edaa urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 255.0 USD 1988-04-23 13:35:04 1988-04-23 13:50:04 1 b16bf2ad-9084-4764-b029-83aa5e40edaa urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 255.0 USD 1988-04-23 13:35:04 1988-04-23 13:50:04 2 722b5412-303f-4c19-8065-b40c8c3cff26 urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 125.0 USD 1988-04-23 13:35:04 1988-04-23 13:50:04 3 6305265e-1ffb-48af-bc29-404eafe9e426 urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 125.0 USD 1991-08-03 13:35:04 1991-08-03 13:50:04 4 e6f0f9cb-0655-4e3f-bbb3-b11fe034618a urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 125.0 USD 1997-08-09 13:35:04 1997-08-09 14:50:04 stmt = db.select([claims]) results = connection.execute(stmt).fetchall() pd.DataFrame(results).head() df.columns = results[0].keys() df.head() id patient status total currency start end 0 b16bf2ad-9084-4764-b029-83aa5e40edaa urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 255.0 USD 1988-04-23 13:35:04 1988-04-23 13:50:04 1 b16bf2ad-9084-4764-b029-83aa5e40edaa urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 255.0 USD 1988-04-23 13:35:04 1988-04-23 13:50:04 2 722b5412-303f-4c19-8065-b40c8c3cff26 urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 125.0 USD 1988-04-23 13:35:04 1988-04-23 13:50:04 3 6305265e-1ffb-48af-bc29-404eafe9e426 urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 125.0 USD 1991-08-03 13:35:04 1991-08-03 13:50:04 4 e6f0f9cb-0655-4e3f-bbb3-b11fe034618a urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 125.0 USD 1997-08-09 13:35:04 1997-08-09 14:50:04 stmt = db.select([claims]).where(claims.columns.total &gt;= 25000.0).order_by(db.desc(claims.columns.total)) results = connection.execute(stmt).fetchall() df = pd.DataFrame(results).head() df.columns = results[0].keys() df.head() id patient status total currency start end 0 16f8da2a-322e-47ca-bc82-8b66843858f9 urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 74670.12 USD 2015-12-26 12:35:04 2015-12-26 17:50:04 1 16f8da2a-322e-47ca-bc82-8b66843858f9 urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 74670.12 USD 2015-12-26 12:35:04 2015-12-26 17:50:04 2 16f8da2a-322e-47ca-bc82-8b66843858f9 urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 74670.12 USD 2015-12-26 12:35:04 2015-12-26 17:50:04 3 16f8da2a-322e-47ca-bc82-8b66843858f9 urn:uuid:ab8f33ad-54b4-4ee0-acd7-a14918459c3d active 74670.12 USD 2015-12-26 12:35:04 2015-12-26 17:50:04 stmt = db.select([db.func.sum(claims.columns.total).label(&#39;total claims&#39;), db.func.avg(claims.columns.total).label(&#39;average claim&#39;)]) results = connection.execute(stmt).fetchall() df = pd.DataFrame(results).head() df.columns = results[0].keys() df.head() total claims average claim 0 1476254.5 3627.160934",
    "url": "http://localhost:4000/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/04%20-%20FHIR%20SQL.html",
    "relUrl": "/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/04%20-%20FHIR%20SQL.html"
  },
  "29": {
    "id": "29",
    "title": "04 - Python Testing",
    "content": "8 Benefis of Unit Testing 8 benefits of unit testing The goal of unit testing is to segregate each part of the program and test that the individual parts are working correctly. It isolates the smallest piece of testable software from the remainder of the code and determines whether it behaves exactly as you expect. Unit testing has proven its value in that a large percentage of defects are identified during its use. It allows automation of the testing process, reduces difficulties of discovering errors contained in more complex pieces of the application, and enhances test coverage because attention is given to each unit. 1. Makes the Process Agile One of the main benefits of unit testing is that it makes the coding process more Agile. When you add more and more features to a software, you sometimes need to change old design and code. However, changing already-tested code is both risky and costly. If we have unit tests in place, then we can proceed for refactoring confidently. Unit testing really goes hand-in-hand with agile programming of all flavors because it builds in tests that allow you to make changes more easily. In other words, unit tests facilitate safe refactoring. 2. Quality of Code Unit testing improves the quality of the code. It identifies every defect that may have come up before code is sent further for integration testing. Writing tests before actual coding makes you think harder about the problem. It exposes the edge cases and makes you write better code. 3. Finds Software Bugs Early Issues are found at an early stage. Since unit testing is carried out by developers who test individual code before integration, issues can be found very early and can be resolved then and there without impacting the other pieces of the code. This includes both bugs in the programmer’s implementation and flaws or missing parts of the specification for the unit. 4. Facilitates Changes and Simplifies Integration Unit testing allows the programmer to refactor code or upgrade system libraries at a later date and make sure the module still works correctly. Unit tests detect changes that may break a design contract. They help with maintaining and changing the code. Unit testing reduces defects in the newly developed features or reduces bugs when changing the existing functionality. Unit testing verifies the accuracy of the each unit. Afterward, the units are integrated into an application by testing parts of the application via unit testing. Later testing of the application during the integration process is easier due to the verification of the individual units. 5. Provides Documentation Unit testing provides documentation of the system. Developers looking to learn what functionality is provided by a unit and how to use it can look at the unit tests to gain a basic understanding of the unit’s interface (API). 6. Debugging Process Unit testing helps simplify the debugging process. If a test fails, then only the latest changes made in the code need to be debugged. 7. Design Writing the test first forces you to think through your design and what it must accomplish before you write the code. This not only keeps you focused; it makes you create better designs. Testing a piece of code forces you to define what that code is responsible for. If you can do this easily, that means the code’s responsibility is well-defined and therefore that it has high cohesion. 8. Reduce Costs Since the bugs are found early, unit testing helps reduce the cost of bug fixes. Just imagine the cost of a bug found during the later stages of development, like during system testing or during acceptance testing. Of course, bugs detected earlier are easier to fix because bugs detected later are usually the result of many changes, and you don’t really know which one caused the bug. Getting Started With Testing in Python Getting Started With Testing in Python Automated vs. Manual Testing To have a complete set of manual tests, all you need to do is make a list of all the features your application has, the different types of input it can accept, and the expected results. Now, every time you make a change to your code, you need to go through every single item on that list and check it. Automated testing is the execution of your test plan (the parts of your application you want to test, the order in which you want to test them, and the expected responses) by a script instead of a human. Python already comes with a set of tools and libraries to help you create automated tests for your application. Unit Tests vs. Integration Tests Think of how you might test the lights on a car. You would turn on the lights (known as the test step) and go outside the car or ask a friend to check that the lights are on (known as the test assertion). Testing multiple components is known as integration testing. Think of all the things that need to work correctly in order for a simple task to give the right result. These components are like the parts to your application, all of those classes, functions, and modules you’ve written. You have just seen two types of tests: An integration test checks that components in your application operate with each other. A unit test checks a small component in your application. You can write both integration tests and unit tests in Python. # To write a unit test for the built-in function sum(), you would check the output of sum() against a known output. assert sum([1, 2, 3]) == 6, &quot;Should be 6&quot; # If the result from sum() is incorrect, this will fail with an AssertionError and the message &quot;Should be 6&quot;. assert sum([1, 1, 1]) == 6, &quot;Should be 6&quot; AssertionError Traceback (most recent call last) &lt;ipython-input-19-bebf0a559570&gt; in &lt;module&gt;() 1 # If the result from sum() is incorrect, this will fail with an AssertionError and the message &quot;Should be 6&quot;. -&gt; 2 assert sum([1, 1, 1]) == 6, &quot;Should be 6&quot; AssertionError: Should be 6 # Instead of testing on the REPL, you’ll want to put this into a new Python file called test_sum.py and execute it again: def test_sum(): assert sum([1, 2, 3]) == 6, &quot;Should be 6&quot; test_sum() print(&quot;Everything passed&quot;) def test_sum_tuple(): assert sum((1, 2, 2)) == 6, &quot;Should be 6&quot; test_sum() test_sum_tuple() print(&quot;Everything passed&quot;) Choosing a Test Runner Pytest Getting Started with Pytest There are many test runners available for Python. The one built into the Python standard library is called unittest. In this tutorial, you will be using unittest test cases and the unittest test runner. The principles of unittest are easily portable to other frameworks. The three most popular test runners are: unittest nose or nose2 pytest (we’ll use pytest) content of test_sample.py def inc(x): return x + 1 def test_answer(): assert inc(3) == 5 !pytest test_sample.py contents of test_sysexit.py # content of test_sysexit.py import pytest def f(): raise SystemExit(1) def test_mytest(): with pytest.raises(SystemExit): f() # Execute the test function with “quiet” reporting mode: !pytest -q test_sysexit.py Group multiple tests in a class Once you develop multiple tests, you may want to group them into a class. pytest makes it easy to create a class containing more than one test. pytest discovers all tests following its Conventions for Python test discovery, so it finds both test_ prefixed functions. There is no need to subclass anything. We can simply run the module by passing its filename: contentx of test_class.py # content of test_class.py class TestClass(object): def test_one(self): x = &quot;this&quot; assert &#39;h&#39; in x def test_two(self): x = &quot;hello&quot; assert hasattr(x, &#39;check&#39;) !pytest -q test_class.py Request a unique temporary directory for functional tests¶ pytest provides Builtin fixtures/function arguments to request arbitrary resources, like a unique temporary directory: contents of test_tmpdir.py # content of test_tmpdir.py def test_needsfiles(tmpdir): print(tmpdir) assert 0 !pytest -q test_tmpdir.py You can use the tmp_path fixture which will provide a temporary directory unique to the test invocation, created in the base temporary directory. contents of test_tmppath.py # content of test_tmp_path.py import os CONTENT = u&quot;content&quot; def test_create_file(tmp_path): d = tmp_path / &quot;sub&quot; d.mkdir() p = d / &quot;hello.txt&quot; p.write_text(CONTENT) assert p.read_text() == CONTENT assert len(list(tmp_path.iterdir())) == 1",
    "url": "http://localhost:4000/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/04%20-%20Python%20Testing.html",
    "relUrl": "/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/04%20-%20Python%20Testing.html"
  },
  "30": {
    "id": "30",
    "title": "04 - Reading Synthea data",
    "content": "Reading Synthea Data Here we’ll walk through the different data files from the synthea data generator. Synthea can generate data in a number of formats including: CCDA CSV FHIR Text Reading Text Data with open(&#39;../data/text/Abe604_Veum823_e841a5e8-9ace-437b-be32-b37d006aef87.txt&#39;) as f: for idx, line in enumerate(f.readlines()): print(f&#39;{idx}: {line}&#39;) if idx &gt;= 5: break 0: Abe604 Veum823 1: ============== 2: Race: Asian 3: Ethnicity: Non-Hispanic 4: Gender: M 5: Age: 69 # find all lines Reading CSV Data with open(&#39;../data/csv/providers.csv&#39;) as f: for idx, line in enumerate(f.readlines()): print(line) if idx &gt;= 5: break Id,ORGANIZATION,NAME,GENDER,SPECIALITY,ADDRESS,CITY,STATE,ZIP,UTILIZATION 4f073dcc-c92a-455b-8b0c-be967da311b8,ef58ea08-d883-3957-8300-150554edc8fb,Noe500 Dibbert990,M,GENERAL PRACTICE,60 HOSPITAL ROAD,LEOMINSTER,MA,01453,362 7066c8e7-c63a-4de5-a6ed-2fe78ba2d484,69176529-fd1f-3b3f-abce-a0a3626769eb,Mariam937 Gleason633,F,GENERAL PRACTICE,330 MOUNT AUBURN STREET,CAMBRIDGE,MA,02138,334 2d6d2a74-e052-4546-8173-ac72a39b7365,5e765f2b-e908-3888-9fc7-df2cb87beb58,Dagny669 Schoen8,F,GENERAL PRACTICE,211 PARK STREET,ATTLEBORO,MA,02703,77 66ab043d-06d1-4f21-b837-2d74448feea7,f1fbcbfb-fcfa-3bd2-b7f4-df20f1b3c3a4,Tyron580 Torphy630,M,GENERAL PRACTICE,ONE GENERAL STREET,LAWRENCE,MA,01842,359 4e37e414-41b9-467f-be47-4293b6dea918,e002090d-4e92-300e-b41e-7d1f21dee4c6,Loren192 Fay398,M,GENERAL PRACTICE,1493 CAMBRIDGE STREET,CAMBRIDGE,MA,02138,7 Reading XML Data with open(&#39;../data/ccda/Abe604_Veum823_e841a5e8-9ace-437b-be32-b37d006aef87.xml&#39;) as f: for idx, line in enumerate(f.readlines()): print(f&#39;{idx}: {line}&#39;) if idx &gt;= 5: break 0: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; 1: &lt;ClinicalDocument xmlns=&quot;urn:hl7-org:v3&quot; xmlns:sdtc=&quot;urn:hl7-org:sdtc&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;urn:hl7-org:v3 http://xreg2.nist.gov:8080/hitspValidation/schema/cdar2c32/infrastructure/cda/C32_CDA.xsd&quot;&gt; 2: &lt;realmCode code=&quot;US&quot;/&gt; 3: &lt;typeId root=&quot;2.16.840.1.113883.1.3&quot; extension=&quot;POCD_HD000040&quot;/&gt; 4: &lt;templateId root=&quot;2.16.840.1.113883.10.20.22.1.1&quot; extension=&quot;2015-08-01&quot;/&gt; 5: &lt;templateId root=&quot;2.16.840.1.113883.10.20.22.1.2&quot; extension=&quot;2015-08-01&quot;/&gt; Reading JSON Data with open(&#39;../data/fhir/Abe604_Veum823_e841a5e8-9ace-437b-be32-b37d006aef87.json&#39;) as f: for idx, line in enumerate(f.readlines()): print(f&#39;{idx}: {line}&#39;) if idx &gt;= 5: break 0: { 1: &quot;resourceType&quot;: &quot;Bundle&quot;, 2: &quot;type&quot;: &quot;transaction&quot;, 3: &quot;entry&quot;: [ 4: { 5: &quot;fullUrl&quot;: &quot;urn:uuid:df5f01e0-810b-4379-be90-bf53a6b3563d&quot;,",
    "url": "http://localhost:4000/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/04%20-%20Reading%20Synthea%20data.html",
    "relUrl": "/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/04%20-%20Reading%20Synthea%20data.html"
  },
  "31": {
    "id": "31",
    "title": "04 - The Ultimate Python Seaborn Tutorial",
    "content": "The Ultimate Python Seaborn Tutorial: Gotta Catch ‘Em All Source In this step-by-step Seaborn tutorial, you’ll learn how to use one of Python’s most convenient libraries for data visualization. For those who’ve tinkered with Matplotlib before, you may have wondered, “why does it take me 10 lines of code just to make a decent-looking histogram?” Well, if you’re looking for a simpler way to plot attractive charts, then you’ll love Seaborn. We’ll walk you through everything you need to know to get started, and we’ll use a fun Pokémon dataset (which you can download below). Introduction to Seaborn Seaborn provides a high-level interface to Matplotlib, a powerful but sometimes unwieldy Python visualization library. On Seaborn’s official website, they state: If matplotlib “tries to make easy things easy and hard things possible”, seaborn tries to make a well-defined set of hard things easy too. We’ve found this to be a pretty good summary of Seaborn’s strengths. In practice, the “well-defined set of hard things” includes: Using default themes that are aesthetically pleasing. Setting custom color palettes. Making attractive statistical plots. Easily and flexibly displaying distributions. Visualizing information from matrices and DataFrames. Those last three points are why Seaborn is our tool of choice for Exploratory Analysis. It makes it very easy to “get to know” your data quickly and efficiently. However, Seaborn is a complement, not a substitute, for Matplotlib. There are some tweaks that still require Matplotlib, and we’ll cover how to do that as well. How to Learn Seaborn, the Self-Starter Way: While Seaborn simplifies data visualization in Python, it still has many features. Therefore, the best way to learn Seaborn is to learn by doing. First, understand the basics and paradigms of the library. Each library approaches data visualization differently, so it’s important to understand how Seaborn “thinks about” the problem. Then, fire up a dataset for practice. Learning in context is the best way to master a new skill quickly. Finally, refer to galleries to spark ideas and documentation to customize your charts. Since you’ve already learned the library’s paradigms and had some hands-on practice, you’ll easily find what you need. This process will give you intuition about what you can do with Seaborn, leaving documentation to serve as further guidance. This is the fastest way to go from zero to proficient. A quick tip before we begin: We tried to make this tutorial as streamlined as possible, which means we won’t go into too much detail for any one topic. It’s helpful to have the Seaborn documentation open beside you, in case you want to learn more about a feature. Seaborn Tutorial Contents Instead of just showing you how to make a bunch of plots, we’re going to walk through the most important paradigms of the Seaborn library. Along the way, we’ll illustrate each concept with examples. Here are the steps we’ll cover in this tutorial: Installing Seaborn. Importing libraries and dataset. Seaborn’s plotting functions. Scatter Plot Customizing with Matplotlib. The role of Pandas. Box Plot Seaborn themes. Violin Plot Color palettes. Swarm Plot Overlaying plots. Putting it all together. Pokédex (mini-gallery). Heatmap Histogram Bar Plot Factor Plot Density Plot Joint Distribution Plot Step 1: Installing Seaborn. Python 3 Pandas Matplotlib Seaborn Jupyter Notebook (optional, but recommended) We strongly recommend installing the Anaconda Distribution, which comes with all of those packages. Simply follow the instructions on that download page. Once you have Anaconda installed, simply start Jupyter (either through the command line or the Navigator app) and open a new notebook Step 2: Importing libraries and dataset. Let’s start by importing Pandas, which is a great library for managing relational (i.e. table-format) datasets: # disable warnings for lecture import warnings warnings.filterwarnings(&#39;ignore&#39;) # Pandas for managing datasets import pandas as pd Next, we’ll import Matplotlib, which will help us customize our plots further. Tip: In Jupyter Notebook, you can also include %matplotlib inline to display your plots inside your notebook. # Matplotlib for additional customization from matplotlib import pyplot as plt %matplotlib inline Then, we’ll import the Seaborn library, which is the star of today’s show. # Seaborn for plotting and styling import seaborn as sns Now we’re ready to import our dataset. Tip: we gave each of our imported libraries an alias. Later, we can invoke Pandas with pd, Matplotlib with plt, and Seaborn with sns. Today, we’ll be using a cool Pokémon dataset (first generation). Here’s the free download: Dataset for this tutorial. Pokemon.csv Once you’ve downloaded the CSV file, you can import it with Pandas. Tip: The argument index_col=0 simply means we’ll treat the first column of the dataset as the ID column. # Read dataset df = pd.read_csv(&#39;Pokemon.csv&#39;, index_col=0) # Display first 5 observations df.head() Name Type 1 Type 2 Total HP Attack Defense Sp. Atk Sp. Def Speed Stage Legendary # 1 Bulbasaur Grass Poison 318 45 49 49 65 65 45 1 False 2 Ivysaur Grass Poison 405 60 62 63 80 80 60 2 False 3 Venusaur Grass Poison 525 80 82 83 100 100 80 3 False 4 Charmander Fire NaN 309 39 52 43 60 50 65 1 False 5 Charmeleon Fire NaN 405 58 64 58 80 65 80 2 False Step 3: Seaborn’s plotting functions. One of Seaborn’s greatest strengths is its diversity of plotting functions. For instance, making a scatter plot is just one line of code using the lmplot() function. There are two ways you can do so. The first way (recommended) is to pass your DataFrame to the data= argument, while passing column names to the axes arguments, x= and y=. The second way is to directly pass in Series of data to the axes arguments. For example, let’s compare the Attack and Defense stats for our Pokémon: # Recommended way sns.lmplot(x=&#39;Attack&#39;, y=&#39;Defense&#39;, data=df) &lt;seaborn.axisgrid.FacetGrid at 0x11e0f2d68&gt; By the way, Seaborn doesn’t have a dedicated scatter plot function, which is why you see a diagonal line. We actually used Seaborn’s function for fitting and plotting a regression line. Thankfully, each plotting function has several useful options that you can set. Here’s how we can tweak the lmplot(): First, we’ll set fit_reg=False to remove the regression line, since we only want a scatter plot. Then, we’ll set hue=&#39;Stage&#39; to color our points by the Pokémon’s evolution stage. This hue argument is very useful because it allows you to express a third dimension of information using color. # Scatterplot arguments sns.lmplot(x=&#39;Attack&#39;, y=&#39;Defense&#39;, data=df, fit_reg=False, # No regression line hue=&#39;Stage&#39;) # Color by evolution stage &lt;seaborn.axisgrid.FacetGrid at 0x125183fd0&gt; # Scatterplot arguments sns.lmplot(x=&#39;Attack&#39;, y=&#39;Defense&#39;, data=df, fit_reg=False, # No regression line hue=&#39;Type 1&#39;) # Color by evolution stage &lt;seaborn.axisgrid.FacetGrid at 0x12023ca58&gt; Looking better, but we can improve this scatter plot further. For example, all of our Pokémon have positive Attack and Defense values, yet our axes limits fall below zero. Let’s see how we can fix that… Step 4: Customizing with Matplotlib. Remember, Seaborn is a high-level interface to Matplotlib. From our experience, Seaborn will get you most of the way there, but you’ll sometimes need to bring in Matplotlib. Setting your axes limits is one of those times, but the process is pretty simple: First, invoke your Seaborn plotting function as normal. Then, invoke Matplotlib’s customization functions. In this case, we’ll use its ylim() and xlim() functions. Here’s our new scatter plot with sensible axes limits: # Plot using Seaborn sns.lmplot(x=&#39;Attack&#39;, y=&#39;Defense&#39;, data=df, fit_reg=False, hue=&#39;Stage&#39;) # Tweak using Matplotlib plt.ylim(0, None) plt.xlim(0, None) (0, 141.9881096001028) Step 5: The role of Pandas. Even though this is a Seaborn tutorial, Pandas actually plays a very important role. You see, Seaborn’s plotting functions benefit from a base DataFrame that’s reasonably formatted. For example, let’s say we wanted to make a box plot for our Pokémon’s combat stats: plt.figure(figsize = (8, 8)) # Boxplot sns.boxplot(data=df) &lt;matplotlib.axes._subplots.AxesSubplot at 0x120c257f0&gt; Well, that’s a reasonable start, but there are some columns we’d probably like to remove: We can remove the Total since we have individual stats. We can remove the Stage and Legendary columns because they aren’t combat stats. In turns out that this isn’t easy to do within Seaborn alone. Instead, it’s much simpler to pre-format your DataFrame. Let’s create a new DataFrame called stats_df that only keeps the stats columns: plt.figure(figsize = (8, 8)) # Pre-format DataFrame stats_df = df.drop([&#39;Total&#39;, &#39;Stage&#39;, &#39;Legendary&#39;], axis=1) # New boxplot using stats_df sns.boxplot(data=stats_df) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1093ec128&gt; Step 6: Seaborn themes. Another advantage of Seaborn is that it comes with decent style themes right out of the box. The default theme is called ‘darkgrid’. Next, we’ll change the theme to ‘whitegrid’ while making a violin plot. Violin plots are useful alternatives to box plots. They show the distribution (through the thickness of the violin) instead of only the summary statistics. For example, we can visualize the distribution of Attack by Pokémon’s primary type: plt.figure(figsize = (12, 12)) # Set theme sns.set_style(&#39;whitegrid&#39;) # Violin plot sns.violinplot(x=&#39;Type 1&#39;, y=&#39;Attack&#39;, data=df) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1212f76d8&gt; As you can see, Dragon types tend to have higher Attack stats than Ghost types, but they also have greater variance. Now, Pokémon fans might find something quite jarring about that plot: The colors are nonsensical. Why is the Grass type colored pink or the Water type colored orange? We must fix this! Step 7: Color palettes. Fortunately, Seaborn allows us to set custom color palettes. We can simply create an ordered Python list of color hex values. Let’s use Bulbapedia to help us create a new color palette: pkmn_type_colors = [&#39;#78C850&#39;, # Grass &#39;#F08030&#39;, # Fire &#39;#6890F0&#39;, # Water &#39;#A8B820&#39;, # Bug &#39;#A8A878&#39;, # Normal &#39;#A040A0&#39;, # Poison &#39;#F8D030&#39;, # Electric &#39;#E0C068&#39;, # Ground &#39;#EE99AC&#39;, # Fairy &#39;#C03028&#39;, # Fighting &#39;#F85888&#39;, # Psychic &#39;#B8A038&#39;, # Rock &#39;#705898&#39;, # Ghost &#39;#98D8D8&#39;, # Ice &#39;#7038F8&#39;, # Dragon ] Wonderful. Now we can simply use the palette= argument to recolor our chart. plt.figure(figsize = (10, 10)) # Violin plot with Pokemon color palette sns.violinplot(x=&#39;Type 1&#39;, y=&#39;Attack&#39;, data=df, palette=pkmn_type_colors) # Set color palette &lt;matplotlib.axes._subplots.AxesSubplot at 0x121a6c048&gt; Much better! Violin plots are great for visualizing distributions. However, since we only have 151 Pokémon in our dataset, we may want to simply display each point. That’s where the swarm plot comes in. This visualization will show each point, while “stacking” those with similar values: plt.figure(figsize = (10, 10)) # Swarm plot with Pokemon color palette sns.swarmplot(x=&#39;Type 1&#39;, y=&#39;Attack&#39;, data=df, palette=pkmn_type_colors) &lt;matplotlib.axes._subplots.AxesSubplot at 0x121a5bd68&gt; That’s handy, but can’t we combine our swarm plot and the violin plot? After all, they display similar information, right? Step 8: Overlaying plots. The answer is yes. It’s pretty straightforward to overlay plots using Seaborn, and it works the same way as with Matplotlib. Here’s what we’ll do: First, we’ll make our figure larger using Matplotlib. Then, we’ll plot the violin plot. However, we’ll set inner=None to remove the bars inside the violins. Next, we’ll plot the swarm plot. This time, we’ll make the points black so they pop out more. Finally, we’ll set a title using Matplotlib. # Set figure size with matplotlib plt.figure(figsize=(10,6)) # Create plot sns.violinplot(x=&#39;Type 1&#39;, y=&#39;Attack&#39;, data=df, inner=None, # Remove the bars inside the violins palette=pkmn_type_colors) sns.swarmplot(x=&#39;Type 1&#39;, y=&#39;Attack&#39;, data=df, color=&#39;k&#39;, # Make points black alpha=0.7) # and slightly transparent # Set title with matplotlib plt.title(&#39;Attack by Type&#39;) Text(0.5,1,&#39;Attack by Type&#39;) Awesome, now we have a pretty chart that tells us how Attack values are distributed across different Pokémon types. But what it we want to see all of the other stats as well? Step 9: Putting it all together. Well, we could certainly repeat that chart for each stat. But we can also combine the information into one chart… we just have to do some data wrangling with Pandas beforehand. First, here’s a reminder of our data format: stats_df.head() Name Type 1 Type 2 HP Attack Defense Sp. Atk Sp. Def Speed # 1 Bulbasaur Grass Poison 45 49 49 65 65 45 2 Ivysaur Grass Poison 60 62 63 80 80 60 3 Venusaur Grass Poison 80 82 83 100 100 80 4 Charmander Fire NaN 39 52 43 60 50 65 5 Charmeleon Fire NaN 58 64 58 80 65 80 As you can see, all of our stats are in separate columns. Instead, we want to “melt” them into one column. To do so, we’ll use Pandas’s melt() function. It takes 3 arguments: First, the DataFrame to melt. Second, ID variables to keep (Pandas will melt all of the other ones). Finally, a name for the new, melted variable. Here’s the output: # Melt DataFrame melted_df = pd.melt(stats_df, id_vars=[&quot;Name&quot;, &quot;Type 1&quot;, &quot;Type 2&quot;], # Variables to keep var_name=&quot;Stat&quot;) # Name of melted variable melted_df.sort_values(&#39;Name&#39;).head(10) Name Type 1 Type 2 Stat value 364 Abra Psychic NaN Defense 15 213 Abra Psychic NaN Attack 20 817 Abra Psychic NaN Speed 90 666 Abra Psychic NaN Sp. Def 55 515 Abra Psychic NaN Sp. Atk 105 62 Abra Psychic NaN HP 25 443 Aerodactyl Rock Flying Defense 65 594 Aerodactyl Rock Flying Sp. Atk 60 745 Aerodactyl Rock Flying Sp. Def 75 292 Aerodactyl Rock Flying Attack 105 All 6 of the stat columns have been “melted” into one, and the new Stat column indicates the original stat (HP, Attack, Defense, Sp. Attack, Sp. Defense, or Speed). For example, it’s hard to see here, but Bulbasaur now has 6 rows of data. In fact, if you print the shape of these two DataFrames… print( stats_df.shape ) print( melted_df.shape ) (151, 9) (906, 5) …you’ll find that melted_df has 6 times the number of rows as stats_df. Now we can make a swarm plot with melted_df. But this time, we’re going to set x=&#39;Stat&#39; and y=&#39;value&#39; so our swarms are separated by stat. Then, we’ll set hue=&#39;Type 1&#39; to color our points by the Pokémon type. plt.figure(figsize=(14,10)) # Swarmplot with melted_df sns.swarmplot(x=&#39;Stat&#39;, y=&#39;value&#39;, data=melted_df, hue=&#39;Type 1&#39;) &lt;matplotlib.axes._subplots.AxesSubplot at 0x121f24390&gt; Finally, let’s make a few final tweaks for a more readable chart: Enlarge the plot. Separate points by hue using the argument split=True. Use our custom Pokemon color palette. Adjust the y-axis limits to end at 0. Place the legend to the right. # 1. Enlarge the plot plt.figure(figsize=(14,10)) sns.swarmplot(x=&#39;Stat&#39;, y=&#39;value&#39;, data=melted_df, hue=&#39;Type 1&#39;, split=True, # 2. Separate points by hue palette=pkmn_type_colors) # 3. Use Pokemon palette # 4. Adjust the y-axis plt.ylim(0, 260) # 5. Place legend to the right plt.legend(bbox_to_anchor=(1, 1), loc=2) &lt;matplotlib.legend.Legend at 0x1224d1240&gt; Step 10: Pokédex (mini-gallery). We’re going to conclude this tutorial with a few quick-fire data visualizations, just to give you a sense of what’s possible with Seaborn. 10.1 - Heatmap Heatmaps help you visualize matrix-like data. plt.figure(figsize=(8,6)) # Calculate correlations corr = stats_df.corr() # Heatmap sns.heatmap(corr) &lt;matplotlib.axes._subplots.AxesSubplot at 0x122892908&gt; 10.2 - Histogram Histograms allow you to plot the distributions of numeric variables. plt.figure(figsize=(8,6)) # Distribution Plot (a.k.a. Histogram) sns.distplot(df.Attack) &lt;matplotlib.axes._subplots.AxesSubplot at 0x122ac08d0&gt; 10.3 - Bar Plot Bar plots help you visualize the distributions of categorical variables. plt.figure(figsize=(8,6)) # Count Plot (a.k.a. Bar Plot) sns.countplot(x=&#39;Type 1&#39;, data=df, palette=pkmn_type_colors) # Rotate x-labels plt.xticks(rotation=-45) (array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]), &lt;a list of 15 Text xticklabel objects&gt;) 10.4 - Factor Plot Factor plots make it easy to separate plots by categorical classes. # Factor Plot g = sns.factorplot(x=&#39;Type 1&#39;, y=&#39;Attack&#39;, data=df, hue=&#39;Stage&#39;, # Color by stage col=&#39;Stage&#39;, # Separate by stage kind=&#39;swarm&#39;) # Swarmplot # Rotate x-axis labels g.set_xticklabels(rotation=-45) # Doesn&#39;t work because only rotates last plot # plt.xticks(rotation=-45) &lt;seaborn.axisgrid.FacetGrid at 0x121f0fac8&gt; 10.5 - Density Plot Density plots display the distribution between two variables. plt.figure(figsize=(8,6)) # Density Plot sns.kdeplot(df.Attack, df.Defense) &lt;matplotlib.axes._subplots.AxesSubplot at 0x122f6ba90&gt; 10.6 - Joint Distribution Plot Joint distribution plots combine information from scatter plots and histograms to give you detailed information for bi-variate distributions. plt.figure(figsize=(8,6)) # Joint Distribution Plot sns.jointplot(x=&#39;Attack&#39;, y=&#39;Defense&#39;, data=df) &lt;seaborn.axisgrid.JointGrid at 0x122fc2e80&gt; &lt;Figure size 576x432 with 0 Axes&gt; Congratulations… you’ve made it to the end of this Python Seaborn tutorial! We’ve just concluded a tour of key Seaborn paradigms and showed you many examples along the way. Feel free to use this page along with the official Seaborn gallery as references for your projects going forward.",
    "url": "http://localhost:4000/lectures/Week%2004%20-%20Numpy,%20Pandas,%20Graphing%20&%20Visualization/04%20-%20The%20Ultimate%20Python%20Seaborn%20Tutorial.html",
    "relUrl": "/lectures/Week%2004%20-%20Numpy,%20Pandas,%20Graphing%20&%20Visualization/04%20-%20The%20Ultimate%20Python%20Seaborn%20Tutorial.html"
  },
  "32": {
    "id": "32",
    "title": "04.a - Dictionaries",
    "content": "Python Dictionaries Python Dictionary Tutorial A dictionary in Python is a collection of items accessed by a specific key rather than by index. What does this mean? Imagine a dictionary in the real world… when you need to look up the meaning of a word, you try to find the meaning using the word itself and not the possible index of the word. Python dictionaries work with the same concept, the word whose meaning you are looking for is the key and the meaning of the word is the value, you do not need to know the index of the word in a dictionary to find its meaning. Note: The keys in a dictionary have to be hashable. Hashing is the process of running an item through a specific kind of function. This function is called a “hash function”. This hash function returns a unique output for a unique input value. Integers, floating point numbers, strings, tuples, and frozensets are hashable. While lists, dictionaries, and sets other than frozensets are not. Hashing is a somewhat complex topic and this is only the basic concept behind hashing. You can initialize a dictionary in Python a variety of ways: # Creating an empty dict using empty brackets word_frequency = {} # Creating an empty dict using dict() word_frequency = dict() print(word_frequency) {} # Creating Dictionaries with literals word_frequency = { &quot;Hello&quot; : 7, &quot;hi&quot; : 10, &quot;there&quot; : 45, &quot;at&quot; : 23, &quot;this&quot; : 77 } print(word_frequency) {&#39;Hello&#39;: 7, &#39;hi&#39;: 10, &#39;there&#39;: 45, &#39;at&#39;: 23, &#39;this&#39;: 77} # Creating Dictionaries by passing parametrs in dict constructor word_frequency = dict(Hello = 7, hi = 10, there = 45, at = 23, this = 77) print(word_frequency) {&#39;Hello&#39;: 7, &#39;hi&#39;: 10, &#39;there&#39;: 45, &#39;at&#39;: 23, &#39;this&#39;: 77} # Creating dictionaries with a List of tuples list_of_tuples = [(&quot;Hello&quot; , 7), (&quot;hi&quot; , 10), (&quot;there&quot; , 45),(&quot;at&quot; , 23),(&quot;this&quot; , 77)] word_frequency = dict(list_of_tuples) print(word_frequency) {&#39;Hello&#39;: 7, &#39;hi&#39;: 10, &#39;there&#39;: 45, &#39;at&#39;: 23, &#39;this&#39;: 77} # create and Initialize a dictionary by this list elements as keys and with same value 0 list_of_strings = [&quot;Hello&quot;, &quot;hi&quot;, &quot;there&quot;, &quot;at&quot;, &quot;this&quot;] word_frequency = dict.fromkeys(list_of_strings,0 ) print(word_frequency) {&#39;Hello&#39;: 0, &#39;hi&#39;: 0, &#39;there&#39;: 0, &#39;at&#39;: 0, &#39;this&#39;: 0} # Creating a Dictionary by a two lists list_of_strings = [&quot;Hello&quot;, &quot;hi&quot;, &quot;there&quot;, &quot;at&quot;, &quot;this&quot;] list_of_ints = [7, 10, 45, 23, 77, 99, 100, 101] # Merge the two lists to create a dictionary word_frequency = dict(zip(list_of_strings, list_of_ints)) print(word_frequency) {&#39;Hello&#39;: 7, &#39;hi&#39;: 10, &#39;there&#39;: 45, &#39;at&#39;: 23, &#39;this&#39;: 77} You can then access the values by specifying the dictionary key # or this way a = {&#39;apple&#39;: &#39;fruit&#39;, &#39;beetroot&#39;: &#39;vegetable&#39;, &#39;cake&#39;: &#39;dessert&#39;} print(a[&#39;apple&#39;]) fruit The items in a dictionary can have any data type. Check out some more examples of a dictionary to get a hang of it: a = {&#39;one&#39;: 1, &#39;two&#39;: &#39;to&#39;, &#39;three&#39;: 3.0, &#39;four&#39;: [4,4.0]} print(a) {&#39;one&#39;: 1, &#39;two&#39;: &#39;to&#39;, &#39;three&#39;: 3.0, &#39;four&#39;: [4, 4.0]} # Update a dictionary a[&#39;one&#39;] = 1.0 print(a) {&#39;one&#39;: 1.0, &#39;two&#39;: &#39;to&#39;, &#39;three&#39;: 3.0, &#39;four&#39;: [4, 4.0]} # Delete a single element del a[&#39;one&#39;] print(a) {&#39;two&#39;: &#39;to&#39;, &#39;three&#39;: 3.0, &#39;four&#39;: [4, 4.0]} # Delete all elements in the dictionary a.clear() print(a) {} # Delete the dictionary del a print(a) NameError Traceback (most recent call last) &lt;ipython-input-13-34aa67d4dc63&gt; in &lt;module&gt; 1 # Delete the dictionary 2 del a -&gt; 3 print(a) NameError: name &#39;a&#39; is not defined It is important to remember is that a key has to be unique in a dictionary, no duplicates are allowed. However, in case of duplicate keys rather than giving an error, Python will take the last instance of the key to be valid and simply ignore the first key-value pair. sweet_dict = {&#39;a1&#39;: &#39;cake&#39;, &#39;a2&#39;:&#39;cookie&#39;, &#39;a1&#39;: &#39;icecream&#39;} print(sweet_dict) print(sweet_dict[&#39;a1&#39;]) {&#39;a1&#39;: &#39;icecream&#39;, &#39;a2&#39;: &#39;cookie&#39;} icecream",
    "url": "http://localhost:4000/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/04.a%20-%20Dictionaries.html",
    "relUrl": "/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/04.a%20-%20Dictionaries.html"
  },
  "33": {
    "id": "33",
    "title": "04.a - Pandas Data analysis Part 1",
    "content": "Source Python is a great language for doing data analysis, primarily because of the fantastic ecosystem of data-centric Python packages. Pandas is one of those packages, and makes importing and analyzing data much easier. Pandas builds on packages like NumPy and matplotlib to give you a single, convenient, place to do most of your data analysis and visualization work. In this introduction, we’ll use Pandas to analyze data on video game reviews from IGN, a popular video game review site. The data was scraped by Eric Grinstein, and can be found here. As we analyze the video game reviews, we’ll learn key Pandas concepts like indexing. Do games like the Witcher 3 tend to get better reviews on the PS4 than the Xbox One? This dataset can help us find out. Importing Data with Pandas The first step we’ll take is to read the data in. The data is stored as a comma-separated values, or csv, file, where each row is separated by a new line, and each column by a comma (,). Here are the first few rows of the ign.csv file: ,score_phrase,title,url,platform,score,genre,editors_choice,release_year,release_month,release_day 0,Amazing,LittleBigPlanet PS Vita,/games/littlebigplanet-vita/vita-98907,PlayStation Vita,9.0,Platformer,Y,2012,9,12 1,Amazing,LittleBigPlanet PS Vita -- Marvel Super Hero Edition,/games/littlebigplanet-ps-vita-marvel-super-hero-edition/vita-20027059,PlayStation Vita,9.0,Platformer,Y,2012,9,12 2,Great,Splice: Tree of Life,/games/splice/ipad-141070,iPad,8.5,Puzzle,N,2012,9,12 3,Great,NHL 13,/games/nhl-13/xbox-360-128182,Xbox 360,8.5,Sports,N,2012,9,11 As you can see above, each row in the data represents a single game that was reviewed by IGN. The columns contain information about that game: score_phrase — how IGN described the game in one word. This is linked to the score it received. title — the name of the game. url — the URL where you can see the full review. platform — the platform the game was reviewed on (PC, PS4, etc). score — the score for the game, from 1.0 to 10.0. genre — the genre of the game. editors_choice — N if the game wasn’t an editor’s choice, Y if it was. This is tied to score. release_year — the year the game was released. release_month — the month the game was released. release_day — the day the game was released. There’s also a leading column that contains row index values. We can safely ignore this column, but we’ll dive into what index values are later on. In order to be able to work with the data in Python, we’ll need to read the csv file into a Pandas DataFrame. A DataFrame is a way to represent and work with tabular data. Tabular data has rows and columns, just like our csv file. In order to read in the data, we’ll need to use the pandas.read_csv function. This function will take in a csv file and return a DataFrame. The below code will: Import the pandas library. We rename it to pd so it’s faster to type out. Read ign.csv into a DataFrame, and assign the result to reviews. # disable warnings for lecture import warnings warnings.filterwarnings(&#39;ignore&#39;) import pandas as pd reviews = pd.read_csv(&quot;ign.csv&quot;) Once we read in a DataFrame, Pandas gives us two methods that make it fast to print out the data. These functions are: pandas.DataFrame.head – prints the first N rows of a DataFrame. By default 5. pandas.DataFrame.tail – prints the last N rows of a DataFrame. By default 5. We’ll use the head method to see what’s in reviews: reviews.head(3) Unnamed: 0 score_phrase title url platform score genre editors_choice release_year release_month release_day 0 0 Amazing LittleBigPlanet PS Vita /games/littlebigplanet-vita/vita-98907 PlayStation Vita 9.0 Platformer Y 2012 9 12 1 1 Amazing LittleBigPlanet PS Vita -- Marvel Super Hero E... /games/littlebigplanet-ps-vita-marvel-super-he... PlayStation Vita 9.0 Platformer Y 2012 9 12 2 2 Great Splice: Tree of Life /games/splice/ipad-141070 iPad 8.5 Puzzle N 2012 9 12 We can also access the pandas.DataFrame.shape property to see row many rows and columns are in reviews: reviews.shape (18625, 11) As you can see, everything has been read in properly – we have 18625 rows and 11 columns. One of the big advantages of Pandas vs just using NumPy is that Pandas allows you to have columns with different data types. reviews has columns that store float values, like score, string values, like score_phrase, and integers, like release_year. Now that we’ve read the data in properly, let’s work on indexing reviews to get the rows and columns that we want. Indexing DataFrames with Pandas Earlier, we used the head method to print the first 5 rows of reviews. We could accomplish the same thing using the pandas.DataFrame.iloc method. The iloc method allows us to retrieve rows and columns by position. In order to do that, we’ll need to specify the positions of the rows that we want, and the positions of the columns that we want as well. The below code will replicate reviews.head(): reviews.iloc[0:5,:] Unnamed: 0 score_phrase title url platform score genre editors_choice release_year release_month release_day 0 0 Amazing LittleBigPlanet PS Vita /games/littlebigplanet-vita/vita-98907 PlayStation Vita 9.0 Platformer Y 2012 9 12 1 1 Amazing LittleBigPlanet PS Vita -- Marvel Super Hero E... /games/littlebigplanet-ps-vita-marvel-super-he... PlayStation Vita 9.0 Platformer Y 2012 9 12 2 2 Great Splice: Tree of Life /games/splice/ipad-141070 iPad 8.5 Puzzle N 2012 9 12 3 3 Great NHL 13 /games/nhl-13/xbox-360-128182 Xbox 360 8.5 Sports N 2012 9 11 4 4 Great NHL 13 /games/nhl-13/ps3-128181 PlayStation 3 8.5 Sports N 2012 9 11 As you can see above, we specified that we wanted rows 0:5. This means that we wanted the rows from position 0 up to, but not including, position 5. The first row is considered to be in position 0. This gives us the rows at positions 0, 1, 2, 3, and 4. If we leave off the first position value, like :5, it’s assumed we mean 0. If we leave off the last position value, like 0:, it’s assumed we mean the last row or column in the DataFrame. We wanted all of the columns, so we specified just a colon (:), without any positions. This gave us the columns from 0 to the last column. Here are some indexing examples, along with the results: reviews.iloc[:5,:] — the first 5 rows, and all of the columns for those rows. reviews.iloc[:,:] — the entire DataFrame. reviews.iloc[5:,5:] — rows from position 5 onwards, and columns from position 5 onwards. reviews.iloc[:,0] — the first column, and all of the rows for the column. reviews.iloc[9,:] — the 10th row, and all of the columns for that row. Indexing by position is very similar to NumPy indexing. Now that we know how to index by position, let’s remove the first column, which doesn’t have any useful information: reviews = reviews.iloc[:,1:] reviews.head() score_phrase title url platform score genre editors_choice release_year release_month release_day 0 Amazing LittleBigPlanet PS Vita /games/littlebigplanet-vita/vita-98907 PlayStation Vita 9.0 Platformer Y 2012 9 12 1 Amazing LittleBigPlanet PS Vita -- Marvel Super Hero E... /games/littlebigplanet-ps-vita-marvel-super-he... PlayStation Vita 9.0 Platformer Y 2012 9 12 2 Great Splice: Tree of Life /games/splice/ipad-141070 iPad 8.5 Puzzle N 2012 9 12 3 Great NHL 13 /games/nhl-13/xbox-360-128182 Xbox 360 8.5 Sports N 2012 9 11 4 Great NHL 13 /games/nhl-13/ps3-128181 PlayStation 3 8.5 Sports N 2012 9 11 reviews.shape (18625, 10) Indexing Using Labels in Pandas Now that we know how to retrieve rows and columns by position, it’s worth looking into the other major way to work with DataFrames, which is to retrieve rows and columns by label. A major advantage of Pandas over NumPy is that each of the columns and rows has a label. Working with column positions is possible, but it can be hard to keep track of which number corresponds to which column. We can work with labels using the pandas.DataFrame.loc method, which allows us to index using labels instead of positions. We can display the first five rows of reviews using the loc method like this: reviews.loc[0:5,:] score_phrase title url platform score genre editors_choice release_year release_month release_day 0 Amazing LittleBigPlanet PS Vita /games/littlebigplanet-vita/vita-98907 PlayStation Vita 9.0 Platformer Y 2012 9 12 1 Amazing LittleBigPlanet PS Vita -- Marvel Super Hero E... /games/littlebigplanet-ps-vita-marvel-super-he... PlayStation Vita 9.0 Platformer Y 2012 9 12 2 Great Splice: Tree of Life /games/splice/ipad-141070 iPad 8.5 Puzzle N 2012 9 12 3 Great NHL 13 /games/nhl-13/xbox-360-128182 Xbox 360 8.5 Sports N 2012 9 11 4 Great NHL 13 /games/nhl-13/ps3-128181 PlayStation 3 8.5 Sports N 2012 9 11 5 Good Total War Battles: Shogun /games/total-war-battles-shogun/mac-142565 Macintosh 7.0 Strategy N 2012 9 11 The above doesn’t actually look much different from reviews.iloc[0:5,:]. This is because while row labels can take on any values, our row labels match the positions exactly. You can see the row labels on the very left of the table above (they’re in bold). You can also see them by accessing the index property of a DataFrame. We’ll display the row indexes for reviews: reviews.index RangeIndex(start=0, stop=18625, step=1) # pull out the 1st twenty indexes list(reviews.index)[:20] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19] Indexes don’t always have to match up with positions, though. In the below code cell, we’ll: Get row 10 to row 20 of reviews, and assign the result to some_reviews. Display the first 5 rows of some_reviews. some_reviews = reviews.iloc[10:20,] some_reviews.head() score_phrase title url platform score genre editors_choice release_year release_month release_day 10 Good Tekken Tag Tournament 2 /games/tekken-tag-tournament-2/ps3-124584 PlayStation 3 7.5 Fighting N 2012 9 11 11 Good Tekken Tag Tournament 2 /games/tekken-tag-tournament-2/xbox-360-124581 Xbox 360 7.5 Fighting N 2012 9 11 12 Good Wild Blood /games/wild-blood/iphone-139363 iPhone 7.0 NaN N 2012 9 10 13 Amazing Mark of the Ninja /games/mark-of-the-ninja-135615/xbox-360-129276 Xbox 360 9.0 Action, Adventure Y 2012 9 7 14 Amazing Mark of the Ninja /games/mark-of-the-ninja-135615/pc-143761 PC 9.0 Action, Adventure Y 2012 9 7 As we mentioned earlier, column labels can make life much easier when you’re working with data. We can specify column labels in the loc method to retrieve columns by label instead of by position. reviews.loc[:5, &quot;score&quot;] 0 9.0 1 9.0 2 8.5 3 8.5 4 8.5 5 7.0 Name: score, dtype: float64 We can also specify more than one column at a time by passing in a list: reviews.loc[:5, [&quot;score&quot;, &quot;release_year&quot;]] score release_year 0 9.0 2012 1 9.0 2012 2 8.5 2012 3 8.5 2012 4 8.5 2012 5 7.0 2012 reviews.loc[[0, 3], [&quot;score&quot;, &quot;release_year&quot;]] score release_year 0 9.0 2012 3 8.5 2012 Pandas Series Objects We can retrieve an individual column in Pandas a few different ways. So far, we’ve seen two types of syntax for this: reviews.iloc[:,1] — will retrieve the second column. reviews.loc[:,&quot;score_phrase&quot;] — will also retrieve the second column. There’s a third, even easier, way to retrieve a whole column. We can just specify the column name in square brackets, like with a dictionary: reviews[&quot;score&quot;].head() 0 9.0 1 9.0 2 8.5 3 8.5 4 8.5 Name: score, dtype: float64 We can also use lists of columns with this method: x = reviews[[&quot;score&quot;, &quot;release_year&quot;]] x.head() score release_year 0 9.0 2012 1 9.0 2012 2 8.5 2012 3 8.5 2012 4 8.5 2012 When we retrieve a single column, we’re actually retrieving a Pandas Series object. A DataFrame stores tabular data, but a Series stores a single column or row of data. We can verify that a single column is a Series: type(reviews[&quot;score&quot;]) pandas.core.series.Series We can create a Series manually to better understand how it works. To create a Series, we pass a list or NumPy array into the Series object when we instantiate it: s1 = pd.Series([1, 2]) s1 0 1 1 2 dtype: int64 A Series can contain any type of data, including mixed types. Here, we create a Series that contains string objects: s2 = pd.Series([&quot;Boris Yeltsin&quot;, &quot;Mikhail Gorbachev&quot;]) s2 0 Boris Yeltsin 1 Mikhail Gorbachev dtype: object Creating A DataFrame in Pandas We can create a DataFrame by passing multiple Series into the DataFrame class. Here, we pass in the two Series objects we just created, s1 as the first row, and s2 as the second row: # create a dataframe from two series x = pd.DataFrame() x[&#39;rank&#39;] = s1 x[&#39;name&#39;] = s2 x rank name 0 1 Boris Yeltsin 1 2 Mikhail Gorbachev # create a datafrme from a dictionary y = pd.DataFrame({ &#39;rank&#39;: s1, &#39;name&#39;: s2 }) y rank name 0 1 Boris Yeltsin 1 2 Mikhail Gorbachev # create a dataframe from a list pd.DataFrame([s1, s2]) 0 1 0 1 2 1 Boris Yeltsin Mikhail Gorbachev We can also accomplish the same thing with a list of lists. Each inner list is treated as a row in the resulting DataFrame: # create a dataframe from a list of lists pd.DataFrame( [ [1, &quot;Boris Yeltsin&quot;], [2, &quot;Mikhail Gorbachev&quot;] ] ) 0 1 0 1 Boris Yeltsin 1 2 Mikhail Gorbachev We can specify the column labels when we create a DataFrame: # specify column labels pd.DataFrame( [ [1, &quot;Boris Yeltsin&quot;], [2, &quot;Mikhail Gorbachev&quot;] ], columns=[&quot;rank&quot;, &quot;name&quot;] ) rank name 0 1 Boris Yeltsin 1 2 Mikhail Gorbachev As well as the row labels (the index): # specify the index labels frame = pd.DataFrame( [ [1,2], [&quot;Boris Yeltsin&quot;, &quot;Mikhail Gorbachev&quot;] ], index=[&quot;rank&quot;, &quot;name&quot;], columns=[&quot;person1&quot;, &quot;person2&quot;] ) frame person1 person2 rank 1 2 name Boris Yeltsin Mikhail Gorbachev We’re then able index the DataFrame using the labels: frame.loc[&quot;rank&quot;:&quot;name&quot;, &quot;person1&quot;] rank 1 name Boris Yeltsin Name: person1, dtype: object We can skip specifying the columns keyword argument if we pass a dictionary into the DataFrame constructor. This will automatically setup column names: frame = pd.DataFrame( { &quot;person1&quot;: [1, &quot;Boris Yeltsin&quot;], &quot;person2&quot;: [2, &quot;Mikhail Gorbachev&quot;] } ) frame person1 person2 0 1 2 1 Boris Yeltsin Mikhail Gorbachev Pandas DataFrame Methods As we mentioned earlier, each column in a DataFrame is a Series object: type(reviews[&quot;title&quot;]) pandas.core.series.Series We can call most of the same methods on a Series object that we can on a DataFrame, including head: reviews[&quot;title&quot;].head() 0 LittleBigPlanet PS Vita 1 LittleBigPlanet PS Vita -- Marvel Super Hero E... 2 Splice: Tree of Life 3 NHL 13 4 NHL 13 Name: title, dtype: object Pandas Series and DataFrame also have other methods that make calculations simpler. For example, we can use the pandas.Series.mean method to find the mean of a Series: reviews[&quot;score&quot;].mean() 6.950459060402666 We can also call the similar pandas.DataFrame.mean method, which will find the mean of each numerical column in a DataFrame by default: x = reviews.mean() x score 6.950459 release_year 2006.515329 release_month 7.138470 release_day 15.603866 dtype: float64 We can modify the axis keyword argument to mean in order to compute the mean of each row or of each column. By default, axis is equal to 0, and will compute the mean of each column. We can also set it to 1 to compute the mean of each row. Note that this will only compute the mean of the numerical values in each row: reviews.mean(axis=1).head() 0 510.500 1 510.500 2 510.375 3 510.125 4 510.125 dtype: float64 There are quite a few methods on Series and DataFrame that behave like mean. Here are some handy ones: pandas.DataFrame.corr — finds the correlation between columns in a DataFrame. pandas.DataFrame.count — counts the number of non-null values in each DataFrame column. pandas.DataFrame.max — finds the highest value in each column. pandas.DataFrame.min — finds the lowest value in each column. pandas.DataFrame.median — finds the median of each column. pandas.DataFrame.std — finds the standard deviation of each column. We can use the corr method to see if any columns correlation with score. For instance, this would tell us if games released more recently have been getting higher reviews (release_year), or if games released towards the end of the year score better (release_month): reviews.corr() score release_year release_month release_day score 1.000000 0.062716 0.007632 0.020079 release_year 0.062716 1.000000 -0.115515 0.016867 release_month 0.007632 -0.115515 1.000000 -0.067964 release_day 0.020079 0.016867 -0.067964 1.000000 As you can see above, none of our numeric columns correlates with score, meaning that release timing doesn’t linearly relate to review score. DataFrame Math with Pandas We can also perform math operations on Series or DataFrame objects. For example, we can divide every value in the score column by 2 to switch the scale from 0-10 to 0-5: reviews[&quot;score&quot;] / 2 0 4.50 1 4.50 2 4.25 3 4.25 4 4.25 5 3.50 6 1.50 7 4.50 8 1.50 9 3.50 10 3.75 11 3.75 12 3.50 13 4.50 14 4.50 15 3.25 16 3.25 17 4.00 18 2.75 19 3.50 20 3.50 21 3.75 22 3.75 23 3.75 24 4.50 25 3.50 26 4.50 27 3.75 28 4.00 29 3.25 ... 18595 2.20 18596 3.25 18597 2.45 18598 3.40 18599 3.50 18600 3.70 18601 3.70 18602 3.70 18603 3.90 18604 4.30 18605 3.00 18606 3.20 18607 3.50 18608 2.70 18609 4.00 18610 3.00 18611 2.90 18612 3.90 18613 4.00 18614 4.60 18615 4.60 18616 3.75 18617 4.20 18618 4.55 18619 3.95 18620 3.80 18621 4.50 18622 2.90 18623 5.00 18624 5.00 Name: score, Length: 18625, dtype: float64 All the common mathematical operators that work in Python, like +, -, *, /, and ^ will work, and will apply to each element in a DataFrame or a Series. Boolean Indexing in Pandas As we saw above, the mean of all the values in the score column of reviews is around 7. What if we wanted to find all the games that got an above average score? We could start by doing a comparison. The comparison compares each value in a Series to a specified value, then generate a Series full of Boolean values indicating the status of the comparison. For example, we can see which of the rows have a score value higher than 7: score_filter = reviews[&quot;score&quot;] &gt; 7 score_filter 0 True 1 True 2 True 3 True 4 True 5 False 6 False 7 True 8 False 9 False 10 True 11 True 12 False 13 True 14 True 15 False 16 False 17 True 18 False 19 False 20 False 21 True 22 True 23 True 24 True 25 False 26 True 27 True 28 True 29 False ... 18595 False 18596 False 18597 False 18598 False 18599 False 18600 True 18601 True 18602 True 18603 True 18604 True 18605 False 18606 False 18607 False 18608 False 18609 True 18610 False 18611 False 18612 True 18613 True 18614 True 18615 True 18616 True 18617 True 18618 True 18619 True 18620 True 18621 True 18622 False 18623 True 18624 True Name: score, Length: 18625, dtype: bool Once we have a Boolean Series, we can use it to select only rows in a DataFrame where the Series contains the value True. So, we could only select rows in reviews where score is greater than 7: filtered_reviews = reviews[score_filter] filtered_reviews.head() score_phrase title url platform score genre editors_choice release_year release_month release_day 0 Amazing LittleBigPlanet PS Vita /games/littlebigplanet-vita/vita-98907 PlayStation Vita 9.0 Platformer Y 2012 9 12 1 Amazing LittleBigPlanet PS Vita -- Marvel Super Hero E... /games/littlebigplanet-ps-vita-marvel-super-he... PlayStation Vita 9.0 Platformer Y 2012 9 12 2 Great Splice: Tree of Life /games/splice/ipad-141070 iPad 8.5 Puzzle N 2012 9 12 3 Great NHL 13 /games/nhl-13/xbox-360-128182 Xbox 360 8.5 Sports N 2012 9 11 4 Great NHL 13 /games/nhl-13/ps3-128181 PlayStation 3 8.5 Sports N 2012 9 11 It’s possible to use multiple conditions for filtering. Let’s say we want to find games released for the Xbox One that have a score of more than 7. In the below code, we: Setup a filter with two conditions: Check if score is greater than 7. Check if platform equals Xbox One Apply the filter to reviews to get only the rows we want. Use the head method to print the first 5 rows of filtered_reviews. # setup the boolean filtr xbox_one_filter = (reviews[&quot;score&quot;] &gt; 7) &amp; (reviews[&quot;platform&quot;] == &quot;Xbox One&quot;) # select the data based on the filter filtered_reviews = reviews[xbox_one_filter] # display the first 5 results filtered_reviews.head() score_phrase title url platform score genre editors_choice release_year release_month release_day 17137 Amazing Gone Home /games/gone-home/xbox-one-20014361 Xbox One 9.5 Simulation Y 2013 8 15 17197 Amazing Rayman Legends /games/rayman-legends/xbox-one-20008449 Xbox One 9.5 Platformer Y 2013 8 26 17295 Amazing LEGO Marvel Super Heroes /games/lego-marvel-super-heroes/xbox-one-20000826 Xbox One 9.0 Action Y 2013 10 22 17313 Great Dead Rising 3 /games/dead-rising-3/xbox-one-124306 Xbox One 8.3 Action N 2013 11 18 17317 Great Killer Instinct /games/killer-instinct-2013/xbox-one-20000538 Xbox One 8.4 Fighting N 2013 11 18 When filtering with multiple conditions, it’s important to put each condition in parentheses (), and separate them with a single ampersand &amp;. Pandas Plotting Now that we know how to filter, we can create plots to observe the review distribution for the Xbox One vs the review distribution for the PlayStation 4. This will help us figure out which console has better games. We can do this via a histogram, which will plot the frequencies for different score ranges. This will tell us which console has more highly reviewed games. We can make a histogram for each console using the pandas.DataFrame.plot method. This method utilizes matplotlib, the popular Python plotting library, under the hood to generate good-looking plots. The plot method defaults to drawing a line graph. We’ll need to pass in the keyword argument kind=&quot;hist&quot; to draw a histogram instead. In the below code, we: Call %matplotlib inline to set up plotting inside a Jupyter notebook. Filter reviews to only have data about the Xbox One. Plot the score column. reviews[&quot;platform&quot;].unique() array([&#39;PlayStation Vita&#39;, &#39;iPad&#39;, &#39;Xbox 360&#39;, &#39;PlayStation 3&#39;, &#39;Macintosh&#39;, &#39;PC&#39;, &#39;iPhone&#39;, &#39;Nintendo DS&#39;, &#39;Nintendo 3DS&#39;, &#39;Android&#39;, &#39;Wii&#39;, &#39;PlayStation 4&#39;, &#39;Wii U&#39;, &#39;Linux&#39;, &#39;PlayStation Portable&#39;, &#39;PlayStation&#39;, &#39;Nintendo 64&#39;, &#39;Saturn&#39;, &#39;Lynx&#39;, &#39;Game Boy&#39;, &#39;Game Boy Color&#39;, &#39;NeoGeo Pocket Color&#39;, &#39;Game.Com&#39;, &#39;Dreamcast&#39;, &#39;Dreamcast VMU&#39;, &#39;WonderSwan&#39;, &#39;Arcade&#39;, &#39;Nintendo 64DD&#39;, &#39;PlayStation 2&#39;, &#39;WonderSwan Color&#39;, &#39;Game Boy Advance&#39;, &#39;Xbox&#39;, &#39;GameCube&#39;, &#39;DVD / HD Video Game&#39;, &#39;Wireless&#39;, &#39;Pocket PC&#39;, &#39;N-Gage&#39;, &#39;NES&#39;, &#39;iPod&#39;, &#39;Genesis&#39;, &#39;TurboGrafx-16&#39;, &#39;Super NES&#39;, &#39;NeoGeo&#39;, &#39;Master System&#39;, &#39;Atari 5200&#39;, &#39;TurboGrafx-CD&#39;, &#39;Atari 2600&#39;, &#39;Sega 32X&#39;, &#39;Vectrex&#39;, &#39;Commodore 64/128&#39;, &#39;Sega CD&#39;, &#39;Nintendo DSi&#39;, &#39;Windows Phone&#39;, &#39;Web Games&#39;, &#39;Xbox One&#39;, &#39;Windows Surface&#39;, &#39;Ouya&#39;, &#39;New Nintendo 3DS&#39;, &#39;SteamOS&#39;], dtype=object) # enable display of chart inline %matplotlib inline # setup the filter platform_filter = reviews[&quot;platform&quot;] == &quot;Xbox One&quot; # select and plot reviews[platform_filter][&quot;score&quot;].plot(kind=&quot;hist&quot;) &lt;matplotlib.axes._subplots.AxesSubplot at 0x11db8fba8&gt; We can also do the same for the PS4: # setup the filter mask = reviews[&quot;platform&quot;].isin([&quot;Xbox One&quot;, &quot;PlayStation 4&quot;]) # select and plot reviews[mask][&quot;score&quot;].plot(kind=&quot;hist&quot;) &lt;matplotlib.axes._subplots.AxesSubplot at 0x11dcd6e80&gt; It appears from our histogram that the PlayStation 4 has many more highly rated games than the Xbox One. # plot all filtered_reviews[&quot;score&quot;].hist() &lt;matplotlib.axes._subplots.AxesSubplot at 0x11dc79be0&gt;",
    "url": "http://localhost:4000/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth/04.a%20-%20Pandas%20Data%20analysis%20Part%201.html",
    "relUrl": "/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth/04.a%20-%20Pandas%20Data%20analysis%20Part%201.html"
  },
  "34": {
    "id": "34",
    "title": "04.b - Dictionary Comprehensions",
    "content": "Python Dictionary Comprehensions Python Dictionary Comprehension Tutorial You’ll learn: What it is, why it is important and how it can serve as an alternative to for loops and lambda functions. How to add conditionals into dictionary comprehensions: you will work with if conditions, multiple if conditions and also if-else statements. What nested dictionary comprehension is, how you can use it and how you can potentially rewrite it with for loops. Dictionary comprehension is a method for transforming one dictionary into another dictionary. During this transformation, items within the original dictionary can be conditionally included in the new dictionary and each item can be transformed as needed. A good list comprehension can make your code more expressive and thus, easier to read. The key with creating comprehensions is to not let them get so complex that your head spins when you try to decipher what they are actually doing. Keeping the idea of “easy to read” alive. The way to do dictionary comprehension in Python is to be able to access the key objects and the value objects of a dictionary. dict1 = {&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3, &#39;d&#39;: 4} # Put all keys of `dict1` in a list and returns the list dict1.keys() dict_keys([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]) # Put all values saved in `dict1` in a list and returns the list dict1.values() dict_values([1, 2, 3, 4]) z = { &#39;x&#39;: 1, &#39;y&#39;: None, None: &#39;a&#39;} print(z) print(type(None)) {&#39;x&#39;: 1, &#39;y&#39;: None, None: &#39;a&#39;} &lt;class &#39;NoneType&#39;&gt; So, now that you know how to access all the keys and their values in a dictionary. You can also access each key-value pair within a dictionary using the items() method: dict1.items() dict_items([(&#39;a&#39;, 1), (&#39;b&#39;, 2), (&#39;c&#39;, 3), (&#39;d&#39;, 4)]) dict1 = {&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3, &#39;d&#39;: 4, &#39;e&#39;: 5} This is the general template you can follow for dictionary comprehension. This can serve as the basic and the most simple template which can get more and more complex as you add conditionalities to it. dict_variable = {key:value for (key,value) in dictonary.items()} # Double each value in the dictionary double_dict1 = {} for (k,v) in dict1.items(): double_dict1[k] = v*2 print(double_dict1) {&#39;a&#39;: 2, &#39;b&#39;: 4, &#39;c&#39;: 6, &#39;d&#39;: 8, &#39;e&#39;: 10} # Double each value in the dictionary double_dict1 = {k:v*2 for (k,v) in dict1.items()} print(double_dict1) {&#39;a&#39;: 2, &#39;b&#39;: 4, &#39;c&#39;: 6, &#39;d&#39;: 8, &#39;e&#39;: 10} # Double each value in the dictionary double_dict1 = {x[0]:x[1]*2 for x in dict1.items()} print(double_dict1) {&#39;a&#39;: 2, &#39;b&#39;: 4, &#39;c&#39;: 6, &#39;d&#39;: 8, &#39;e&#39;: 10} double_dict1 = {k:dict1[k]*2 for k in dict1.keys()} print(double_dict1) {&#39;a&#39;: 2, &#39;b&#39;: 4, &#39;c&#39;: 6, &#39;d&#39;: 8, &#39;e&#39;: 10} You can also make changes to the key values. For example, let’s create the same dictionary as above but also change the names of the key. dict1_keys = {k*3:v for (k,v) in dict1.items()} print(dict1_keys) {&#39;aaa&#39;: 1, &#39;bbb&#39;: 2, &#39;ccc&#39;: 3, &#39;ddd&#39;: 4, &#39;eee&#39;: 5} Why Use Dictionary Comprehension? Dictionary comprehension is a powerful concept and can be used to substitute for loops and lambda functions. However, not all for loop can be written as a dictionary comprehension but all dictionary comprehension can be written with a for loop. Consider the following problem, where you want to create a new dictionary where the key is a number divisible by 2 in a range of 0-10 and it’s value is the square of the number. Alternative to for loops For loops are used to repeat a certain operation or a block of instructions in a program for a given number of times. However, nested for loops (for loop inside another for loop) can get confusing and complex. Dictionary comprehensions are better in such situations and can simplify the readability and your understanding of the code. Let’s see how the same probem can be solved using a for loop and dictionary comprehension: numbers = range(10) new_dict_for = {} # Add values to `new_dict` using for loop for n in numbers: if n % 2 == 0: new_dict_for[n] = n**2 print(new_dict_for) {0: 0, 2: 4, 4: 16, 6: 36, 8: 64} # Use dictionary comprehension new_dict_comp = {n:n**2 for n in numbers if n % 2 == 0} print(new_dict_comp) {0: 0, 2: 4, 4: 16, 6: 36, 8: 64} Alternative to lambda functions Lambda functions are a way of creating small anonymous functions. They are functions without a name. These functions are throw-away functions, which are only needed where they have been created. Lambda functions are mainly used in combination with the functions filter(), map() and reduce(). Let’s look at the lambda function along with the map() function: # Initialize `fahrenheit` dictionary fahrenheit = {&#39;t1&#39;:-30, &#39;t2&#39;:-20, &#39;t3&#39;:-10, &#39;t4&#39;:0} #Get the corresponding `celsius` values celsius = map(lambda x: (float(5)/9)*(x-32), fahrenheit.values()) celsius = list(celsius) #Create the `celsius` dictionary celsius_dict = dict(zip(fahrenheit.keys(), celsius)) print(celsius_dict) {&#39;t1&#39;: -34.44444444444444, &#39;t2&#39;: -28.88888888888889, &#39;t3&#39;: -23.333333333333336, &#39;t4&#39;: -17.77777777777778} Now, let’s try to solve the same problem using dictionary comprehension: # Initialize the `fahrenheit` dictionary fahrenheit = {&#39;t1&#39;: -30,&#39;t2&#39;: -20,&#39;t3&#39;: -10,&#39;t4&#39;: 0} # Get the corresponding `celsius` values and create the new dictionary celsius = {k:(float(5)/9)*(v-32) for (k,v) in fahrenheit.items()} print(celsius_dict) {&#39;t1&#39;: -34.44444444444444, &#39;t2&#39;: -28.88888888888889, &#39;t3&#39;: -23.333333333333336, &#39;t4&#39;: -17.77777777777778} Adding Conditionals to Dictionary Comprehension You often need to add conditions to a solution while tackling problems. Let’s explore how you can add conditionals into dictionary comprehension to make it more powerful. If Condition Let’s suppose you need to create a new dictionary from a given dictionary but with items that are greater than 2. This means that you need to add a condition to the original template you saw above… dict1 = {&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3, &#39;d&#39;: 4, &#39;e&#39;: 5} # Check for items greater than 2 dict1_cond = {k:v for (k,v) in dict1.items() if v &gt; 2} print(dict1_cond) {&#39;c&#39;: 3, &#39;d&#39;: 4, &#39;e&#39;: 5} Multiple If Conditions In the problem above, what if you have to not only get the items greater than 2 but also need to check if they are multiples of 2 at the same time. dict1_doubleCond = {k:v for (k,v) in dict1.items() if v&gt;2 if v%2 == 0} print(dict1_doubleCond) {&#39;d&#39;: 4} dict1_doubleCond = {k:v for (k,v) in dict1.items() if v&gt;2 and v%2 == 0} print(dict1_doubleCond) {&#39;d&#39;: 4} dict1_doubleCond = {k:v for (k,v) in dict1.items() if v&gt;2 or v%2 == 0} print(dict1_doubleCond) {&#39;b&#39;: 2, &#39;c&#39;: 3, &#39;d&#39;: 4, &#39;e&#39;: 5} The solution to adding multiple conditionals is as easy as simply adding the conditions one after another in your comprehension. However, you need to be careful about what you are trying to do in the problem. Remember, that the consecutive if statements work as if they had and clauses between them. Lets see one more example with three conditionals: dict1 = {&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3, &#39;d&#39;: 4, &#39;e&#39;: 5, &#39;f&#39;:6} dict1_tripleCond = {k:v for (k,v) in dict1.items() if v&gt;2 if v%2 == 0 if v%3 == 0} print(dict1_tripleCond) {&#39;f&#39;: 6} In a for loop, this will correspond to: dict1_tripleCond = {} for (k,v) in dict1.items(): if (v&gt;=2 and v%2 == 0 and v%3 == 0): dict1_tripleCond[k] = v print(dict1_tripleCond) {&#39;f&#39;: 6} dict1_tripleCond = {} for (k,v) in dict1.items(): if v&gt;=2: if v%2 == 0: if v%3 == 0: dict1_tripleCond[k] = v print(dict1_tripleCond) {&#39;f&#39;: 6} If-Else Conditions Dealing with an if-else condition is also easy with dictionary comprehension. Check out the following example to see it for yourself: dict1 = {&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3, &#39;d&#39;: 4, &#39;e&#39;: 5, &#39;f&#39;:6} # Identify odd and even entries dict1_tripleCond = {k:(&#39;even&#39; if v%2==0 else &#39;odd&#39;) for (k,v) in dict1.items()} print(dict1_tripleCond) {&#39;a&#39;: &#39;odd&#39;, &#39;b&#39;: &#39;even&#39;, &#39;c&#39;: &#39;odd&#39;, &#39;d&#39;: &#39;even&#39;, &#39;e&#39;: &#39;odd&#39;, &#39;f&#39;: &#39;even&#39;} Nested Dictionary Comprehension Nesting is a programming concept where data is organized in layers, or where objects contain other similar objects. You must have often seen a nested ‘if’ structure, which is an if condition inside another if condition. Similarly, dictionaries can be nested and thus their comprehensions can be nested as well. Let’s see what this means: nested_dict = {&#39;first&#39;:{&#39;a&#39;:1}, &#39;second&#39;:{&#39;b&#39;:2}} float_dict = { outer_k: {inner_k:float(inner_v) for (inner_k, inner_v) in outer_v.items()} for (outer_k, outer_v) in nested_dict.items() } print(float_dict) {&#39;first&#39;: {&#39;a&#39;: 1.0}, &#39;second&#39;: {&#39;b&#39;: 2.0}} This is an example of a nested dictionary. The nested_dict is a dictionary with the keys: first and second, which hold dictionary objects in their values. The code works with the inner dictionary values and converts them to float and then combines the outer keys with the new float inner values into a new dictionary. The code also has a nested dictionary comprehension, which is dictionary comprehension inside another one. The dictionary comprehension when nested as you can see can get pretty hard to read as well as understand, which takes away the whole point of using comprehensions in the first place. As the structure of the dictionary you are working with gets complicated, the dictionary comprehension starts to get complicated as well. For such situations, you might be better off not using complicated comprehensions in your code. Note that you can rewrite the above code chunk also with a nested for loop: nested_dict = {&#39;first&#39;:{&#39;a&#39;:1}, &#39;second&#39;:{&#39;b&#39;:2}} for (outer_k, outer_v) in nested_dict.items(): for (inner_k, inner_v) in outer_v.items(): outer_v.update({inner_k: float(inner_v)}) nested_dict.update({outer_k:outer_v}) print(nested_dict) {&#39;first&#39;: {&#39;a&#39;: 1.0}, &#39;second&#39;: {&#39;b&#39;: 2.0}}",
    "url": "http://localhost:4000/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/04.b%20-%20Dictionary%20Comprehensions.html",
    "relUrl": "/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/04.b%20-%20Dictionary%20Comprehensions.html"
  },
  "35": {
    "id": "35",
    "title": "04.b - Pandas Data analysis Part 2",
    "content": "Source In this tutorial, we’ll dive into one of the most powerful aspects of pandas — its grouping and aggregation functionality. With this functionality, it’s dead simple to compute group summary statistics, discover patterns, and slice up your data in various ways. Since Thanksgiving was just last week, we’ll use a dataset on what Americans typically eat for Thanksgiving dinner as we explore the pandas library. You can download the dataset here. It contains 1058 online survey responses collected by FiveThirtyEight. Each survey respondent was asked questions about what they typically eat for Thanksgiving, along with some demographic questions, like their gender, income, and location. This dataset will allow us to discover regional and income-based patterns in what Americans eat for Thanksgiving dinner. As we explore the data and try to find patterns, we’ll be heavily using the grouping and aggregation functionality of pandas. Reading in and summarizing the data Our first step is to read in the data and do some preliminary exploration. This will help us figure out how we want to approach creating groups and finding patterns. As you may recall from part one of this tutorial, we can read in the data using the pandas.read_csv function. The data is stored using Latin-1 encoding, so we additionally need to specify the encoding keyword argument. If we don’t, pandas won’t be able to load in the data, and we’ll get an error: # disable warnings for lecture import warnings warnings.filterwarnings(&#39;ignore&#39;) import pandas as pd data = pd.read_csv(&quot;thanksgiving-2015-poll-data.csv&quot;, encoding=&quot;Latin-1&quot;) data.head() RespondentID Do you celebrate Thanksgiving? What is typically the main dish at your Thanksgiving dinner? What is typically the main dish at your Thanksgiving dinner? - Other (please specify) How is the main dish typically cooked? How is the main dish typically cooked? - Other (please specify) What kind of stuffing/dressing do you typically have? What kind of stuffing/dressing do you typically have? - Other (please specify) What type of cranberry saucedo you typically have? What type of cranberry saucedo you typically have? - Other (please specify) ... Have you ever tried to meet up with hometown friends on Thanksgiving night? Have you ever attended a &quot;Friendsgiving?&quot; Will you shop any Black Friday sales on Thanksgiving Day? Do you work in retail? Will you employer make you work on Black Friday? How would you describe where you live? Age What is your gender? How much total combined money did all members of your HOUSEHOLD earn last year? US Region 0 4337954960 Yes Turkey NaN Baked NaN Bread-based NaN None NaN ... Yes No No No NaN Suburban 18 - 29 Male $75,000 to $99,999 Middle Atlantic 1 4337951949 Yes Turkey NaN Baked NaN Bread-based NaN Other (please specify) Homemade cranberry gelatin ring ... No No Yes No NaN Rural 18 - 29 Female $50,000 to $74,999 East South Central 2 4337935621 Yes Turkey NaN Roasted NaN Rice-based NaN Homemade NaN ... Yes Yes Yes No NaN Suburban 18 - 29 Male $0 to $9,999 Mountain 3 4337933040 Yes Turkey NaN Baked NaN Bread-based NaN Homemade NaN ... Yes No No No NaN Urban 30 - 44 Male $200,000 and up Pacific 4 4337931983 Yes Tofurkey NaN Baked NaN Bread-based NaN Canned NaN ... Yes No No No NaN Urban 30 - 44 Male $100,000 to $124,999 Pacific 5 rows × 65 columns As you can see above, the data has 65 columns of mostly categorical data. For example, the first column appears to allow for Yes and No responses only. Let’s verify by using the pandas.Series.unique method to see what unique values are in the Do you celebrate Thanksgiving? column of data: # investigate respondent values data[&quot;Do you celebrate Thanksgiving?&quot;].unique() array([&#39;Yes&#39;, &#39;No&#39;], dtype=object) # investigate respondent values data[&quot;What is typically the main dish at your Thanksgiving dinner?&quot;].unique() array([&#39;Turkey&#39;, &#39;Tofurkey&#39;, &#39;Other (please specify)&#39;, nan, &#39;Ham/Pork&#39;, &#39;Turducken&#39;, &#39;Roast beef&#39;, &#39;Chicken&#39;, &quot;I don&#39;t know&quot;], dtype=object) We can also view all the column names to see all of the survey questions. We’ll truncate the output below to save you from having to scroll: data.columns[50:] Index([&#39;Which of these desserts do you typically have at Thanksgiving dinner? Please select all that apply. - Other (please specify).1&#39;, &#39;Do you typically pray before or after the Thanksgiving meal?&#39;, &#39;How far will you travel for Thanksgiving?&#39;, &#39;Will you watch any of the following programs on Thanksgiving? Please select all that apply. - Macy&#39;s Parade&#39;, &#39;What&#39;s the age cutoff at your &quot;kids&#39; table&quot; at Thanksgiving?&#39;, &#39;Have you ever tried to meet up with hometown friends on Thanksgiving night?&#39;, &#39;Have you ever attended a &quot;Friendsgiving?&quot;&#39;, &#39;Will you shop any Black Friday sales on Thanksgiving Day?&#39;, &#39;Do you work in retail?&#39;, &#39;Will you employer make you work on Black Friday?&#39;, &#39;How would you describe where you live?&#39;, &#39;Age&#39;, &#39;What is your gender?&#39;, &#39;How much total combined money did all members of your HOUSEHOLD earn last year?&#39;, &#39;US Region&#39;], dtype=&#39;object&#39;) Using this Thanksgiving survey data, we can answer quite a few interesting questions, like: Do people in Suburban areas eat more Tofurkey than people in Rural areas? Where do people go to Black Friday sales most often? Is there a correlation between praying on Thanksgiving and income? What income groups are most likely to have homemade cranberry sauce? In order to answer these questions and others, we’ll first need to become familiar with applying, grouping and aggregation in Pandas. Applying functions to Series in pandas There are times when we’re using pandas that we want to apply a function to every row or every column in the data. A good example is getting from the values in our What is your gender? column to numeric values. We’ll assign 0 to Male, and 1 to Female. Before we dive into transforming the values, let’s confirm that the values in the column are either Male or Female. We can use the pandas.Series.value_counts method to help us with this. We’ll pass the dropna=False keyword argument to also count missing values: # investigate respondent values data[&quot;What is your gender?&quot;].unique() array([&#39;Male&#39;, &#39;Female&#39;, nan], dtype=object) # get respondent counts per response data[&quot;What is your gender?&quot;].value_counts(dropna=False) Female 544 Male 481 NaN 33 Name: What is your gender?, dtype: int64 As you can see, not all of the values are Male or Female. We’ll preserve any missing values in the final output when we transform our column. Here’s a diagram of the input and outputs we need: Source: https://www.dataquest.io/blog/content/images/2017/12/ditaa_diagram_1-2.png We’ll need to apply a custom function to each value in the What is your gender? column to get the output we want. Here’s a function that will do the transformation we want: # print the integer representation of True and False print(int(True), int(False)) 1 0 import math def gender_code(gender_val): # check to see if the gender iss a float or not specified if isinstance(gender_val, float) and math.isnan(gender_val): # if so return the float or nan value return gender_val # otherwise return 1 for female and 0 for male return int(gender_val.lower().strip() == &quot;female&quot;) In order to apply this function to each item in the What is your gender? column, we could either write a for loop, and loop across each element in the column, or we could use the pandas.Series.apply method. This method will take a function as input, then return a new pandas Series that contains the results of applying the function to each item in the Series. We can assign the result back to a column in the data DataFrame, then verify the results using value_counts: # calculate a new gender code column where 1 represents female and 0 represents male gender_codes = data[&quot;What is your gender?&quot;].apply(gender_code) print(type(gender_codes), gender_codes.head()) &lt;class &#39;pandas.core.series.Series&#39;&gt; 0 0.0 1 1.0 2 0.0 3 0.0 4 0.0 Name: What is your gender?, dtype: float64 # add a new column containing the series gender_codes data[&quot;gender&quot;] = gender_codes # display the value counts data[&quot;gender&quot;].value_counts(dropna=False) 1.0 544 0.0 481 NaN 33 Name: gender, dtype: int64 # check the data type of the new column data[&quot;gender&quot;].dtype dtype(&#39;float64&#39;) # change the datatype to categorical data[&quot;gender&quot;] = data[&quot;gender&quot;].astype(&#39;category&#39;) # check the datatype data[&quot;gender&quot;].dtype CategoricalDtype(categories=[0.0, 1.0], ordered=False) # print the top 5 values data[&quot;gender&quot;].head() 0 0.0 1 1.0 2 0.0 3 0.0 4 0.0 Name: gender, dtype: category Categories (2, float64): [0.0, 1.0] Applying functions to DataFrames in pandas We can use the apply method on DataFrames as well as Series. When we use the pandas.DataFrame.apply method, an entire row or column will be passed into the function we specify. By default, apply will work across each column in the DataFrame. If we pass the axis=1 keyword argument, it will work across each row. In the below example, we check the data type of each column in data using a lambda function. We also call the head method on the result to avoid having too much output: # create a method to return the datatype of a row def get_type(row): return row.dtype # apply the method to all rows in the dataframe data.apply(get_type).head() RespondentID int64 Do you celebrate Thanksgiving? object What is typically the main dish at your Thanksgiving dinner? object What is typically the main dish at your Thanksgiving dinner? - Other (please specify) object How is the main dish typically cooked? object dtype: object # return data types with a lambda instead of a function data.apply(lambda row: row.dtype).head() RespondentID int64 Do you celebrate Thanksgiving? object What is typically the main dish at your Thanksgiving dinner? object What is typically the main dish at your Thanksgiving dinner? - Other (please specify) object How is the main dish typically cooked? object dtype: object Using the apply method to clean up income We can now use what we know about the apply method to clean up the How much total combined money did all members of your HOUSEHOLD earn last year? column. Cleaning up the income column will allow us to go from string values to numeric values. First, let’s see all the unique values that are in the How much total combined money did all members of your HOUSEHOLD earn last year? # specify the column by name column_name = &quot;How much total combined money did all members of your HOUSEHOLD earn last year?&quot; # get value counts for the specified column data[column_name].value_counts(dropna=False) $25,000 to $49,999 180 Prefer not to answer 136 $50,000 to $74,999 135 $75,000 to $99,999 133 $100,000 to $124,999 111 $200,000 and up 80 $10,000 to $24,999 68 $0 to $9,999 66 $125,000 to $149,999 49 $150,000 to $174,999 40 NaN 33 $175,000 to $199,999 27 Name: How much total combined money did all members of your HOUSEHOLD earn last year?, dtype: int64 Looking at this, there are 4 different patterns for the values in the column: Pattern Example Notes X to Y $25,000 to $49,999 We can convert this to a numeric value by extracting the numbers and averaging them. NaN   We’ll preserve NaN values, and not convert them at all. X and up $200,000 and up We can convert this to a numeric value by extracting the number. Prefer not to answer   We’ll turn this into an NaN value. Here is how we want the transformations to work: Source: https://www.dataquest.io/blog/content/images/2017/12/ditaa_diagram_2-1.png We can write a function that covers all of these cases. In the below function, we: Take a string called value as input. Check to see if value is $200,000 and up, and return 200000 if so. Check if value is Prefer not to answer, and return NaN if so. Check if value is NaN, and return NaN if so. Clean up value by removing any dollar signs or commas. Split the string to extract the incomes, then average them. import numpy as np def clean_income(value): if value == &quot;$200,000 and up&quot;: return 200000 elif value == &quot;Prefer not to answer&quot;: return np.nan elif isinstance(value, float) and math.isnan(value): return np.nan # remove commas and $ with empty spaces value = value.replace(&quot;,&quot;, &quot;&quot;).replace(&quot;$&quot;, &quot;&quot;) # split high and low income ranges income_low, income_high = value.split(&quot; to &quot;) # return the average between the ranges return (int(income_high) + int(income_low)) / 2 After creating the function, we can apply it to the How much total combined money did all members of your HOUSEHOLD earn last year? column: column_name = &quot;How much total combined money did all members of your HOUSEHOLD earn last year?&quot; data[&quot;income&quot;] = data[column_name].apply(clean_income) data[&quot;income&quot;].head() 0 87499.5 1 62499.5 2 4999.5 3 200000.0 4 112499.5 Name: income, dtype: float64 Grouping data with pandas Now that we’ve covered applying functions, we can move on to grouping data using Pandas. When performing data analysis, it’s often useful to explore only a subset of the data. For example, what if we want to compare income between people who tend to eat homemade cranberry sauce for Thanksgiving vs people who eat canned cranberry sauce? First, let’s see what the unique values in the column are: data[&quot;What type of cranberry saucedo you typically have?&quot;].value_counts() Canned 502 Homemade 301 None 146 Other (please specify) 25 Name: What type of cranberry saucedo you typically have?, dtype: int64 We can now filter data to get two DataFrames that only contain rows where the What type of cranberry saucedo you typically have? is Canned or Homemade, respectively: column_name = &quot;What type of cranberry saucedo you typically have?&quot; homemade_mask = data[column_name] == &quot;Homemade&quot; print(homemade_mask.head()) homemade = data[homemade_mask] 0 False 1 False 2 True 3 True 4 False Name: What type of cranberry saucedo you typically have?, dtype: bool canned = data[data[column_name] == &quot;Canned&quot;] Finally, we can use the pandas.Series.mean method to find the average income in homemade and canned: print(homemade[&quot;income&quot;].mean()) print(canned[&quot;income&quot;].mean()) 94878.1072874494 83823.40340909091 We get our answer, but it took more lines of code than it should have. What if we now want to compute the average income for people who didn’t have cranberry sauce? An easier way to find groupwise summary statistics with pandas is to use the pandas.DataFrame.groupby method. This method will split a DataFrame into groups based on a column or set of columns. We’ll then be able to perform computations on each group. Here’s how splitting data based on the What type of cranberry saucedo you typically have? column would look: Source: https://www.dataquest.io/blog/content/images/2017/12/ditaa_diagram_3-1.png Note how each resulting group only has a single unique value in the What type of cranberry saucedo you typically have? column. One group is created for each unique value in the column we choose to group by. Let’s create groups from the What type of cranberry saucedo you typically have? column: column_name = &quot;What type of cranberry saucedo you typically have?&quot; grouped = data.groupby(column_name) grouped &lt;pandas.core.groupby.groupby.DataFrameGroupBy object at 0x11834ce48&gt; As you can see above, the groupby method returns a DataFrameGroupBy object. We can call the pandas.GroupBy.groups method to see what value for the What type of cranberry saucedo you typically have? column is in each group: grouped.groups {&#39;Canned&#39;: Int64Index([ 4, 6, 8, 11, 12, 15, 18, 19, 26, 27, ... 1040, 1041, 1042, 1044, 1045, 1046, 1047, 1051, 1054, 1057], dtype=&#39;int64&#39;, length=502), &#39;Homemade&#39;: Int64Index([ 2, 3, 5, 7, 13, 14, 16, 20, 21, 23, ... 1016, 1017, 1025, 1027, 1030, 1034, 1048, 1049, 1053, 1056], dtype=&#39;int64&#39;, length=301), &#39;None&#39;: Int64Index([ 0, 17, 24, 29, 34, 36, 40, 47, 49, 51, ... 980, 981, 997, 1015, 1018, 1031, 1037, 1043, 1050, 1055], dtype=&#39;int64&#39;, length=146), &#39;Other (please specify)&#39;: Int64Index([ 1, 9, 154, 216, 221, 233, 249, 265, 301, 336, 380, 435, 444, 447, 513, 550, 749, 750, 784, 807, 860, 872, 905, 1000, 1007], dtype=&#39;int64&#39;)} We can call the pandas.GroupBy.size method to see how many rows are in each group. This is equivalent to the value_counts method on a Series: grouped.size() What type of cranberry saucedo you typically have? Canned 502 Homemade 301 None 146 Other (please specify) 25 dtype: int64 We can also use a loop to manually iterate through the groups: for name, group in grouped: print(name) print(&#39; t&#39;, group.shape) print(&#39; t&#39;, type(group)) Canned (502, 67) &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Homemade (301, 67) &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; None (146, 67) &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Other (please specify) (25, 67) &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; As you can see above, each group is a DataFrame, and you can use any normal DataFrame methods on it. We can also extract a single column from a group. This will allow us to perform further computations just on that specific column: grouped[&quot;income&quot;] &lt;pandas.core.groupby.groupby.SeriesGroupBy object at 0x11909f710&gt; As you can see above, this gives us a SeriesGroupBy object. We can then call the normal methods we can call on a DataFrameGroupBy object: grouped[&quot;income&quot;].size() What type of cranberry saucedo you typically have? Canned 502 Homemade 301 None 146 Other (please specify) 25 Name: income, dtype: int64 Aggregating values in groups If all we could do was split a DataFrame into groups, it wouldn’t be of much use. The real power of groups is in the computations we can do after creating groups. We do these computations through the pandas.GroupBy.aggregate method, which we can abbreviate as agg. This method allows us to perform the same computation on every group. For example, we could find the average income for people who served each type of cranberry sauce for Thanksgiving (Canned, Homemade, None, etc). In the below code, we: Extract just the income column from grouped, so we don’t find the average of every column. Call the agg method with np.mean as input. This will compute the mean for each group, then combine the results from each group. grouped[&quot;income&quot;].agg(np.mean) What type of cranberry saucedo you typically have? Canned 83823.403409 Homemade 94878.107287 None 78886.084034 Other (please specify) 86629.978261 Name: income, dtype: float64 grouped[&quot;income&quot;].agg(np.std) What type of cranberry saucedo you typically have? Canned 55835.478014 Homemade 62251.937645 None 54562.750866 Other (please specify) 54175.781001 Name: income, dtype: float64 grouped[&quot;income&quot;].agg(np.median) What type of cranberry saucedo you typically have? Canned 62499.5 Homemade 87499.5 None 62499.5 Other (please specify) 87499.5 Name: income, dtype: float64 grouped[&quot;income&quot;].agg([np.mean, np.std, np.median]) mean std median What type of cranberry saucedo you typically have? Canned 83823.403409 55835.478014 62499.5 Homemade 94878.107287 62251.937645 87499.5 None 78886.084034 54562.750866 62499.5 Other (please specify) 86629.978261 54175.781001 87499.5 If we left out only selecting the income column, here’s what we’d get: grouped.agg(np.mean) RespondentID income What type of cranberry saucedo you typically have? Canned 4.336699e+09 83823.403409 Homemade 4.336792e+09 94878.107287 None 4.336765e+09 78886.084034 Other (please specify) 4.336763e+09 86629.978261 The above code will find the mean for each group for every column in data. However, most columns are string columns, not integer or float columns, so Pandas didn’t process them, since calling np.mean on them raised an error. Plotting the results of aggregation We can make a plot using the results of our agg method. This will create a bar chart that shows the average income of each category. %matplotlib inline sauce = grouped.agg(np.mean) sauce[&quot;income&quot;].plot(kind=&quot;bar&quot;) &lt;matplotlib.axes._subplots.AxesSubplot at 0x1187d0f98&gt; Aggregating with multiple columns We can call groupby with multiple columns as input to get more granular groups. If we use the What type of cranberry saucedo you typically have? and What is typically the main dish at your Thanksgiving dinner? columns as input, we’ll be able to find the average income of people who eat Homemade cranberry sauce and Tofurkey, for example: grouped = data.groupby( [&quot;What type of cranberry saucedo you typically have?&quot;, &quot;What is typically the main dish at your Thanksgiving dinner?&quot;]) grouped.agg(np.mean) RespondentID income What type of cranberry saucedo you typically have? What is typically the main dish at your Thanksgiving dinner? Canned Chicken 4.336354e+09 80999.600000 Ham/Pork 4.336757e+09 77499.535714 I don&#39;t know 4.335987e+09 4999.500000 Other (please specify) 4.336682e+09 53213.785714 Roast beef 4.336254e+09 25499.500000 Tofurkey 4.337157e+09 100713.857143 Turkey 4.336705e+09 85242.682045 Homemade Chicken 4.336540e+09 19999.500000 Ham/Pork 4.337253e+09 96874.625000 I don&#39;t know 4.336084e+09 NaN Other (please specify) 4.336863e+09 55356.642857 Roast beef 4.336174e+09 33749.500000 Tofurkey 4.336790e+09 57916.166667 Turducken 4.337475e+09 200000.000000 Turkey 4.336791e+09 97690.147982 None Chicken 4.336151e+09 11249.500000 Ham/Pork 4.336680e+09 61249.500000 I don&#39;t know 4.336412e+09 33749.500000 Other (please specify) 4.336688e+09 119106.678571 Roast beef 4.337424e+09 162499.500000 Tofurkey 4.336950e+09 112499.500000 Turducken 4.336739e+09 NaN Turkey 4.336784e+09 74606.275281 Other (please specify) Ham/Pork 4.336465e+09 87499.500000 Other (please specify) 4.337335e+09 124999.666667 Tofurkey 4.336122e+09 37499.500000 Turkey 4.336724e+09 82916.194444 As you can see above, we get a nice table that shows us the mean of each column for each group. This enables us to find some interesting patterns, such as: People who have Turducken and Homemade cranberry sauce seem to have high household incomes. People who eat Canned cranberry sauce tend to have lower incomes, but those who also have Roast Beef have the lowest incomes. It looks like there’s one person who has Canned cranberry sauce and doesn’t know what type of main dish he’s having. Aggregating with multiple functions We can also perform aggregation with multiple functions. This enables us to calculate the mean and standard deviation of a group, for example. In the below code, we find the sum, standard deviation, and mean of each group in the income column: grouped[&quot;income&quot;].agg([np.mean, np.sum, np.std]).head(10) mean sum std What type of cranberry saucedo you typically have? What is typically the main dish at your Thanksgiving dinner? Canned Chicken 80999.600000 404998.0 75779.481062 Ham/Pork 77499.535714 1084993.5 56645.063944 I don&#39;t know 4999.500000 4999.5 NaN Other (please specify) 53213.785714 372496.5 29780.946290 Roast beef 25499.500000 127497.5 24584.039538 Tofurkey 100713.857143 704997.0 61351.484439 Turkey 85242.682045 34182315.5 55687.436102 Homemade Chicken 19999.500000 59998.5 16393.596311 Ham/Pork 96874.625000 387498.5 77308.452805 I don&#39;t know NaN 0.0 NaN Using apply on groups One of the limitations of aggregation is that each function has to return a single number. While we can perform computations like finding the mean, we can’t for example, call value_counts to get the exact count of a category. We can do this using the pandas.GroupBy.apply method. This method will apply a function to each group, then combine the results. In the below code, we’ll apply value_counts to find the number of people who live in each area type (Rural, Suburban, etc) who eat different kinds of main dishes for Thanksgiving: grouped = data.groupby(&quot;How would you describe where you live?&quot;)[&quot;What is typically the main dish at your Thanksgiving dinner?&quot;] grouped.apply(lambda x: x.value_counts()) How would you describe where you live? Rural Turkey 189 Other (please specify) 9 Ham/Pork 7 Tofurkey 3 I don&#39;t know 3 Turducken 2 Chicken 2 Roast beef 1 Suburban Turkey 449 Ham/Pork 17 Other (please specify) 13 Tofurkey 9 Chicken 3 Roast beef 3 Turducken 1 I don&#39;t know 1 Urban Turkey 198 Other (please specify) 13 Tofurkey 8 Chicken 7 Roast beef 6 Ham/Pork 4 Name: What is typically the main dish at your Thanksgiving dinner?, dtype: int64 The above table shows us that people who live in different types of areas eat different Thanksgiving main dishes at about the same rate.",
    "url": "http://localhost:4000/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth/04.b%20-%20Pandas%20Data%20analysis%20Part%202.html",
    "relUrl": "/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth/04.b%20-%20Pandas%20Data%20analysis%20Part%202.html"
  },
  "36": {
    "id": "36",
    "title": "05 - Getting Data from Web APIs",
    "content": "Python API tutorial - An Introduction to using APIs source Application Program Interfaces, or APIs, are commonly used to retrieve data from remote websites. Sites like Reddit, Twitter, and Facebook all offer certain data through their APIs. To use an API, you make a request to a remote web server, and retrieve the data you need. But why use an API instead of a static dataset you can download? APIs are useful in the following cases: The data is changing quickly. An example of this is stock price data. It doesn’t really make sense to regenerate a dataset and download it every minute – this will take a lot of bandwidth, and be pretty slow. You want a small piece of a much larger set of data. Reddit comments are one example. What if you want to just pull your own comments on Reddit? It doesn’t make much sense to download the entire Reddit database, then filter just your own comments. There is repeated computation involved. Spotify has an API that can tell you the genre of a piece of music. You could theoretically create your own classifier, and use it to categorize music, but you’ll never have as much data as Spotify does. In cases like the ones above, an API is the right solution. In this blog post, we’ll be querying a simple API to retrieve data about the International Space Station (ISS). Using an API will save us time and effort over doing all the computation ourselves. API Requests APIs are hosted on web servers. When you type www.google.com in your browser’s address bar, your computer is actually asking the www.google.com server for a webpage, which it then returns to your browser. APIs work much the same way, except instead of your web browser asking for a webpage, your program asks for data. This data is usually returned in JSON format (for more on this, checkout our tutorial on working with JSON data). In order to get the data, we make a request to a webserver. The server then replies with our data. In Python, we’ll use the requests library to do this. In this Python API tutorial we’ll be using Python 3.4 for all of our examples. Type of requests There are many different types of requests. The most commonly used one, a GET request, is used to retrieve data. We can use a simple GET request to retrieve information from the OpenNotify API. OpenNotify has several API endpoints. An endpoint is a server route that is used to retrieve different data from the API. For example, the /comments endpoint on the Reddit API might retrieve information about comments, whereas the /users endpoint might retrieve data about users. To access them, you would add the endpoint to the base url of the API. The first endpoint we’ll look at on OpenNotify is the iss-now.json endpoint. This endpoint gets the current latitude and longitude of the International Space Station. As you can see, retrieving this data isn’t a great fit for a dataset, because it involves some calculation on the server, and changes quickly. You can see a listing of all the endpoints on OpenNotify here. The base url for the OpenNotify API is http://api.open-notify.org, so we’ll add this to the beginning of all of our endpoints. import requests # Make a get request to get the latest position of the international space station from the opennotify api. response = requests.get(&quot;http://api.open-notify.org/iss-now.json&quot;) # Print the status code of the response. print(response.status_code) print(response.content) 200 b&#39;{&quot;message&quot;: &quot;success&quot;, &quot;iss_position&quot;: {&quot;longitude&quot;: &quot;1.1366&quot;, &quot;latitude&quot;: &quot;-46.3248&quot;}, &quot;timestamp&quot;: 1572553589}&#39; Status codes The request we just made had a status code of 200. Status codes are returned with every request that is made to a web server. Status codes indicate information about what happened with a request. Here are some codes that are relevant to GET requests: 200 – everything went okay, and the result has been returned (if any) 301 – the server is redirecting you to a different endpoint. This can happen when a company switches domain names, or an endpoint name is changed. 401 – the server thinks you’re not authenticated. This happens when you don’t send the right credentials to access an API (we’ll talk about authentication in a later post). 400 – the server thinks you made a bad request. This can happen when you don’t send along the right data, among other things. 403 – the resource you’re trying to access is forbidden – you don’t have the right permissions to see it. 404 – the resource you tried to access wasn’t found on the server. We’ll now make a GET request to http://api.open-notify.org/iss-pass, an endpoint that doesn’t exist, per the API documentation. response = requests.get(&quot;http://api.open-notify.org/iss-pass&quot;) print(response.status_code) 404 Hitting the right endpoint iss-pass wasn’t a valid endpoint, so we got a 404 status code in response. We forgot to add .json at the end, as the API documentation states. We’ll now make a GET request to http://api.open-notify.org/iss-pass.json. response = requests.get(&quot;http://api.open-notify.org/iss-pass.json&quot;) print(response.status_code) 400 Query parameters You’ll see that in the last example, we got a 400 status code, which indicates a bad request. If you look at the documentation for the OpenNotify API, we see that the ISS Pass endpoint requires two parameters. The ISS Pass endpoint returns when the ISS will next pass over a given location on earth. In order to compute this, we need to pass the coordinates of the location to the API. We do this by passing two parameters – latitude and longitude. We can do this by adding an optional keyword argument, params, to our request. In this case, there are two parameters we need to pass: lat – The latitude of the location we want. lon – The longitude of the location we want. We can make a dictionary with these parameters, and then pass them into the requests.get function. We can also do the same thing directly by adding the query parameters to the url, like this: http://api.open-notify.org/iss-pass.json?lat=40.71&amp;lon=-74. It’s almost always preferable to setup the parameters as a dictionary, because requests takes care of some things that come up, like properly formatting the query parameters. We’ll make a request using the coordinates of New York City, and see what response we get. # Set up the parameters we want to pass to the API. # This is the latitude and longitude of New York City. parameters = {&quot;lat&quot;: 40.71, &quot;lon&quot;: -74} # Make a get request with the parameters. response = requests.get(&quot;http://api.open-notify.org/iss-pass.json&quot;, params=parameters) # response = requests.get(&quot;http://api.open-notify.org/iss-pass.json?lat={0}&amp;lon={1}&quot;.format(parameters[&#39;lat&#39;], parameters[&#39;lon&#39;])) # Print the content of the response (the data the server returned) print(response.json()) # This gets the same data as the command above # response = requests.get(&quot;http://api.open-notify.org/iss-pass.json?lat=40.71&amp;lon=-74&quot;) # print(response.content) {&#39;message&#39;: &#39;success&#39;, &#39;request&#39;: {&#39;altitude&#39;: 100, &#39;datetime&#39;: 1572551178, &#39;latitude&#39;: 40.71, &#39;longitude&#39;: -74.0, &#39;passes&#39;: 5}, &#39;response&#39;: [{&#39;duration&#39;: 504, &#39;risetime&#39;: 1572588456}, {&#39;duration&#39;: 655, &#39;risetime&#39;: 1572594154}, {&#39;duration&#39;: 606, &#39;risetime&#39;: 1572600003}, {&#39;duration&#39;: 559, &#39;risetime&#39;: 1572605889}, {&#39;duration&#39;: 613, &#39;risetime&#39;: 1572611722}]} Working with JSON data You may have noticed that the content of the response earlier was a string. Although it was shown as a bytes object, we can easily convert the content to a string using response.content.decode(&quot;utf-8&quot;). Strings are the way that we pass information back and forth to APIs, but it’s hard to get the information we want out of them. How do we know how to decode the string that we get back and work with it in Python? How do we figure out the altitude of the ISS from the string response? Luckily, there’s a format called JavaScript Object Notation (JSON). JSON is a way to encode data structures like lists and dictionaries to strings that ensures that they are easily readable by machines. JSON is the primary format in which data is passed back and forth to APIs, and most API servers will send their responses in JSON format. Python has great JSON support, with the json package. The json package is part of the standard library, so we don’t have to install anything to use it. We can both convert lists and dictionaries to JSON, and convert strings to lists and dictionaries. In the case of our ISS Pass data, it is a dictionary encoded to a string in JSON format. The json library has two main methods: dumps – Takes in a Python object, and converts it to a string. loads – Takes a JSON string, and converts it to a Python object. # Make a list of fast food chains. best_food_chains = [&quot;Taco Bell&quot;, &quot;Shake Shack&quot;, &quot;Chipotle&quot;] # This is a list. print(type(best_food_chains)) &lt;class &#39;list&#39;&gt; # Import the json library import json # Use json.dumps to convert best_food_chains to a string. best_food_chains_string = json.dumps(best_food_chains) print(&#39;***&#39;, best_food_chains_string) *** [&quot;Taco Bell&quot;, &quot;Shake Shack&quot;, &quot;Chipotle&quot;] # We&#39;ve successfully converted our list to a string. print(type(best_food_chains_string)) &lt;class &#39;str&#39;&gt; # Convert best_food_chains_string back into a list print(type(json.loads(best_food_chains_string))) &lt;class &#39;list&#39;&gt; # Make a dictionary fast_food_franchise = { &quot;Subway&quot;: 24722, &quot;McDonalds&quot;: 14098, &quot;Starbucks&quot;: 10821, &quot;Pizza Hut&quot;: 7600 } # We can also dump a dictionary to a string and load it. fast_food_franchise_string = json.dumps(fast_food_franchise) print(type(fast_food_franchise_string)) &lt;class &#39;str&#39;&gt; Getting JSON from an API request You can get the content of a response as a python object by using the .json() method on the response. # Make the same request we did earlier, but with the coordinates of San Francisco instead. parameters = {&quot;lat&quot;: 37.78, &quot;lon&quot;: -122.41} response = requests.get(&quot;http://api.open-notify.org/iss-pass.json&quot;, params=parameters) print(type(response.content)) &lt;class &#39;bytes&#39;&gt; # Get the response data as a python object. Verify that it&#39;s a dictionary. data = response.json() print(type(data)) print(data) print(&#39;message is &#39;, data[&#39;message&#39;]) print(&#39;altitude is &#39;, data[&#39;request&#39;][&#39;altitude&#39;]) &lt;class &#39;dict&#39;&gt; {&#39;message&#39;: &#39;success&#39;, &#39;request&#39;: {&#39;altitude&#39;: 100, &#39;datetime&#39;: 1572553593, &#39;latitude&#39;: 37.78, &#39;longitude&#39;: -122.41, &#39;passes&#39;: 5}, &#39;response&#39;: [{&#39;duration&#39;: 529, &#39;risetime&#39;: 1572599536}, {&#39;duration&#39;: 654, &#39;risetime&#39;: 1572605252}, {&#39;duration&#39;: 567, &#39;risetime&#39;: 1572611131}, {&#39;duration&#39;: 487, &#39;risetime&#39;: 1572617049}, {&#39;duration&#39;: 567, &#39;risetime&#39;: 1572622888}]} message is success altitude is 100 Content type The server doesn’t just send a status code and the data when it generates a response. It also sends metadata containing information on how the data was generated and how to decode it. This is stored in the response headers. In Python, we can access this with the headers property of a response object. The headers will be shown as a dictionary. Within the headers, content-type is the most important key for now. It tells us the format of the response, and how to decode it. For the OpenNotify API, the format is JSON, which is why we could decode it with the json package earlier. # Headers is a dictionary print(response.headers) # Get the content-type from the dictionary. print(response.headers[&quot;content-type&quot;]) {&#39;Server&#39;: &#39;nginx/1.10.3&#39;, &#39;Date&#39;: &#39;Thu, 31 Oct 2019 20:26:33 GMT&#39;, &#39;Content-Type&#39;: &#39;application/json&#39;, &#39;Content-Length&#39;: &#39;521&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;, &#39;Via&#39;: &#39;1.1 vegur&#39;} application/json Finding the number of people in space OpenNotify has one more API endpoint, astros.json. It tells you how many people are currently in space. The format of the responses can be found here. # Get the response from the API endpoint. response = requests.get(&quot;http://api.open-notify.org/astros.json&quot;) data = response.json() # people are currently in space. print(data[&quot;number&quot;]) print(data) 6 {&#39;people&#39;: [{&#39;name&#39;: &#39;Christina Koch&#39;, &#39;craft&#39;: &#39;ISS&#39;}, {&#39;name&#39;: &#39;Alexander Skvortsov&#39;, &#39;craft&#39;: &#39;ISS&#39;}, {&#39;name&#39;: &#39;Luca Parmitano&#39;, &#39;craft&#39;: &#39;ISS&#39;}, {&#39;name&#39;: &#39;Andrew Morgan&#39;, &#39;craft&#39;: &#39;ISS&#39;}, {&#39;name&#39;: &#39;Oleg Skripochka&#39;, &#39;craft&#39;: &#39;ISS&#39;}, {&#39;name&#39;: &#39;Jessica Meir&#39;, &#39;craft&#39;: &#39;ISS&#39;}], &#39;number&#39;: 6, &#39;message&#39;: &#39;success&#39;}",
    "url": "http://localhost:4000/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/05%20-%20Getting%20Data%20from%20Web%20APIs.html",
    "relUrl": "/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests/05%20-%20Getting%20Data%20from%20Web%20APIs.html"
  },
  "37": {
    "id": "37",
    "title": "05 - Python Generators",
    "content": "Python Generators Source todo : add content",
    "url": "http://localhost:4000/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/05%20-%20Python%20Generators.html",
    "relUrl": "/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/05%20-%20Python%20Generators.html"
  },
  "38": {
    "id": "38",
    "title": "05 - Start a process in Python",
    "content": "Start a process in Python Start a process in Python Sometimes you might want to spawn a process from python and interact with the data. You might use a process to generate some files that your python application will read, or read the output of the process within your application. Doing so is relatively simple in python using the subprocess library,. subprocess.Popen You can start a process in Python using the Popen function call. Open a pipe to or from command. The return value is an open file object connected to the pipe, which can be read or written depending on whether mode is ‘r’ (default) or ‘w’. from subprocess import Popen, PIPE process = Popen([&#39;cat&#39;, &#39;scores.csv&#39;], stdout=PIPE, stderr=PIPE) stdout, stderr = process.communicate() print(stdout.decode(&#39;utf-8&#39;)) date,home_team,home_score,away_team,away_score 2019-05-01,Pirates,0,Cubs,10 2019-05-15,Reds,7,Pirates,0 The process.communicate() call reads input and output from the process. stdout is the process output. stderr will be written only if an error occurs. If you want to wait for the program to finish you can call Popen.wait(). from subprocess import Popen, PIPE process = Popen([&#39;cat&#39;, &#39;scores.csv&#39;], stdout=PIPE, stderr=PIPE) stdout, stderr = process.communicate() status = process.wait() print(stdout.decode(&#39;utf-8&#39;)) date,home_team,home_score,away_team,away_score 2019-05-01,Pirates,0,Cubs,10 2019-05-15,Reds,7,Pirates,0 subprocess.call Subprocess has a method call() which can be used to start a program. This is basically just like the Popen class and takes all of the same arguments, but it simply wait until the command completes and gives us the return code. import subprocess subprocess.call([&#39;ls&#39;,&#39;-l&#39;]) 0 total 181 drwxr-xr-x 2 root root 4096 Mar 3 2012 bin drwxr-xr-x 4 root root 1024 Oct 26 2012 boot The command line arguments are passed as a list of strings, which avoids the need for escaping quotes or other special characters that might be interpreted by the shell. subprocess.check_call() The check_call() function works like call() except that the exit code is checked, and if it indicates an error happened then a CalledProcessError exception is raised. import subprocess subprocess.check_call([&#39;false&#39;]) CalledProcessError Traceback (most recent call last) &lt;ipython-input-5-436d6a2ac26e&gt; in &lt;module&gt;() 1 import subprocess -&gt; 2 subprocess.check_call([&#39;false&#39;]) ~/anaconda/lib/python3.6/subprocess.py in check_call(*popenargs, **kwargs) 289 if cmd is None: 290 cmd = popenargs[0] --&gt; 291 raise CalledProcessError(retcode, cmd) 292 return 0 293 CalledProcessError: Command &#39;[&#39;false&#39;]&#39; returned non-zero exit status 1. subprocess.check_output() The standard input and output channels for the process started by call() are bound to the parent’s input and output. That means the calling program cannot capture the output of the command. To capture the output, we can use check_output() for later processing. import subprocess output = subprocess.check_output([&#39;ls&#39;,&#39;-l&#39;]) print(output.decode(&#39;utf-8&#39;)) total 488 -rw-r--r-- 1 kolobj staff 2821 Mar 19 13:04 00 - Anaconda &amp; PyCharm Setup.ipynb -rw-r--r-- 1 kolobj staff 1724 Mar 23 09:17 00 - Anaconda &amp; PyCharm Setup.md -rw-r--r-- 1 kolobj staff 8084 Mar 20 19:08 01.a - Terminal Application.ipynb -rw-r--r-- 1 kolobj staff 4651 Mar 23 09:17 01.a - Terminal Application.md -rw-r--r-- 1 kolobj staff 10913 Mar 20 19:47 01.b - Argparse.ipynb -rw-r--r-- 1 kolobj staff 5670 Mar 23 09:17 01.b - Argparse.md -rw-r--r-- 1 kolobj staff 16220 Mar 20 20:04 02 - Generating Synthetic Data.ipynb -rw-r--r-- 1 kolobj staff 12974 Mar 23 09:17 02 - Generating Synthetic Data.md -rw-r--r-- 1 kolobj staff 5772 Mar 23 09:29 03 - Start a process in Python.ipynb -rw-r--r-- 1 kolobj staff 3324 Mar 23 09:17 03 - Start a process in Python.md -rw-r--r-- 1 kolobj staff 14276 Mar 21 09:27 04 - Python Testing.ipynb -rw-r--r-- 1 kolobj staff 9337 Mar 23 09:17 04 - Python Testing.md drwxr-xr-x 7 kolobj staff 224 Mar 20 20:23 __pycache__ -rw-r--r-- 1 kolobj staff 149 Mar 19 13:04 argparse_1.py -rw-r--r-- 1 kolobj staff 202 Mar 19 13:04 argparse_2.py -rw-r--r-- 1 kolobj staff 299 Mar 19 13:04 argparse_3.py -rw-r--r-- 1 kolobj staff 309 Mar 19 13:04 argparse_4.py -rw-r--r-- 1 kolobj staff 219 Mar 19 13:04 argparse_5.py -rw-r--r-- 1 kolobj staff 580 Mar 19 13:04 argparse_6.py -rw-r--r-- 1 kolobj staff 45 Mar 19 13:04 file.txt drwxr-xr-x 7 kolobj staff 224 Mar 19 13:04 images -rw-r--r-- 1 kolobj staff 644 Mar 19 13:04 mock.csv -rw-r--r-- 1 kolobj staff 45673 Mar 19 13:04 python.png -rw-r--r-- 1 kolobj staff 107 Mar 19 13:04 scores.csv -rw-r--r-- 1 kolobj staff 219 Mar 19 13:04 scores.json -rw-r--r-- 1 kolobj staff 547 Mar 19 13:04 scores.xml -rw-r--r-- 1 kolobj staff 762 Mar 19 13:04 scores.xsd -rw-r--r-- 1 kolobj staff 520 Mar 19 13:04 scores2.xml -rw-r--r-- 1 kolobj staff 406 Mar 20 19:01 terminal_1.py -rw-r--r-- 1 kolobj staff 404 Mar 19 13:04 terminal_2.py -rw-r--r-- 1 kolobj staff 0 Mar 19 13:04 test.txt -rw-r--r-- 1 kolobj staff 198 Mar 19 13:04 test_class.py -rw-r--r-- 1 kolobj staff 100 Mar 20 20:22 test_sample.py -rw-r--r-- 1 kolobj staff 143 Mar 19 13:04 test_sysexit.py -rw-r--r-- 1 kolobj staff 87 Mar 19 13:04 test_tmpdir.py -rw-r--r-- 1 kolobj staff 281 Mar 19 13:04 test_tmppath.py",
    "url": "http://localhost:4000/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/05%20-%20Start%20a%20process%20in%20Python.html",
    "relUrl": "/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data/05%20-%20Start%20a%20process%20in%20Python.html"
  },
  "39": {
    "id": "39",
    "title": "06 - Cleaning and Transforming Data",
    "content": "import csv import json from pprint import pprint with open(&#39;../data/csv/patients.csv&#39;) as f: reader = csv.reader(f) header = next(reader, None) rows = [row for row in reader] print(header) print(rows[0]) [&#39;Id&#39;, &#39;BIRTHDATE&#39;, &#39;DEATHDATE&#39;, &#39;SSN&#39;, &#39;DRIVERS&#39;, &#39;PASSPORT&#39;, &#39;PREFIX&#39;, &#39;FIRST&#39;, &#39;LAST&#39;, &#39;SUFFIX&#39;, &#39;MAIDEN&#39;, &#39;MARITAL&#39;, &#39;RACE&#39;, &#39;ETHNICITY&#39;, &#39;GENDER&#39;, &#39;BIRTHPLACE&#39;, &#39;ADDRESS&#39;, &#39;CITY&#39;, &#39;STATE&#39;, &#39;ZIP&#39;] [&#39;c09181f8-6526-4de7-87c7-25c95ccdbdea&#39;, &#39;2014-06-06&#39;, &#39;&#39;, &#39;999-26-1662&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;Lizbeth716&#39;, &#39;Hackett68&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;white&#39;, &#39;irish&#39;, &#39;F&#39;, &#39;Denver Pennsylvania US&#39;, &#39;742 Parisian Run Suite 87&#39;, &#39;Pittsburgh&#39;, &#39;Pennsylvania&#39;, &#39;15106&#39;] import datetime from datetime import date, timedelta from dateutil import parser def get_age(birth_date): if isinstance(birth_date, str): birth_date = parser.parse(birth_date).date() age = (date.today() - birth_date) // timedelta(days=365) return age date.today() datetime.date(2019, 6, 6) datetime.datetime.now() datetime.datetime(2019, 6, 6, 19, 56, 20, 846787) print(get_age(&#39;2011-09-10&#39;)) 7 print(get_age(&#39;2014-01-10&#39;)) 5 ages = [get_age(row[1]) for row in rows] print(ages) [4, 50, 50, 41, 63, 52, 28, 72, 23, 31] patients = [ {&#39;birth_date&#39;: row[1], &#39;age&#39;: get_age(row[1])} for row in rows ] pprint(patients) [{&#39;age&#39;: 5, &#39;birth_date&#39;: &#39;2014-06-06&#39;}, {&#39;age&#39;: 50, &#39;birth_date&#39;: &#39;1969-05-10&#39;}, {&#39;age&#39;: 50, &#39;birth_date&#39;: &#39;1969-05-30&#39;}, {&#39;age&#39;: 41, &#39;birth_date&#39;: &#39;1978-02-04&#39;}, {&#39;age&#39;: 63, &#39;birth_date&#39;: &#39;1955-11-01&#39;}, {&#39;age&#39;: 52, &#39;birth_date&#39;: &#39;1966-10-13&#39;}, {&#39;age&#39;: 28, &#39;birth_date&#39;: &#39;1990-08-20&#39;}, {&#39;age&#39;: 72, &#39;birth_date&#39;: &#39;1947-01-31&#39;}, {&#39;age&#39;: 23, &#39;birth_date&#39;: &#39;1995-07-03&#39;}, {&#39;age&#39;: 31, &#39;birth_date&#39;: &#39;1987-10-01&#39;}] # filtering based on age min_age = 18 max_age = 79 patients = [ {&#39;birth_date&#39;: row[1], &#39;age&#39;: get_age(row[1])} for row in rows if get_age(row[1]) &gt;= min_age and get_age(row[1]) &lt;= max_age ] pprint(patients) [{&#39;age&#39;: 50, &#39;birth_date&#39;: &#39;1969-05-10&#39;}, {&#39;age&#39;: 50, &#39;birth_date&#39;: &#39;1969-05-30&#39;}, {&#39;age&#39;: 41, &#39;birth_date&#39;: &#39;1978-02-04&#39;}, {&#39;age&#39;: 63, &#39;birth_date&#39;: &#39;1955-11-01&#39;}, {&#39;age&#39;: 52, &#39;birth_date&#39;: &#39;1966-10-13&#39;}, {&#39;age&#39;: 28, &#39;birth_date&#39;: &#39;1990-08-20&#39;}, {&#39;age&#39;: 72, &#39;birth_date&#39;: &#39;1947-01-31&#39;}, {&#39;age&#39;: 23, &#39;birth_date&#39;: &#39;1995-07-03&#39;}, {&#39;age&#39;: 31, &#39;birth_date&#39;: &#39;1987-10-01&#39;}] # another way to do it, add the age to the end for row in rows: row.append(get_age(row[1])) print(rows[0]) [&#39;c09181f8-6526-4de7-87c7-25c95ccdbdea&#39;, &#39;2014-06-06&#39;, &#39;&#39;, &#39;999-26-1662&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;Lizbeth716&#39;, &#39;Hackett68&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;white&#39;, &#39;irish&#39;, &#39;F&#39;, &#39;Denver Pennsylvania US&#39;, &#39;742 Parisian Run Suite 87&#39;, &#39;Pittsburgh&#39;, &#39;Pennsylvania&#39;, &#39;15106&#39;, 5] min_age = 18 max_age = 79 patients = [ {&#39;birth_date&#39;: row[1], &#39;age&#39;: row[20]} for row in rows if row[20] &gt;= min_age and row[20] &lt;= max_age ] pprint(patients) [{&#39;age&#39;: 50, &#39;birth_date&#39;: &#39;1969-05-10&#39;}, {&#39;age&#39;: 50, &#39;birth_date&#39;: &#39;1969-05-30&#39;}, {&#39;age&#39;: 41, &#39;birth_date&#39;: &#39;1978-02-04&#39;}, {&#39;age&#39;: 63, &#39;birth_date&#39;: &#39;1955-11-01&#39;}, {&#39;age&#39;: 52, &#39;birth_date&#39;: &#39;1966-10-13&#39;}, {&#39;age&#39;: 28, &#39;birth_date&#39;: &#39;1990-08-20&#39;}, {&#39;age&#39;: 72, &#39;birth_date&#39;: &#39;1947-01-31&#39;}, {&#39;age&#39;: 23, &#39;birth_date&#39;: &#39;1995-07-03&#39;}, {&#39;age&#39;: 31, &#39;birth_date&#39;: &#39;1987-10-01&#39;}] # deidentify the name import random def fake_name_generator(): fake_names = &quot;&quot;&quot;Veronique Tippetts Sarah Santiago Eustolia Bushard Emanuel Riker Maybelle Denney Lilia Gobel Clarine Vandermeer Felicidad Joynes Rod Pixley Rashad Fukushima Marci Bakley Melvina Cichon Susy Sibert Oma Hoskins Lance Curnutte Mei Wooldridge Jillian Mccroy Darby Castellon Raul Pickney Loni Kaur&quot;&quot;&quot;.split(&#39; n&#39;) return random.choice(fake_names).strip() print(fake_name_generator()) print(fake_name_generator()) print(fake_name_generator()) Lilia Gobel Emanuel Riker Clarine Vandermeer # don&#39;t reuse names fake_names = &quot;&quot;&quot;Veronique Tippetts Sarah Santiago Eustolia Bushard Emanuel Riker Maybelle Denney Lilia Gobel Clarine Vandermeer Felicidad Joynes Rod Pixley Rashad Fukushima Marci Bakley Melvina Cichon Susy Sibert Oma Hoskins Lance Curnutte Mei Wooldridge Jillian Mccroy Darby Castellon Raul Pickney Loni Kaur&quot;&quot;&quot;.split(&#39; n&#39;) def get_fake_name(): if len(fake_names) == 0: return None r = random.randint(0, len(fake_names) - 1) n = fake_names[r].strip() del fake_names[r] return n for i in range(21): print(get_fake_name()) Melvina Cichon Marci Bakley Raul Pickney Maybelle Denney Lilia Gobel Loni Kaur Felicidad Joynes Susy Sibert Rod Pixley Oma Hoskins Jillian Mccroy Eustolia Bushard Lance Curnutte Clarine Vandermeer Veronique Tippetts Sarah Santiago Mei Wooldridge Rashad Fukushima Darby Castellon Emanuel Riker None min_age = 18 max_age = 79 patients = [ {&#39;birth_date&#39;: row[1], &#39;age&#39;: row[20], &#39;name&#39;: get_fake_name() } for row in rows if row[20] &gt;= min_age and row[20] &lt;= max_age ] pprint(patients) [{&#39;age&#39;: 50, &#39;birth_date&#39;: &#39;1969-05-10&#39;, &#39;name&#39;: &#39;Oma Hoskins&#39;}, {&#39;age&#39;: 50, &#39;birth_date&#39;: &#39;1969-05-30&#39;, &#39;name&#39;: &#39;Clarine Vandermeer&#39;}, {&#39;age&#39;: 41, &#39;birth_date&#39;: &#39;1978-02-04&#39;, &#39;name&#39;: &#39;Darby Castellon&#39;}, {&#39;age&#39;: 63, &#39;birth_date&#39;: &#39;1955-11-01&#39;, &#39;name&#39;: &#39;Loni Kaur&#39;}, {&#39;age&#39;: 52, &#39;birth_date&#39;: &#39;1966-10-13&#39;, &#39;name&#39;: &#39;Rod Pixley&#39;}, {&#39;age&#39;: 28, &#39;birth_date&#39;: &#39;1990-08-20&#39;, &#39;name&#39;: &#39;Jillian Mccroy&#39;}, {&#39;age&#39;: 72, &#39;birth_date&#39;: &#39;1947-01-31&#39;, &#39;name&#39;: &#39;Raul Pickney&#39;}, {&#39;age&#39;: 23, &#39;birth_date&#39;: &#39;1995-07-03&#39;, &#39;name&#39;: &#39;Felicidad Joynes&#39;}, {&#39;age&#39;: 31, &#39;birth_date&#39;: &#39;1987-10-01&#39;, &#39;name&#39;: &#39;Marci Bakley&#39;}]",
    "url": "http://localhost:4000/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/06%20-%20Cleaning%20and%20Transforming%20Data.html",
    "relUrl": "/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/06%20-%20Cleaning%20and%20Transforming%20Data.html"
  },
  "40": {
    "id": "40",
    "title": "07 - Grouping Data",
    "content": "Grouping data using python In this tutorial we’re going to learn how to use basic python funtionality to group datasets. import csv from pprint import pprint # recall, opening the file and reading the data with open(&#39;../data/csv/patients.csv&#39;) as f: reader = csv.DictReader(f) for i, row in enumerate(reader): pprint(row) if i &gt;= 1: break OrderedDict([(&#39;Id&#39;, &#39;a1f26fb1-05aa-4991-8cf3-78d5dbc7853a&#39;), (&#39;BIRTHDATE&#39;, &#39;1994-08-22&#39;), (&#39;DEATHDATE&#39;, &#39;&#39;), (&#39;SSN&#39;, &#39;999-81-6585&#39;), (&#39;DRIVERS&#39;, &#39;S99916284&#39;), (&#39;PASSPORT&#39;, &#39;X62883440X&#39;), (&#39;PREFIX&#39;, &#39;Mr.&#39;), (&#39;FIRST&#39;, &#39;Gregory545&#39;), (&#39;LAST&#39;, &#39;Zulauf375&#39;), (&#39;SUFFIX&#39;, &#39;&#39;), (&#39;MAIDEN&#39;, &#39;&#39;), (&#39;MARITAL&#39;, &#39;&#39;), (&#39;RACE&#39;, &#39;white&#39;), (&#39;ETHNICITY&#39;, &#39;italian&#39;), (&#39;GENDER&#39;, &#39;M&#39;), (&#39;BIRTHPLACE&#39;, &#39;Worcester Massachusetts US&#39;), (&#39;ADDRESS&#39;, &#39;448 Bahringer Junction Apt 97&#39;), (&#39;CITY&#39;, &#39;North Reading&#39;), (&#39;STATE&#39;, &#39;Massachusetts&#39;), (&#39;ZIP&#39;, &#39;01864&#39;)]) OrderedDict([(&#39;Id&#39;, &#39;112942a0-dca9-4a07-983f-9e9cabcc6fe0&#39;), (&#39;BIRTHDATE&#39;, &#39;1993-10-28&#39;), (&#39;DEATHDATE&#39;, &#39;&#39;), (&#39;SSN&#39;, &#39;999-93-5205&#39;), (&#39;DRIVERS&#39;, &#39;S99938900&#39;), (&#39;PASSPORT&#39;, &#39;X13004759X&#39;), (&#39;PREFIX&#39;, &#39;Ms.&#39;), (&#39;FIRST&#39;, &#39;Tena12&#39;), (&#39;LAST&#39;, &#39;Ryan260&#39;), (&#39;SUFFIX&#39;, &#39;&#39;), (&#39;MAIDEN&#39;, &#39;&#39;), (&#39;MARITAL&#39;, &#39;&#39;), (&#39;RACE&#39;, &#39;white&#39;), (&#39;ETHNICITY&#39;, &#39;irish&#39;), (&#39;GENDER&#39;, &#39;F&#39;), (&#39;BIRTHPLACE&#39;, &#39;Revere Massachusetts US&#39;), (&#39;ADDRESS&#39;, &#39;880 Bartell Trafficway&#39;), (&#39;CITY&#39;, &#39;Tyngsborough&#39;), (&#39;STATE&#39;, &#39;Massachusetts&#39;), (&#39;ZIP&#39;, &#39;&#39;)]) # then we&#39;re going to parse out a group, e.g. Gender # recall, opening the file and reading the data with open(&#39;../data/csv/patients.csv&#39;) as f: reader = csv.DictReader(f) for i, row in enumerate(reader): patient_gender = row[&#39;GENDER&#39;] print(patient_gender) if i &gt;= 2: break M F M # how do we know what the unique genders are? # let&#39;s iterate over them and create a set patient_genders = set() with open(&#39;../data/csv/patients.csv&#39;) as f: reader = csv.DictReader(f) for i, row in enumerate(reader): patient_gender = row[&#39;GENDER&#39;] patient_genders.add(patient_gender) print(patient_genders) {&#39;F&#39;, &#39;M&#39;} # okay, we have 2 genders let&#39;s create 2 lists male_patients = [] female_patients = [] with open(&#39;../data/csv/patients.csv&#39;) as f: reader = csv.DictReader(f) for i, row in enumerate(reader): patient_gender = row[&#39;GENDER&#39;] if patient_gender == &#39;M&#39;: male_patients.append(row) elif patient_gender == &#39;F&#39;: female_patients.append(row) else: raise Exception(&#39;Unknown Gender&#39;) pprint(male_patients[0]) pprint(female_patients[0]) OrderedDict([(&#39;Id&#39;, &#39;a1f26fb1-05aa-4991-8cf3-78d5dbc7853a&#39;), (&#39;BIRTHDATE&#39;, &#39;1994-08-22&#39;), (&#39;DEATHDATE&#39;, &#39;&#39;), (&#39;SSN&#39;, &#39;999-81-6585&#39;), (&#39;DRIVERS&#39;, &#39;S99916284&#39;), (&#39;PASSPORT&#39;, &#39;X62883440X&#39;), (&#39;PREFIX&#39;, &#39;Mr.&#39;), (&#39;FIRST&#39;, &#39;Gregory545&#39;), (&#39;LAST&#39;, &#39;Zulauf375&#39;), (&#39;SUFFIX&#39;, &#39;&#39;), (&#39;MAIDEN&#39;, &#39;&#39;), (&#39;MARITAL&#39;, &#39;&#39;), (&#39;RACE&#39;, &#39;white&#39;), (&#39;ETHNICITY&#39;, &#39;italian&#39;), (&#39;GENDER&#39;, &#39;M&#39;), (&#39;BIRTHPLACE&#39;, &#39;Worcester Massachusetts US&#39;), (&#39;ADDRESS&#39;, &#39;448 Bahringer Junction Apt 97&#39;), (&#39;CITY&#39;, &#39;North Reading&#39;), (&#39;STATE&#39;, &#39;Massachusetts&#39;), (&#39;ZIP&#39;, &#39;01864&#39;)]) OrderedDict([(&#39;Id&#39;, &#39;112942a0-dca9-4a07-983f-9e9cabcc6fe0&#39;), (&#39;BIRTHDATE&#39;, &#39;1993-10-28&#39;), (&#39;DEATHDATE&#39;, &#39;&#39;), (&#39;SSN&#39;, &#39;999-93-5205&#39;), (&#39;DRIVERS&#39;, &#39;S99938900&#39;), (&#39;PASSPORT&#39;, &#39;X13004759X&#39;), (&#39;PREFIX&#39;, &#39;Ms.&#39;), (&#39;FIRST&#39;, &#39;Tena12&#39;), (&#39;LAST&#39;, &#39;Ryan260&#39;), (&#39;SUFFIX&#39;, &#39;&#39;), (&#39;MAIDEN&#39;, &#39;&#39;), (&#39;MARITAL&#39;, &#39;&#39;), (&#39;RACE&#39;, &#39;white&#39;), (&#39;ETHNICITY&#39;, &#39;irish&#39;), (&#39;GENDER&#39;, &#39;F&#39;), (&#39;BIRTHPLACE&#39;, &#39;Revere Massachusetts US&#39;), (&#39;ADDRESS&#39;, &#39;880 Bartell Trafficway&#39;), (&#39;CITY&#39;, &#39;Tyngsborough&#39;), (&#39;STATE&#39;, &#39;Massachusetts&#39;), (&#39;ZIP&#39;, &#39;&#39;)]) Can we do better? What’s wrong with the code above? Multiple iterations over the file Brittle… not resilient to new genders What can we do? Use a dictionary to store the groupings Make the code case insensitive # patients by gender patients_by_gender = {} patients_by_gender[&#39;F&#39;] = [&#39;patient1&#39;, &#39;patient3&#39;] patients_by_gender[&#39;M&#39;] = [&#39;patient2&#39;, &#39;patient4&#39;] pprint(patients_by_gender) {&#39;F&#39;: [&#39;patient1&#39;, &#39;patient3&#39;], &#39;M&#39;: [&#39;patient2&#39;, &#39;patient4&#39;]} print(patients_by_gender.keys()) dict_keys([&#39;F&#39;, &#39;M&#39;]) print(patients_by_gender.values()) dict_values([[&#39;patient1&#39;, &#39;patient3&#39;], [&#39;patient2&#39;, &#39;patient4&#39;]]) print(patients_by_gender.items()) dict_items([(&#39;F&#39;, [&#39;patient1&#39;, &#39;patient3&#39;]), (&#39;M&#39;, [&#39;patient2&#39;, &#39;patient4&#39;])]) # check if a gender is in the dictionary print(&#39;F&#39; in patients_by_gender) True print(&#39;f&#39; in patients_by_gender) False # let&#39;s group using a dictionary patients_by_gender = {} with open(&#39;../data/csv/patients.csv&#39;) as f: reader = csv.DictReader(f) for row in reader: patient_gender = row[&#39;GENDER&#39;].upper() # let&#39;s store the keys as uppercase # check to see if the key exists, if not if patient_gender not in patients_by_gender: # add the key patients_by_gender[patient_gender] = [] # create an empty list # append the patient as a new row to the correct grouping patients_by_gender[patient_gender].append(row) print(patients_by_gender.keys()) dict_keys([&#39;M&#39;, &#39;F&#39;]) pprint(patients_by_gender[&#39;F&#39;][0:2]) [OrderedDict([(&#39;Id&#39;, &#39;112942a0-dca9-4a07-983f-9e9cabcc6fe0&#39;), (&#39;BIRTHDATE&#39;, &#39;1993-10-28&#39;), (&#39;DEATHDATE&#39;, &#39;&#39;), (&#39;SSN&#39;, &#39;999-93-5205&#39;), (&#39;DRIVERS&#39;, &#39;S99938900&#39;), (&#39;PASSPORT&#39;, &#39;X13004759X&#39;), (&#39;PREFIX&#39;, &#39;Ms.&#39;), (&#39;FIRST&#39;, &#39;Tena12&#39;), (&#39;LAST&#39;, &#39;Ryan260&#39;), (&#39;SUFFIX&#39;, &#39;&#39;), (&#39;MAIDEN&#39;, &#39;&#39;), (&#39;MARITAL&#39;, &#39;&#39;), (&#39;RACE&#39;, &#39;white&#39;), (&#39;ETHNICITY&#39;, &#39;irish&#39;), (&#39;GENDER&#39;, &#39;F&#39;), (&#39;BIRTHPLACE&#39;, &#39;Revere Massachusetts US&#39;), (&#39;ADDRESS&#39;, &#39;880 Bartell Trafficway&#39;), (&#39;CITY&#39;, &#39;Tyngsborough&#39;), (&#39;STATE&#39;, &#39;Massachusetts&#39;), (&#39;ZIP&#39;, &#39;&#39;)]), OrderedDict([(&#39;Id&#39;, &#39;893ba78c-4633-4707-a11a-bf7f6c6fc827&#39;), (&#39;BIRTHDATE&#39;, &#39;2003-08-16&#39;), (&#39;DEATHDATE&#39;, &#39;&#39;), (&#39;SSN&#39;, &#39;999-46-3420&#39;), (&#39;DRIVERS&#39;, &#39;S99923748&#39;), (&#39;PASSPORT&#39;, &#39;&#39;), (&#39;PREFIX&#39;, &#39;&#39;), (&#39;FIRST&#39;, &#39;Casandra937&#39;), (&#39;LAST&#39;, &#39;Reynolds644&#39;), (&#39;SUFFIX&#39;, &#39;&#39;), (&#39;MAIDEN&#39;, &#39;&#39;), (&#39;MARITAL&#39;, &#39;&#39;), (&#39;RACE&#39;, &#39;white&#39;), (&#39;ETHNICITY&#39;, &#39;russian&#39;), (&#39;GENDER&#39;, &#39;F&#39;), (&#39;BIRTHPLACE&#39;, &#39;Boston Massachusetts US&#39;), (&#39;ADDRESS&#39;, &#39;1048 Botsford Skyway Apt 45&#39;), (&#39;CITY&#39;, &#39;Fairhaven&#39;), (&#39;STATE&#39;, &#39;Massachusetts&#39;), (&#39;ZIP&#39;, &#39;02719&#39;)])] print(patients_by_gender[&#39;F&#39;][0][&#39;LAST&#39;]) Ryan260 Let’s make the code reusable Create a function Externalize parameters that will change fromt the function What’s common? The csv processing The grouping logic What’s different? The file name The groupby parameters # define the function def group_patient(file_name, groupby): pass # call the function patients_by_gender = group_patient(&#39;../data/csv/patients.csv&#39;, &#39;GENDER&#39;) print(patients_by_gender) None # now let&#39;s implement the function def group_patient(file_name, groupby): patients_by_group = {} with open(file_name) as f: reader = csv.DictReader(f) for row in reader: # note : we renamed the variable to _attribute patient_attribute = row[groupby].upper() # check to see if the key exists, if not if patient_attribute not in patients_by_group: # add the key patients_by_group[patient_attribute] = [] # create an empty list # append the patient as a new row to the correct grouping patients_by_group[patient_attribute].append(row) return patients_by_group patients_by_gender = group_patient(&#39;../data/csv/patients.csv&#39;, &#39;GENDER&#39;) pprint(patients_by_gender[&#39;F&#39;][0:2]) [OrderedDict([(&#39;Id&#39;, &#39;112942a0-dca9-4a07-983f-9e9cabcc6fe0&#39;), (&#39;BIRTHDATE&#39;, &#39;1993-10-28&#39;), (&#39;DEATHDATE&#39;, &#39;&#39;), (&#39;SSN&#39;, &#39;999-93-5205&#39;), (&#39;DRIVERS&#39;, &#39;S99938900&#39;), (&#39;PASSPORT&#39;, &#39;X13004759X&#39;), (&#39;PREFIX&#39;, &#39;Ms.&#39;), (&#39;FIRST&#39;, &#39;Tena12&#39;), (&#39;LAST&#39;, &#39;Ryan260&#39;), (&#39;SUFFIX&#39;, &#39;&#39;), (&#39;MAIDEN&#39;, &#39;&#39;), (&#39;MARITAL&#39;, &#39;&#39;), (&#39;RACE&#39;, &#39;white&#39;), (&#39;ETHNICITY&#39;, &#39;irish&#39;), (&#39;GENDER&#39;, &#39;F&#39;), (&#39;BIRTHPLACE&#39;, &#39;Revere Massachusetts US&#39;), (&#39;ADDRESS&#39;, &#39;880 Bartell Trafficway&#39;), (&#39;CITY&#39;, &#39;Tyngsborough&#39;), (&#39;STATE&#39;, &#39;Massachusetts&#39;), (&#39;ZIP&#39;, &#39;&#39;)]), OrderedDict([(&#39;Id&#39;, &#39;893ba78c-4633-4707-a11a-bf7f6c6fc827&#39;), (&#39;BIRTHDATE&#39;, &#39;2003-08-16&#39;), (&#39;DEATHDATE&#39;, &#39;&#39;), (&#39;SSN&#39;, &#39;999-46-3420&#39;), (&#39;DRIVERS&#39;, &#39;S99923748&#39;), (&#39;PASSPORT&#39;, &#39;&#39;), (&#39;PREFIX&#39;, &#39;&#39;), (&#39;FIRST&#39;, &#39;Casandra937&#39;), (&#39;LAST&#39;, &#39;Reynolds644&#39;), (&#39;SUFFIX&#39;, &#39;&#39;), (&#39;MAIDEN&#39;, &#39;&#39;), (&#39;MARITAL&#39;, &#39;&#39;), (&#39;RACE&#39;, &#39;white&#39;), (&#39;ETHNICITY&#39;, &#39;russian&#39;), (&#39;GENDER&#39;, &#39;F&#39;), (&#39;BIRTHPLACE&#39;, &#39;Boston Massachusetts US&#39;), (&#39;ADDRESS&#39;, &#39;1048 Botsford Skyway Apt 45&#39;), (&#39;CITY&#39;, &#39;Fairhaven&#39;), (&#39;STATE&#39;, &#39;Massachusetts&#39;), (&#39;ZIP&#39;, &#39;02719&#39;)])] # but wait... is there anything patient specific??? # let&#39;s refactor the code to make it more extensible # and easier to read def group(file_name, groupby): grouped_data = {} with open(file_name) as f: reader = csv.DictReader(f) for row in reader: attribute = row[groupby].upper() if attribute not in grouped_data: grouped_data[attribute] = [] grouped_data[attribute].append(row) return grouped_data patients_by_gender = group(&#39;../data/csv/patients.csv&#39;, &#39;GENDER&#39;) pprint(patients_by_gender[&#39;F&#39;][0]) OrderedDict([(&#39;Id&#39;, &#39;112942a0-dca9-4a07-983f-9e9cabcc6fe0&#39;), (&#39;BIRTHDATE&#39;, &#39;1993-10-28&#39;), (&#39;DEATHDATE&#39;, &#39;&#39;), (&#39;SSN&#39;, &#39;999-93-5205&#39;), (&#39;DRIVERS&#39;, &#39;S99938900&#39;), (&#39;PASSPORT&#39;, &#39;X13004759X&#39;), (&#39;PREFIX&#39;, &#39;Ms.&#39;), (&#39;FIRST&#39;, &#39;Tena12&#39;), (&#39;LAST&#39;, &#39;Ryan260&#39;), (&#39;SUFFIX&#39;, &#39;&#39;), (&#39;MAIDEN&#39;, &#39;&#39;), (&#39;MARITAL&#39;, &#39;&#39;), (&#39;RACE&#39;, &#39;white&#39;), (&#39;ETHNICITY&#39;, &#39;irish&#39;), (&#39;GENDER&#39;, &#39;F&#39;), (&#39;BIRTHPLACE&#39;, &#39;Revere Massachusetts US&#39;), (&#39;ADDRESS&#39;, &#39;880 Bartell Trafficway&#39;), (&#39;CITY&#39;, &#39;Tyngsborough&#39;), (&#39;STATE&#39;, &#39;Massachusetts&#39;), (&#39;ZIP&#39;, &#39;&#39;)]) What if we want multiple grouping levels? # single level grouping by gender { &quot;F&quot;: [ &#39;patient1&#39;, &#39;patient2&#39;], &quot;M&quot;: [ &#39;patient3&#39;, &#39;patient4&#39;] } {&#39;F&#39;: [&#39;patient1&#39;, &#39;patient2&#39;], &#39;M&#39;: [&#39;patient3&#39;, &#39;patient4&#39;]} # multi level grouping by gender and race { &quot;F&quot;: { &quot;WHITE&quot;: [&#39;patient1&#39;, &#39;patient2&#39;], &quot;HISPANIC&quot;: [&#39;patient3&#39;] }, &quot;M&quot;: { &quot;WHITE&quot;: [], &quot;HISPANIC&quot;: [&#39;patient4&#39;, &#39;patient5&#39;] } } {&#39;F&#39;: {&#39;WHITE&#39;: [&#39;patient1&#39;, &#39;patient2&#39;], &#39;HISPANIC&#39;: [&#39;patient3&#39;]}, &#39;M&#39;: {&#39;WHITE&#39;: [], &#39;HISPANIC&#39;: [&#39;patient4&#39;, &#39;patient5&#39;]}} def group_file(file_name, groupby): with open(file_name) as f: reader = csv.DictReader(f) return group(reader, groupby) def group(iterable, groupby): grouped_data = {} for item in iterable: attribute = item[groupby].upper() if attribute not in grouped_data: grouped_data[attribute] = [] grouped_data[attribute].append(item) return grouped_data patients_by_gender = group_file(&#39;../data/csv/patients.csv&#39;, &#39;GENDER&#39;) pprint(patients_by_gender[&#39;F&#39;][0]) OrderedDict([(&#39;Id&#39;, &#39;112942a0-dca9-4a07-983f-9e9cabcc6fe0&#39;), (&#39;BIRTHDATE&#39;, &#39;1993-10-28&#39;), (&#39;DEATHDATE&#39;, &#39;&#39;), (&#39;SSN&#39;, &#39;999-93-5205&#39;), (&#39;DRIVERS&#39;, &#39;S99938900&#39;), (&#39;PASSPORT&#39;, &#39;X13004759X&#39;), (&#39;PREFIX&#39;, &#39;Ms.&#39;), (&#39;FIRST&#39;, &#39;Tena12&#39;), (&#39;LAST&#39;, &#39;Ryan260&#39;), (&#39;SUFFIX&#39;, &#39;&#39;), (&#39;MAIDEN&#39;, &#39;&#39;), (&#39;MARITAL&#39;, &#39;&#39;), (&#39;RACE&#39;, &#39;white&#39;), (&#39;ETHNICITY&#39;, &#39;irish&#39;), (&#39;GENDER&#39;, &#39;F&#39;), (&#39;BIRTHPLACE&#39;, &#39;Revere Massachusetts US&#39;), (&#39;ADDRESS&#39;, &#39;880 Bartell Trafficway&#39;), (&#39;CITY&#39;, &#39;Tyngsborough&#39;), (&#39;STATE&#39;, &#39;Massachusetts&#39;), (&#39;ZIP&#39;, &#39;&#39;)]) # patients by gender and race # here we&#39;ll use a dictionary to represent the 2nd level patients_by_gender_and_race = group_file(&#39;../data/csv/patients.csv&#39;, &#39;GENDER&#39;) for gender in patients_by_gender_and_race.keys(): patients_by_gender_and_race[gender] = {} pprint(patients_by_gender_and_race) {&#39;F&#39;: {}, &#39;M&#39;: {}} # now let&#39;s perform the groupings patients_by_gender_and_race = group_file(&#39;../data/csv/patients.csv&#39;, &#39;GENDER&#39;) # print(patients_by_gender_and_race) for gender in patients_by_gender.keys(): patients_by_gender_and_race[gender] = group(patients_by_gender[gender], &#39;RACE&#39;) # finally let&#39;s print the unique genders and races for gender in patients_by_gender_and_race.keys(): for race in patients_by_gender_and_race[gender].keys(): print(gender, race) M WHITE F WHITE F NATIVE # as a sanity check let&#39;s look over the dataset again gender = set() race = set() with open(&#39;../data/csv/patients.csv&#39;) as f: reader = csv.DictReader(f) for row in reader: gender.add(row[&#39;GENDER&#39;]) race.add(row[&#39;RACE&#39;]) print(gender, race) {&#39;F&#39;, &#39;M&#39;} {&#39;white&#39;, &#39;native&#39;} # what about 3 levels of grouping? grouped_patients = group_file(&#39;../data/csv/patients.csv&#39;, &#39;GENDER&#39;) for gender in grouped_patients.keys(): grouped_patients[gender] = group(grouped_patients[gender], &#39;RACE&#39;) for race in grouped_patients[gender].keys(): grouped_patients[gender][race] = group(grouped_patients[gender][race], &#39;ETHNICITY&#39;) # print(grouped_patients) # let&#39;s print the unique genders and races for gender in grouped_patients.keys(): for race in grouped_patients[gender].keys(): for ethnicity in grouped_patients[gender][race].keys(): print(gender, race, ethnicity) M WHITE ITALIAN M WHITE ENGLISH M WHITE GERMAN F WHITE IRISH F WHITE RUSSIAN F WHITE AMERICAN F NATIVE AMERICAN_INDIAN What about 4 levels of grouping? I think we should refactor again. This time using recursion. This time we’ll support any number of groupings. def group_file_by_list(file_name, groupings): with open(file_name) as f: reader = csv.DictReader(f) grouped_data = group(reader, groupings[0]) if len(groupings) &gt; 1: group_by_list(grouped_data.keys(), grouped_data, groupings[1:]) return grouped_data def group_by_list(iterable, grouped_data, groupings): for item in iterable: grouped_data[item] = group(grouped_data[item], groupings[0]) if len(groupings) &gt; 1: group_by_list(grouped_data[item].keys(), grouped_data[item], groupings[1:]) return grouped_data groupings = [&#39;GENDER&#39;, &#39;RACE&#39;, &#39;ETHNICITY&#39;] grouped_patients = group_file_by_list(&#39;../data/csv/patients.csv&#39;, groupings) for gender in grouped_patients.keys(): for race in grouped_patients[gender].keys(): for ethnicity in grouped_patients[gender][race].keys(): print(gender, race, ethnicity) M WHITE ITALIAN M WHITE ENGLISH M WHITE GERMAN F WHITE IRISH F WHITE RUSSIAN F WHITE AMERICAN F NATIVE AMERICAN_INDIAN # let&#39;s create a recursive print def print_keys(d): for k, v in d.items(): print_keys2(v, [k]) def print_keys2(d, l): if isinstance(d, dict): for k, v in d.items(): print_keys2(v, l + [k]) else: print(&#39; &#39;.join(l)) l = [] print_keys(grouped_patients) M WHITE ITALIAN M WHITE ENGLISH M WHITE GERMAN F WHITE IRISH F WHITE RUSSIAN F WHITE AMERICAN F NATIVE AMERICAN_INDIAN # lets try it out on a few examples grouped_patients = group_file_by_list(&#39;../data/csv/patients.csv&#39;, [&#39;GENDER&#39;]) print_keys(grouped_patients) M F grouped_patients = group_file_by_list(&#39;../data/csv/patients.csv&#39;, [&#39;RACE&#39;]) print_keys(grouped_patients) WHITE NATIVE grouped_patients = group_file_by_list(&#39;../data/csv/patients.csv&#39;, [&#39;GENDER&#39;, &#39;RACE&#39;]) print_keys(grouped_patients) M WHITE F WHITE F NATIVE grouped_patients = group_file_by_list(&#39;../data/csv/patients.csv&#39;, [&#39;RACE&#39;, &#39;GENDER&#39;]) print_keys(grouped_patients) WHITE M WHITE F NATIVE F grouped_patients = group_file_by_list(&#39;../data/csv/patients.csv&#39;, [&#39;ETHNICITY&#39;]) print_keys(grouped_patients) ITALIAN IRISH RUSSIAN AMERICAN_INDIAN ENGLISH AMERICAN GERMAN grouped_patients = group_file_by_list(&#39;../data/csv/patients.csv&#39;, [&#39;RACE&#39;, &#39;ETHNICITY&#39;]) print_keys(grouped_patients) WHITE ITALIAN WHITE IRISH WHITE RUSSIAN WHITE ENGLISH WHITE AMERICAN WHITE GERMAN NATIVE AMERICAN_INDIAN grouped_patients = group_file_by_list(&#39;../data/csv/patients.csv&#39;, [&#39;RACE&#39;, &#39;ETHNICITY&#39;, &#39;BIRTHPLACE&#39;, &#39;GENDER&#39;]) print_keys(grouped_patients) WHITE ITALIAN WORCESTER MASSACHUSETTS US M WHITE ITALIAN MILFORD MASSACHUSETTS US M WHITE IRISH REVERE MASSACHUSETTS US F WHITE IRISH GROTON MASSACHUSETTS US F WHITE IRISH TAUNTON MASSACHUSETTS US F WHITE RUSSIAN BOSTON MASSACHUSETTS US F WHITE ENGLISH BOSTON MASSACHUSETTS US M WHITE AMERICAN FRAMINGHAM MASSACHUSETTS US F WHITE GERMAN NANTUCKET MASSACHUSETTS US M NATIVE AMERICAN_INDIAN HARWICH MASSACHUSETTS US F",
    "url": "http://localhost:4000/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/07%20-%20Grouping%20Data.html",
    "relUrl": "/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping/07%20-%20Grouping%20Data.html"
  },
  "41": {
    "id": "41",
    "title": "Data Focused Python",
    "content": "Description Course Site This course focuses on the fundamentals of computer programming using the Python interpreted programming language. Students will develop his or her problem solving skills using the divide and-conquer and top-down approaches to build real-world based software applications. Students will also learn the basics of the software development life-cycle: planning, development, testing, implementation and maintenance. Assignments will include individual coding assignments and weekly fundamental checkpoint quizzes culminating with an individual final project to test essential programming and problem solving skills. Note: The course schedule and assignments are subject to change. Please see your Enterprise Learning Management System (e.g. Canvas, Blackboard, Desire2Learn) for the official schedule. Lectures Lectures will contain a mixture of content form this site and others. Week 01 - Language basics, Generating Data, Storing Data Week 02 - Processing files, Making Web Requests Week 03 - Comprehensions, Generators, and Grouping Week 04 - Numpy, Pandas, Graphing &amp; Visualization Week 05 - Numpy &amp; Pandas In-Depth Week 06 - Web Scraping, Databases, and Other Data Sources Quizzes Quizzes will be administered approximately every week on material from prior weeks. All quizzes are closed book and no materials may be used. Week 2 - Quiz 1 Week 3 - Quiz 2 Week 4 - Quiz 3 Week 5 - Quiz 4 Week 6 - Quiz 5 Assignments The project is a collection of individual programming assignments building towards delivery of a final product. Week 2 - Assignment 1 Week 3 - Assignment 2 Week 4 - Assignment 3 Week 6 - Assignment 4 Grading All assignments will be evaluated by 2 criteria: Correctness: The program produces the expected output or data. Proficiency: The program demonstrates a high degree of competence or skill.",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },
  "42": {
    "id": "42",
    "title": "Week 01 - Language basics, Generating Data, Storing Data",
    "content": "",
    "url": "http://localhost:4000/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data.html",
    "relUrl": "/lectures/Week%2001%20-%20Language%20basics,%20Generating%20Data,%20Storing%20Data.html"
  },
  "43": {
    "id": "43",
    "title": "Week 02 - Processing files, Making Web Requests",
    "content": "",
    "url": "http://localhost:4000/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests.html",
    "relUrl": "/lectures/Week%2002%20-%20Processing%20files,%20Making%20Web%20Requests.html"
  },
  "44": {
    "id": "44",
    "title": "Week 03 - Comprehensions, Generators, and Grouping",
    "content": "",
    "url": "http://localhost:4000/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping.html",
    "relUrl": "/lectures/Week%2003%20-%20Comprehensions,%20Generators,%20and%20Grouping.html"
  },
  "45": {
    "id": "45",
    "title": "Week 04 - Numpy, Pandas, Graphing & Visualization",
    "content": "",
    "url": "http://localhost:4000/lectures/Week%2004%20-%20Numpy,%20Pandas,%20Graphing%20&%20Visualization.html",
    "relUrl": "/lectures/Week%2004%20-%20Numpy,%20Pandas,%20Graphing%20&%20Visualization.html"
  },
  "46": {
    "id": "46",
    "title": "Week 05 - Numpy & Pandas In-Depth",
    "content": "",
    "url": "http://localhost:4000/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth.html",
    "relUrl": "/lectures/Week%2005%20-%20Numpy%20&%20Pandas%20In-Depth.html"
  },
  "47": {
    "id": "47",
    "title": "Week 06 - Web Scraping, Databases, and Other Data Sources",
    "content": "",
    "url": "http://localhost:4000/lectures/Week%2006%20-%20Web%20Scraping,%20Databases,%20and%20Other%20Data%20Sources.html",
    "relUrl": "/lectures/Week%2006%20-%20Web%20Scraping,%20Databases,%20and%20Other%20Data%20Sources.html"
  },
  "48": {
    "id": "48",
    "title": "Assignments",
    "content": "Description During this project you will generate, process, analyze, and answer specific questions questions using algorithms and visualizations about a healthcare dataset. Each of the individual assignments will build towards the final deliverable. Individual assignments will have both must have requirements and stretch requirements. Completion of the must have requirements “Meet Expectations”. Sophistication, completeness, and style of the stretch requirements will contribute to students “Exceeding Expectations” or delivering “Superior Work”. Deliverables Assignment 1 Writing console applications Parsing json and csv with python out of the box Using 3rd party packages to parse data Assignment 2 Answering basic questions about the data Assignment 3 Data analysis Assignment 4 Data analysis with visualization Example Output for Assigment 4 that Meets Expectations",
    "url": "http://localhost:4000/assignments",
    "relUrl": "/assignments"
  },
  "49": {
    "id": "49",
    "title": "Lectures",
    "content": "Week 01 - Language basics, Generating Data, Storing Data 00 - Getting Started (ipynb) 01.A - Terminal Application (ipynb) 01.B - Argparse (ipynb) 02.A - Generating Synthetic Healthcare Data (ipynb) 02.B - Generating Other Synthetic Data (ipynb) 02.C - Using Synthea (ipynb) 03 - Getting Data From A Database (ipynb) 04 - Fhir Sql (ipynb) 04 - Python Testing (ipynb) 05 - Start A Process In Python (ipynb) Week 02 - Processing files, Making Web Requests 01.A - File Processing (ipynb) 01.B - Csv Files (ipynb) 01.C - Json Files (ipynb) 01.D - Xml Files (ipynb) 02.A - Python Classes (ipynb) 02.B - Python Modules And Packages (ipynb) 03 - Using Fhirclient To Parse Healthcare Data (ipynb) 04 - Reading Synthea Data (ipynb) 05 - Getting Data From Web Apis (ipynb) Week 03 - Comprehensions, Generators, and Grouping 01.A - Python Functions (ipynb) 01.B - Python Tuples (ipynb) 01.C - Loops (ipynb) 02 - Lists And List Comprehensions (ipynb) 03 - Sets And Set Comprehensions (ipynb) 04.A - Dictionaries (ipynb) 04.B - Dictionary Comprehensions (ipynb) 05 - Python Generators (ipynb) 06 - Cleaning And Transforming Data (ipynb) 07 - Grouping Data (ipynb) Week 04 - Numpy, Pandas, Graphing &amp; Visualization 01 - Descriptive Statistics (ipynb) 02 - Basic Medical Data Visualization (ipynb) 03 - Matplotlib Tutorial Python Plotting (ipynb) 04 - The Ultimate Python Seaborn Tutorial (ipynb) Week 05 - Numpy &amp; Pandas In-Depth 00 - Additional Links (ipynb) 01 - Numpy Introduction (ipynb) 02 - Numpy Data Analysis (ipynb) 03 - Pandas Introduction (ipynb) 04.A - Pandas Data Analysis Part 1 (ipynb) 04.B - Pandas Data Analysis Part 2 (ipynb) Week 06 - Web Scraping, Databases, and Other Data Sources 01.A - Getting Data From Web Pages (ipynb) 01.B - Getting Data From Web Pages (ipynb)",
    "url": "http://localhost:4000/lectures",
    "relUrl": "/lectures"
  },
  "50": {
    "id": "50",
    "title": "Resources",
    "content": "This page contains a collection of useful resources related to the course. Useful Books Python for Data Analysis Note: Available at the CMU Library as an eBook Automate the Boring Stuff Synthetic Data Generation Synthetic patient generation Mimic Critical Care Database Synthetic data generation (roll your own) Useful Links 24 Ultimate Data Science Projects To Boost Your Knowledge and Skills",
    "url": "http://localhost:4000/resources",
    "relUrl": "/resources"
  },
  "51": {
    "id": "51",
    "title": "",
    "content": "Director of Product Management &amp; Developer Experience (DX) Professor of Information Science Brian J Kolowitz DSc. Information Systems MSc. Management of Information Systems MBA BSc. Computer Engineering Product ManagerProfessorSoftware Developer developer experienceapi designsolution architecturelean development pythonjavahtmljavascriptc#c++ fhirdicomhl7",
    "url": "http://localhost:4000/about.html",
    "relUrl": "/about.html"
  }
  
}
